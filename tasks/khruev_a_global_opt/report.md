# Многошаговая схема решения двумерных задач глобальной оптимизации. Распараллеливание по характеристикам

**Студент:** Хруев Антон  
**Группа:** 3823Б1ФИ1  
**Технологии:** SEQ | MPI  
**Вариант:** 13  

---

## 1. Введение

Целью данной работы является разработка и исследование алгоритма **глобальной оптимизации функции двух переменных** на прямоугольной области определения с использованием **многошаговой схемы поиска**.

Реализованы две версии алгоритма:
- последовательная (SEQ),
- параллельная с использованием технологии MPI (MPI).

В основе алгоритма лежит **сведение двумерной задачи глобальной оптимизации к одномерной** с помощью развертки Гильберта, а также использование **характеристик интервалов**, позволяющих направленно уточнять область поиска минимума.

Параллельная версия использует распараллеливание по вычислению характеристик и значений целевой функции в наиболее перспективных интервалах.

---

## 2. Постановка задачи

Требуется найти глобальный минимум функции двух переменных  

\[
f(x, y) \rightarrow \min,
\]

где  

\[
x \in [a_x, b_x], \quad y \in [a_y, b_y].
\]

### Входные данные
- границы области поиска: \( [a_x, b_x] \times [a_y, b_y] \);
- идентификатор целевой функции;
- параметр надежности \( r > 1 \);
- точность поиска \( \varepsilon \);
- максимальное число итераций `max_iter`.

### Выходные данные
- координаты точки минимума \( (x^*, y^*) \);
- значение функции в точке минимума \( f(x^*, y^*) \);
- количество выполненных итераций.

---

## 3. Последовательный алгоритм (SEQ)

Последовательная версия реализована в классе  
`KhruevAGlobalOptSEQ`.

### Основная идея алгоритма

Двумерная задача оптимизации сводится к одномерной с помощью **непрерывной развертки Гильберта**:

\[
t \in [0, 1] \longrightarrow (x(t), y(t)) \in [a_x, b_x] \times [a_y, b_y].
\]

Таким образом, задача поиска минимума функции двух переменных заменяется задачей поиска минимума функции одной переменной:

\[
\varphi(t) = f(x(t), y(t)).
\]


### Этапы алгоритма

1. **Инициализация**
   - В список испытаний добавляются точки \( t = 0 \) и \( t = 1 \).
   - Для них вычисляются значения целевой функции.

2. **Оценка константы Липшица**
   - На каждом шаге вычисляется оценка:
     \[
     M = r \cdot \max_i \frac{|z_i - z_{i-1}|}{|x_i - x_{i-1}|},
     \]
     где \( z_i = \varphi(t_i) \).

3. **Вычисление характеристик интервалов**
   Для каждого интервала \([t_{i-1}, t_i]\) вычисляется характеристика:
   \[
   R_i = M \Delta t_i + \frac{(z_i - z_{i-1})^2}{M \Delta t_i} - 2(z_i + z_{i-1}).
   \]

4. **Выбор перспективного интервала**
   - Выбирается интервал с максимальной характеристикой \( R_i \).

5. **Построение новой точки**
   Новая точка вычисляется по формуле:
   \[
   t_{\text{new}} = \frac{t_i + t_{i-1}}{2} - \frac{z_i - z_{i-1}}{2M}.
   \]

6. **Критерий остановки**
   - Алгоритм завершается, если длина лучшего интервала меньше \( \varepsilon \),
   - или достигнуто максимальное число итераций.


## 4. Параллельная версия (MPI)

Параллельная версия реализована в классе  
`KhruevAGlobalOptMPI`.

### Идея распараллеливания

Распараллеливание выполняется **по интервалам с наибольшими характеристиками**:
- каждый MPI-процесс независимо вычисляет значение функции в своей новой точке;
- дорогостоящие вычисления целевой функции выполняются параллельно.

### Основные этапы алгоритма

#### 1. Инициализация
- Каждый процесс добавляет одинаковые начальные точки \( t = 0 \) и \( t = 1 \).
- Список испытаний синхронизирован на всех процессах.

#### 2. Вычисление параметра \( M \)
- Параметр \( M \) вычисляется локально, так как список точек одинаков у всех процессов.

#### 3. Вычисление характеристик интервалов
- Для всех интервалов вычисляются значения \( R_i \).
- Интервалы сортируются по убыванию характеристик.

#### 4. Распределение работы
- Выбираются **top-P интервалов**, где \( P \) — число MPI-процессов.
- Каждый процесс получает **один интервал** для вычисления новой точки.

#### 5. Параллельное вычисление новых точек
- Каждый процесс:
  - вычисляет свою точку \( t_{\text{new}} \);
  - вычисляет значение целевой функции (наиболее затратная операция).


#### 6. Обмен результатами
- Используется коллективная операция **`MPI_Allgather`**.
- Все новые точки и значения функции становятся известны всем процессам.

#### 7. Обновление множества испытаний
- Все корректные точки добавляются в список.
- Если ни одна точка не была добавлена, алгоритм завершает работу.

---

## 5. Детали реализации

Основные файлы проекта:
- `ops_seq.cpp` — последовательная реализация алгоритма;
- `ops_mpi.cpp` — параллельная реализация с использованием MPI;
- `common.hpp` — общие структуры данных и вспомогательные функции.

Основные классы:
- `KhruevAGlobalOptSEQ`,
- `KhruevAGlobalOptMPI`.

---

## 6. Аппаратное и программное обеспечение

- **Процессор:** AMD Ryzen 3 7320U (4 ядра / 8 потоков)  
- **Оперативная память:** 8 GB  
- **ОС:** Ubuntu 24.04.2 LTS  
- **Компилятор:** GCC 13.3.0  
- **Тип сборки:** Release  
- **Данные:** синтетические тестовые функции  

---

## 7. Результаты

### Функциональные тесты

Проверялась корректность:
- нахождения глобального минимума;
- работы на различных целевых функциях;
- устойчивости к изменению параметров \( r \) и \( \varepsilon \);
- совпадения результатов SEQ и MPI версий.

### Тесты производительности

Измерения проводились для одинаковых входных данных.

#### Время выполнения

| Режим | Процессы | Время, с | Ускорение | Эффективность |
|-----|---------|----------|-----------|---------------|
| SEQ | 1 | 0.01495 | 1.00 | 100% |
| MPI | 2 | 0.00861 | 1.74 | 87% |
| MPI | 3 | 0.00621 | 2.41 | 80% |
| MPI | 4 | 0.00569 | 2.67 | 67% |

Полученные результаты показывают хорошую масштабируемость при увеличении числа процессов.

---

## 8. Выводы

В ходе выполнения работы:
- реализован последовательный алгоритм глобальной оптимизации;
- реализована параллельная MPI-версия с распараллеливанием по характеристикам;
- достигнуто значительное ускорение за счет параллельного вычисления целевой функции;
- корректность реализации подтверждена функциональными и performance-тестами.

---

## 9. Источники

1. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025.  
2. Баркалов К. А., Гергель В. П., Лебедев И. Г., Сысоев А. В.  
   *Решение задач глобальной оптимизации на гетерогенных кластерных системах*. — Н. Новгород: ННГУ, 2015.
