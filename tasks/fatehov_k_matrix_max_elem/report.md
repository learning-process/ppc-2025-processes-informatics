# <Task Full Name>

- Student: <Фатехов Камиль Гаярович>, group <3823Б1ФИ3>
- Technology: SEQ | MPI
- Variant: 13

## 1. Введение
Brief motivation, problem context, expected outcome.
Разработка последовательной и параллельной версии поиска максимального значения элементов матрицы с последующим сравнением этих двух версий.

**Цели лабораторной**:  
    - Реализовать последовательную версию поиска максимального значения элементов матрицы.  
    - Изучить основы MPI и реализовать параллельную версию программы.  
    - Сравнить эти производительность и эффективность этих реализаций
## 2. Постановка задачи
Formal task definition, input/output format, constraints.  
**Цель**: Определить максимальное значение элементов матрицы

**Входные данные**  
    Данные представлены в виде `tuple(rows, cols, matrix)`, где:  
    - `rows` - количество строк матрицы  
    - `cols` - количество столбцов матрицы  
    - `matrix` - непосредственно сама матрица

**Выходные данные**
На выходе получается единичное значение типа *double* - максимальный элемент в матрице.  

**Ограничения**:  
    - Размер матрицы не превышает величины `kMaxMatrixSize = 100000000`  
    - Количество строк не превышает величины `kMaxRows = 10000`  
    - количество столбцов не превышает величины `kMaxCols = 10000`  

## 3. Базовый алгоритм (Последовательный)

 **Реализован следующий код**:
```cpp 
bool FatehovKMatrixMaxElemSEQ::RunImpl() {
  auto &data = GetInput();
  size_t rows = std::get<0>(data);
  size_t columns = std::get<1>(data);
  std::vector<double>& matrix = std::get<2>(data);
  double max = matrix[0];
  for (size_t i = 0; i < rows; i++) {
    for (size_t j = 0; j < columns; j++) {
      max = std::max(matrix[(i * columns) + j], max);
    }
  }
  GetOutput() = max;
  return true;
}
```

**Алгоритм работы**:  
1. Получаем входные данные: количество строк (rows), количество столбцов (columns) и элементы матрицы в виде одномерного вектора, хранящего элементы построчно

2. Инициализируем максимум: присваиваем переменной max значение первого элемента матрицы

3. Последовательно перебираем элементы: через двойной цикл проходим по всем строкам и столбцам матрицы

4. Сравниваем элементы: для каждого элемента вычисляем его позицию в векторе по формуле `(i * columns + j)` и сравниваем с текущим максимумом

5. Обновляем результат: если найденный элемент больше текущего максимума, обновляем значение max

6. Возвращаем результат: записываем найденное максимальное значение в выходные данные  

## 4. Схема распараллеливания

**Описание**:  
- Код реализует параллельный поиск максимального элемента в матрице с использованием MPI. Данные распределяются блоками по процессам, каждый процесс находит локальный максимум, а затем все процессы объединяют свои результаты чтобы найти общий максимум.

**Алгоритм работы**:  

1. **Инициализация и получение данных**

```cpp
auto &data = GetInput();
size_t rows = std::get<0>(data);
size_t columns = std::get<1>(data);
std::vector<double>& matrix = std::get<2>(data);
```

2. **MPI инициализация**
```cpp
int world_rank = 0;
int world_size = 0;
MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
MPI_Comm_size(MPI_COMM_WORLD, &world_size);  
```

3. **Распределение данных**  

*Схема распределения*:  

Всего элементов: `N = rows × columns `   
Базовое количество на процесс: `elems_per_proc = N / world_size`  
Остаток: `remainder = N % world_size`   

*Формула распределения*:  

```cpp
size_t start = (world_rank * elems_per_proc) + std::min(world_rank, static_cast<int>(remainder));
  size_t end = start + elems_per_proc + (std::cmp_less(world_rank, remainder) ? 1 : 0);
```

*Пример (4 процесса, 10 элементов)*:

Процесс 0: start=0, end=3 (3 элемента)  
Процесс 1: start=3, end=6 (3 элемента)    
Процесс 2: start=6, end=8 (2 элемента)  
Процесс 3: start=8, end=10 (2 элемента)  

4. **Локальные вычисления**

```cpp
double local_max = -std::numeric_limits<double>::max();
for (size_t i = start; i < end; i++) {
    local_max = std::max(matrix[i], local_max);
  }
```
5. **Объединение локальных максимумов и поиск общего глобального**
```cpp
MPI_Allreduce(&local_max, &global_max, 1, MPI_DOUBLE, MPI_MAX, MPI_COMM_WORLD);
```

*Схема связи*:

P0: local_max₀ ──────┐  
P1: local_max₁ ──────┤─ Allreduce(MPI_MAX) ─→ global_max (во всех процессах)  
P2: local_max₂ ──────┤  
P3: local_max₃ ──────┘  

6. **Запись результата**

```cpp
GetOutput() = global_max;
```
## 5. Детали реализации

**Генерация тестовых данных**

- Для создания тестовой матрицы используется линейный конгруэнтный генератор (ЛКГ) - алгоритм для генерации псевдослучайных чисел.

**Алгоритм ЛКГ**:

```cpp
for (size_t i = 0; i < total; ++i) {
      state = (a * state + c) % m;
      double value = (static_cast<double>(state) / m) * 1000.0;
      matrix.push_back(value);

      max_val = std::max(value, max_val);
    }
```

где:

- `state` - текущее состояние генератора  
- `a` - множитель (1664525)
- `c` - приращение (1013904223)
- `m` - модуль (2²² = 4194304)

**Процесс генерации**: 

1. Начинаем с начального состояние `state = 42`
2. Для каждого элемента матрицы:  
    - Вычисляем новое состояние по формуле ЛКГ  
    - Преобразуем в число от 0 до 1000
    - Сохраняем в матрице
    - Сравниваем с текущим максимумом

**Преимущества для тестирования**:

- Генерирует одинаковые данные на всех процессах

- Быстрый и простой алгоритм

- Предсказуемый результат для проверки правильности

Таким способом создается матрица 5000×10000 элементов (50 миллионов чисел) с известным максимальным значением для проверки работы алгоритма.


## 6. Экспериментальная среда
- Hardware/OS: AMD RYZEN 5 5600 6-Core Processor, 12-Threads, 16GB, Windows OS
- Toolchain: GCC 14.1.0, cmake version 3.31.1, Release
- Data: происходит генерация данных через функцию, описанную в пункте 5

## 7. Результаты и обсуждение

### 7.1 Корректность
**Модульные тесты**

В коде реализовано 3 тестовых случая:

- Тест 1: Матрица 3×4 с положительными числами (максимум = 12)

- Тест 2: Матрица 3×3 с отрицательными числами (максимум = -2)

- Тест 3: Матрица 5×5 со смешанными значениями (максимум = 4123412)

**Сравнение с эталонным результатом**

- При тестировании производительности генерируется матрица 5000×10000 элементов

- Во время генерации вычисляется и сохраняется ожидаемый максимум (`expected_result_`)

- Результат параллельного алгоритма сравнивается с эталонным значением

**Проверка инвариантов**
- ValidationImpl() проверяет корректность входных данных:

    - Размеры матрицы в допустимых пределах

    - Количество элементов соответствует заявленным размерам

    - Матрица не пустая

**Условие корректности**
 - Параллельная MPI-версия и последовательная SEQ-версия дают идентичные результаты

 - Все процессы в MPI-реализации получают одинаковый глобальный максимум

Таким образом, корректность подтверждается совпадением результатов с эталонными значениями, успешным прохождением модульных тестов и идентичностью результатов разных реализаций алгоритма.

### 7.2 Производительность
Present time, speedup and efficiency. Example table:

| Mode        | Count | Time, s | Speedup | Efficiency |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 1.234   | 1.00    | N/A        |
| mpi         | 2     | 0.0171   | 1.76    | 88.0%      |
| mpi         | 4     | 0.0144   | 3.16    | 79.0%      |

Optionally add plots (use relative paths), and discuss bottlenecks and scalability limits.

## 8. Заключение
Summarize findings and limitations.

## 9. Источники
1. <Article/Book/Doc URL>
2. <Another source>


