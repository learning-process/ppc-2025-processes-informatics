# Максимальное значение элементов матрицы

- Студент: Фатехов Камиль Гаярович, группа 3823Б1ФИ3
- Технология: SEQ | MPI
- Вариант: 13

## 1. Введение
**Цель лабораторной**: 
Разработка последовательной и параллельной версии поиска максимального значения элементов матрицы с последующим сравнением этих двух версий.

**Задачи лабораторной**:  
    - Реализовать последовательную версию поиска максимального значения элементов матрицы.  
    - Изучить основы MPI и реализовать параллельную версию программы.  
    - Сравнить эти производительность и эффективность этих реализаций
## 2. Постановка задачи
**Задача**: Определить максимальное значение элементов матрицы

**Входные данные**  
    Данные представлены в виде `tuple(rows, columns, matrix)`, где:  
    - `rows` - количество строк матрицы (*size_t*)  
    - `columns` - количество столбцов матрицы (*size_t*)  
    - `matrix` - непосредственно сама матрица (*vector*)

**Выходные данные**
На выходе получается единичное значение типа *double* - максимальный элемент в матрице.  

**Ограничения**:  
    - `rows <= 10000`  
    - `cols <= 10000` 
 

## 3. Базовый алгоритм (Последовательный)

 **Реализован следующий код**:
```cpp 
bool FatehovKMatrixMaxElemSEQ::RunImpl() {
  auto &data = GetInput();
  size_t rows = std::get<0>(data);
  size_t columns = std::get<1>(data);
  std::vector<double>& matrix = std::get<2>(data);
  double max = matrix[0];
  for (size_t i = 0; i < rows * columns; i++) {
    max = std::max(matrix[i], max);
  }
  GetOutput() = max;
  return true;
}
```

**Алгоритм работы**:  
1. Получаем входные данные: количество строк (rows), количество столбцов (columns) и ссылку на матрицу, записанную в виде одномерного вектора, хранящего элементы построчно

2. Инициализируем максимум: присваиваем переменной max значение первого элемента матрицы

3. Последовательно перебираем элементы: через цикл проходим по всем элементам матрицы

4. Сравниваем и обновляем результат: если элемент больше чем текущий максимумом, обновляем значение max

5. Возвращаем результат: записываем найденное максимальное значение в выходные данные  

## 4. Схема распараллеливания

**Описание**:  
- Код реализует параллельный поиск максимального элемента в матрице с использованием MPI. Данные распределяются блоками по процессам, каждый процесс находит локальный максимум, а затем все процессы объединяют свои результаты чтобы найти общий максимум.

**Алгоритм работы**:  

1. **Инициализация и получение данных**

```cpp
auto &data = GetInput();
size_t rows = std::get<0>(data);
size_t columns = std::get<1>(data);
std::vector<double>& matrix = std::get<2>(data);
```

2. **MPI инициализация**
```cpp
int world_rank = 0;
int world_size = 0;
MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
MPI_Comm_size(MPI_COMM_WORLD, &world_size);  
```

3. **Распределение данных**  

*Схема распределения*:  

Всего элементов: `N = rows × columns `   
Базовое количество на процесс: `elems_per_proc = N / world_size`  
Остаток: `remainder = N % world_size`   

*Формула распределения*:  

```cpp
size_t start = (world_rank * elems_per_proc) + std::min(world_rank, static_cast<int>(remainder));
  size_t end = start + elems_per_proc + (std::cmp_less(world_rank, remainder) ? 1 : 0);
```

*Пример (4 процесса, 10 элементов)*:

Процесс 0: start=0, end=3 (3 элемента)  
Процесс 1: start=3, end=6 (3 элемента)    
Процесс 2: start=6, end=8 (2 элемента)  
Процесс 3: start=8, end=10 (2 элемента)  

4. **Локальные вычисления**

```cpp
double local_max = -std::numeric_limits<double>::max();
for (size_t i = start; i < end; i++) {
    local_max = std::max(matrix[i], local_max);
  }
```
5. **Объединение локальных максимумов и поиск общего глобального**
```cpp
MPI_Allreduce(&local_max, &global_max, 1, MPI_DOUBLE, MPI_MAX, MPI_COMM_WORLD);
```

*Схема связи*:
```
P0: local_max₀ ──────┐  
P1: local_max₁ ──────┤─ Allreduce(MPI_MAX) ─→ global_max (во всех процессах)  
P2: local_max₂ ──────┤  
P3: local_max₃ ──────┘  
```
6. **Запись результата**

```cpp
GetOutput() = global_max;
```
## 5. Детали реализации

### **Генерация тестовых данных**

Для создания тестовой матрицы используется линейный конгруэнтный генератор (ЛКГ) - алгоритм для генерации псевдослучайных чисел.

**Алгоритм ЛКГ**:

```cpp
for (size_t i = 0; i < total; ++i) {
      state = (a * state + c) % m;
      double value = (static_cast<double>(state) / m) * 1000.0;
      matrix.push_back(value);

      max_val = std::max(value, max_val);
    }
```

где:

- `state` - текущее состояние генератора  
- `a` - множитель (1664525)
- `c` - приращение (1013904223)
- `m` - модуль (2²² = 4194304)

**Процесс генерации**: 

1. Начинаем с начального состояние `state = 42`
2. Для каждого элемента матрицы:  
    - Вычисляем новое состояние по формуле ЛКГ  
    - Преобразуем в число от 0 до 1000
    - Сохраняем в матрице
    - Сравниваем с текущим максимумом

**Преимущества для тестирования**:

- Генерирует одинаковые данные на всех процессах

- Быстрый и простой алгоритм

- Предсказуемый результат для проверки правильности

Таким способом создается матрица 5000×10000 элементов (50 миллионов чисел) с известным максимальным значением для проверки работы алгоритма.


## 6. Экспериментальная среда
- Hardware/OS: AMD RYZEN 5 5600 6-Core Processor, 12-Threads, 16GB, Ubuntu (DevContainer/WSL 2.0)
- Toolchain: GCC 14.1.0, cmake version 3.31.1, Release
- Data: происходит генерация данных через функцию, описанную в пункте 5

## 7. Результаты и обсуждение

### 7.1 Корректность
**Модульные тесты**

В коде реализовано 3 тестовых случая:

- Тест 1: Матрица 3×4 с положительными числами (максимум = 12)

- Тест 2: Матрица 3×3 с отрицательными числами (максимум = -2)

- Тест 3: Матрица 5×5 со смешанными значениями (максимум = 4123412)

**Сравнение с результатом**

- Результат алгоритма сравнивается с истинным значением, которое было вычислено заранее  (`expected_result_`)

**Условие корректности**
 - Параллельная MPI-версия и последовательная SEQ-версия дают идентичные результаты

 - Все процессы в MPI-реализации получают одинаковый глобальный максимум

Таким образом, корректность подтверждается совпадением результатов с эталонными значениями, успешным прохождением модульных тестов и идентичностью результатов разных реализаций алгоритма.

### 7.2 Производительность
- При тестировании производительности генерируется матрица 5000×10000 элементов
- Во время генерации вычисляется и сохраняется ожидаемый максимум

| **Режим** | **Количество процессов** | **Время, с** | **Ускорение** | **Эффективность** |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 0.0509   | 1.00    | N/A        |
| mpi         | 2     | 0.0171   | 2.98    | 149.0%      |
| mpi         | 4     | 0.0144   | 3.53    | 88.25%      |
| mpi         | 6     | 0.0136   | 3.74    | 62.37%      |


## 8. Заключение
В ходе лабораторной работы были реализованы последовательная и параллельная версии алгоритма поиска максимального элемента в матрице.

Основные выводы:

- Параллельная MPI-реализация показала ускорение только при использовании 2-4 процессов

- При увеличении числа процессов свыше 4 наблюдается снижение эффективности из-за накладных расходов MPI

Для простых операций (поиск максимума) накладные расходы параллелизации могут превышать выгоду от распараллеливания

## 9. Источники
[Линейный конгруэнтный генератор](https://www.tutorialspoint.com/cplusplus-program-to-implement-the-linear-congruential-generator-for-pseudo-random-number-generation)



