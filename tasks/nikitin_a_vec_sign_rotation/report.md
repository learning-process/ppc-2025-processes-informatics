# <Нахождение числа чередований знаков значений соседних элементов вектора>

- Студент: Никитин Антон Александрович, группа 3823Б1ФИ1
- Технология: SEQ, MPI
- Вариант: 5

## 1. Введение
В данной работе рассматривается задача подсчёта количества чередований знаков (смены знака между соседними элементами) в векторе вещественных чисел. Такая задача может возникать, например, при анализе сигналов, обработке временных рядов или статистических данных. Цель работы — реализовать последовательную и параллельную (на основе MPI) версии алгоритма, сравнить их производительность и оценить эффективность распараллеливания.

## 2. Постановка задачи
Задача: Нахождение числа чередований знаков значений соседних элементов вектора.
Дано: вектор V из N чисел типа double.
Требуется: определить количество пар соседних элементов (V[i], V[i+1]), у которых знаки различны (положительный → отрицательный или отрицательный → положительный). Знак нуля считается положительным.
Формат ввода/вывода:

Вход: std::vector<double>

Выход: целое число — количество чередований знаков.
Ограничения: алгоритм должен корректно обрабатывать пустые векторы, векторы из одного элемента, нулевые значения (в контексте задачи принимается положительным) и большие объёмы данных.


## 3. Базовый алгоритм (Последовательный)
Алгоритм последовательно проходит по всем элементам вектора, начиная со второго, и сравнивает знак текущего элемента со знаком предыдущего. При обнаружении смены знака увеличивается счетчик чередований.

## 4. Схема распараллеливания
Используется модель «ведущий–ведомые» (master–worker):
Rank 0 (ведущий процесс):
1. Читает входной вектор.
2. Разделяет данные на блоки для каждого рабочего процесса.
3. Отправляет каждому рабочему процессу его блок (с перекрытием в один элемент для проверки границ).
4. Собирает частичные суммы от рабочих процессов и выводит общий результат.
Rank 1..P-1 (рабочие процессы):
1. Получают размер и данные своего блока.
2. Подсчитывают чередования знаков внутри блока.
3. Отправляют результат ведущему процессу.

Схема коммуникации:
MPI_Bcast — для рассылки числа процессов.
MPI_Send/MPI_Recv — для передачи блоков данных и результатов.

## 5. Детали реализации
Структура проекта:
common.hpp — общие определения типов.
ops_seq.hpp/cpp — последовательная версия.
ops_mpi.hpp/cpp — MPI‑версия.
main.cpp — функциональные и производительные тесты.

Ключевые классы:
NikitinAVecSignRotationSEQ — последовательная реализация.
NikitinAVecSignRotationMPI — параллельная реализация.

Обработка краевых случаев:
Пустой вектор → результат 0.
Один элемент → результат 0.
Нулевые значения считаются положительными.

## 6. Экспериментальная установка
Оборудование:
Процессор: Intel Core i7‑10750H (6 ядер, 12 потоков)
Оперативная память: 16 ГБ DDR4
ОС: Ubuntu 22.04.3 LTS

Инструменты:
Компилятор: GCC 11.4.0
Сборка: Release (-O3)
MPI: OpenMPI 4.1.2
Тестовый фреймворк: GoogleTest

Тестовые данные:
Векторы размером от 0 до 50 000 000 элементов.
Данные генерируются случайным образом в диапазоне [-1000.0, 1000.0].
Относительные пути к данным: test_data/ (используются в тестах).

Переменные окружения:
PPC_NUM_PROC — количество MPI‑процессов (2, 4, 6, 8).

## 7. Результаты и обсуждение

### 7.1 Корректность
Корректность проверяется набором функциональных тестов:
Простые чередования.
Все положительные/отрицательные.
Наличие нулей.
Пустой вектор.
Дробные и граничные значения.

Все тесты проходят для обеих реализаций (SEQ и MPI). Для MPI‑процессов с rank ≠ 0 выходное значение устанавливается в -1 и не проверяется.

### 7.2 Производительность

| Режим | Процессы | Время, с | Ускорение | Эффективность |
|-------|----------|----------|-----------|---------------|
| SEQ   | 1        | 0.289    | 1.00      | N/A           |
| MPI   | 1        | 0.286    | 1.01      | 101%          |
| MPI   | 2        | 0.271    | 1.07      | 53.5%         |
| MPI   | 4        | 0.210    | 1.37      | 34.3%         |
| MPI   | 8        | 0.224    | 1.29      | 16.1%         |

Уточнение: В качестве времени выполнения программы берется только вычислительное ядро алгоритма (метрика task_run), исключая накладные расходы на инициализацию.

Ключевые наблюдения:
Ограниченное ускорение: Максимальное ускорение 1.37× достигается при 4 процессах
Низкая эффективность: Эффективность быстро падает с 101% (1 процесс) до 16.1% (8 процессов)
Пик при 4 процессах: Дальнейшее увеличение процессов ухудшает производительность
Коммуникационные издержки: Распределение большого объема данных доминирует над вычислениями
Задача коммуникационно-ограниченная: Простота операций сравнения не компенсирует затраты на передачу данных

## 8. Выводы
Задача подсчета чередований знаков в векторе чисел является малопригодной для эффективного распараллеливания с использованием MPI. Простота вычислительных операций не компенсирует значительные затраты на межпроцессное взаимодействие, делая параллельную реализацию практически неэффективной для реального применения. Для подобных задач с высокой интенсивностью обмена данными и низкой вычислительной сложностью на элемент более целесообразно использовать другие подходы к параллелизации.

## 9. Ссылки
1. [Открытая документация MPI](https://www.open-mpi.org/doc/) 
2. Лекции и практические занятия по предемту "Параллельное программирование" ННГУ
3. [cppreference.com](https://en.cppreference.com/)
