# Отчет по лабораторной работе №3
## "Алгоритм глобального поиска (Стронгин)"

**Студент:** Шеленкова Мария Сергеевна  
**Группа:** 3823Б1ФИ1  
**Вариант:** 11

### 1. Введение
**Мотивация.** Задачи глобальной оптимизации встречаются в инженерных расчётах и моделировании. Анализ алгоритма Стронгина с параллельной поддержкой позволяет оценить возможности масштабирования.  
**Проблематика.** Большая доля коммуникаций может нивелировать преимущества распараллеливания, особенно при дешёвой функции отклика.  
**Ожидаемый результат.** При лёгких функциях значимого ускорения не планировалось; цель эксперимента — подтвердить корректность параллельной схемы и оценить характер накладных расходов.

### 2. Постановка задачи
**Задано:** отрезок `[left, right]`, параметры `reliability`, `epsilon`, ограничение `max_iterations` и однопараметрическая функция.  
**Требуется:** найти точку глобального минимума и соответствующее значение функции.  
**Входные данные:** структура `InType` с границами, параметрами и функциональным объектом.  
**Выходные данные:** структура `OutType` (`best_point`, `best_value`, `iterations`).

### 3. Последовательный алгоритм
1. Формируется набор точек из концов отрезка и их значений.
2. На каждой итерации выбирается интервал с минимальными значениями на концах (при равенстве — наиболее длинный).  
3. В середину выбранного интервала добавляется новая точка; если интервал короче `epsilon` или точка уже присутствует, выполнение останавливается.  
4. Минимум обновляется по всем накопленным точкам, увеличивается счётчик итераций.  
Алгоритм представляет собой упрощённую модификацию Стронгина, обеспечивающую стабильную сходимость без сложных характеристик.

### 4. Схема распараллеливания
**Декомпозиция данных.** Интервалы между соседними точками распределяются между процессами. Каждый процесс вычисляет локальный кандидат на разбиение.  
**Коммуникация.** С помощью `MPI_Allreduce` определяется лучший интервал; корневой процесс вычисляет новую точку и рассылает обновлённое состояние через `MPI_Bcast`.  
**Синхронизация.** На каждом шаге выполняется одна глобальная редукция и одна рассылка.

### 5. Экспериментальная установка
* Процессор: 13th Gen Intel(R) Core(TM) i9-13980HX (24 физических ядра, 32 логических потока).
* Оперативная память: 32 GB.
* Операционная система: Microsoft Windows 11 Pro.
* Компилятор: MSVC 19.40, конфигурация Release x64.
* MPI-библиотека: Microsoft MPI 10.1.12498.52.

### 6. Результаты и обсуждение
#### 6.1. Корректность
Функциональные тесты запускались командой `ppc_func_tests.exe --gtest_filter=*global_search_strongin*`. Проверка включала квадратичную функцию, синусоидальный профиль и кусочную функцию; отличий между реализациями не выявлено.

#### 6.2. Производительность
Замеры выполнялись утилитой `ppc_perf_tests.exe`. Последовательная версия работала на одном процессе, MPI-версия — на восьми (`mpiexec -n 8`).

| Реализация | Процессов | Режим теста | Время, сек |
|-----------:|----------:|-------------|-----------:|
| seq        | 1         | pipeline    | 0.0000363 |
| seq        | 1         | task_only   | 0.0000083 |
| mpi        | 8         | pipeline    | 0.0009418 |
| mpi        | 8         | task_only   | 0.0001938 |

Выполненные измерения подтверждают, что на функциях с низкой вычислительной стоимостью коммуникационные накладные расходы превышают возможный выигрыш от параллелизма.

### 7. Выводы
Алгоритм обеспечивает корректный поиск глобального минимума и демонстрирует ожидаемое поведение производительности. Параллельная схема пригодна для задач с высокой стоимостью вычисления функции, тогда как на лёгких функциях рациональнее использовать последовательную реализацию.
