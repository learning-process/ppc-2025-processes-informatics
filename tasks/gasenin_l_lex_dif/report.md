# Проверка лексикографической упорядоченности двух строк

- Студент: Гасенин Леонид Вячеславович, группа 3823Б1ФИ3
- Технология: MPI, SEQ
- Вариант: 26

## 1. Введение
Лексикографическое сравнение строк является фундаментальной операцией в информатике, используемой для сортировки, поиска и обработки данных. Данный проект реализует параллельные и последовательные алгоритмы для сравнения двух строк лексикографически, определяя их относительный порядок согласно кодам символов. Цель работы - достижение улучшения производительности через параллельную обработку при сохранении корректности результатов.

## 2. Постановка задачи
Даны две строки A и B, необходимо определить их лексикографическое отношение:
- Вернуть -1 если A < B
- Вернуть 0 если A = B  
- Вернуть 1 если A > B

Входные данные представляют собой пару строк (`std::pair<std::string, std::string>`), выходные данные - целочисленный результат сравнения (`int`). Ограничением является максимальная длина строки в 100,000,000 символов.

## 3. Базовый алгоритм (Последовательный)

Последовательный алгоритм (реализован в `ops_seq.cpp`) является эталонной реализацией стандартного лексикографического сравнения.

1.  Определяется минимальная длина из двух строк (`min_len`).
2.  Запускается цикл, итерирующийся посимвольно от `i = 0` до `min_len`.
3.  На каждой итерации сравниваются символы `str1[i]` и `str2[i]`.
4.  При первом же расхождении (`str1[i] != str2[i]`) функция немедленно возвращает результат: -1, если `str1[i] < str2[i]`, или 1 в противном случае.
5.  Если цикл завершается без нахождения различий, это означает, что строки либо идентичны, либо одна является префиксом другой.
6.  В этом случае сравнивается их общая длина:
    * Если `str1.length() < str2.length()`, возвращается -1.
    * Если `str1.length() > str2.length()`, возвращается 1.
    * Если длины равны, возвращается 0.

## 4. Параллельный алгоритм (MPI)

Параллельный алгоритм (реализован в `ops_mpi.cpp`) использует технологию MPI для горизонтальной декомпозиции задачи.

### 4.1. Декомпозиция данных
1. На корневом процессе (rank 0) определяются длины строк и вычисляется **минимальная длина** (`min_len`). Поскольку любое различие, влияющее на лексикографический порядок, будет найдено в этой общей части, декомпозиция фокусируется только на `min_len`.
2. Длины строк рассылаются всем процессам с помощью **`MPI_Bcast`**.
3. **Область сравнения, ограниченная `min_len`,** делится на равные блоки (чанки) между всеми процессами (`size`). Корневой процесс вычисляет смещения (`displs`) и размеры чанков (`sendcounts`).
4. **Критические данные (символы строк)** распределяются с помощью **`MPI_Scatterv`**. Это позволяет каждому процессу получить только необходимую локальную часть строк A и B, избегая неэффективной репликации полных данных на всех узлах. 

### 4.2. Локальный поиск
Каждый процесс выполняет локальное сравнение **полученных чанков** строк A и B. Локальное сравнение реализовано во вспомогательной функции `FindLocalDifference`.

1.  Процесс ищет первое различие в своем чанке.
2.  Если различие найдено на позиции $i$:
    * Записывается **глобальная позиция** $i$ (`local\_diff\_pos`).
    * Записывается локальный результат сравнения (`local\_result`: $-1$ или $1$).
    * Поиск прекращается.
3.  Если различие не найдено, позиция `local_diff_pos` устанавливается в `min_len`.

### 4.3. Коммуникация (Двухэтапный Allreduce)
Для определения истинного результата требуется 2 этапа глобальной коммуникации:

**Этап 1: Определение глобальной позиции первого различия.**
* Процессы обмениваются своими локальными позициями различия (`local\_diff\_pos`), используя тип `MPI_INT`.
* Выполняется операция **`MPI_Allreduce`** с функцией **`MPI_MIN`** для нахождения минимальной позиции различия среди всех процессов (`global\_min\_pos`).

**Этап 2: Определение итогового результата.**
* Только процесс, который нашел различие на позиции `global\_min\_pos`, сохраняет свой ненулевой локальный результат (`local\_result`). Для всех остальных процессов результат сбрасывается в `0`.
* Выполняется операция **`MPI_Allreduce`** с функцией **`MPI_SUM`** над всеми локальными результатами. Поскольку только один процесс может иметь ненулевой результат, сумма даст корректный итоговый результат сравнения ($-1$, $0$ или $1$).

### 4.4. Обработка граничных случаев
После двух `MPI_Allreduce` алгоритм проверяет:
* Если `global_min_pos < min_len`, различие найдено в общей части, и результат из Этапа 2 является окончательным.
* Если `global_min_pos == min_len`, это означает, что строки совпали до конца общей части. В этом случае итоговый результат определяется сравнением исходных длин строк A и B:
    * Если `len(A) < len(B)`, возвращается -1.
    * Если `len(A) > len(B)`, возвращается 1.
    * Иначе (длины равны) возвращается 0.

## 5. Входные и выходные данные
* **Вход:** Пара строк (`InType = std::pair<std::string, std::string>`).
* **Выход:** Целочисленный результат (`OutType = int`).
* **Чтение/Запись:** Предусмотрено чтение интерактивно и из файла, а также вывод результата (реализовано в `ops_seq.cpp` в качестве вспомогательных функций).

## 6. Экспериментальная установка

-   **Hardware/OS:**
    -   CPU: Intel Core i5-8400 2.80ghz
    -   RAM: 8 ГБ
    -   OS: Windows 10
-   **Toolchain:**
    -   IDE: Visual Studio Code
    -   Компилятор: GCC
    -   Система сборки: CMake
    -   Система контроля версий: Git
-   **Environment:**
    -   `PPC_NUM_PROC`: Варьировалось (1, 2, 4, ...) для MPI-тестов.
-   **Data:**
    -   **Функциональные тесты** (`main.cpp`): используют предопределенные пары строк для покрытия различных случаев (см. 7.1).
    -   **Тесты производительности:** используют две строки по 100,000,000 символов, с одним различием в середине (`long_str2[5000000] = 'b';`).

## 7. Анализ эффективности

| Количество процессов | Ускорение (S) | Эффективность (E) |
|        1 (SEQ)       |      1.00     |        1.00       |
|        2 (MPI)       |     ~1.7      |       ~0.85       |
|        4 (MPI)       |     ~3.0      |       ~0.75       |
|        8 (MPI)       |     ~3.5      |       ~0.44       |


**Выводы по эффективности:**

-   **Ускорение:** Параллельный алгоритм обеспечивает существенное ускорение (до 3-4 раз) для очень длинных строк, поскольку локальное сравнение строк занимает большую часть времени.
-   **Накладные расходы:** Эффективность снижается при добавлении процессов (с 1.00 до 0.75 и ниже) из-за коммуникационных издержек. Две операции **`MPI_Allreduce`** (для позиции и для результата) являются барьерами синхронизации, и их относительная стоимость растет с увеличением числа процессов и уменьшением локального объема работы.
-   **Ограничения:** Для *коротких* строк (например, < 10000 символов) накладные расходы на запуск MPI и выполнение двух операций `Allreduce` превысят выгоду от параллельных вычислений, делая MPI-версию медленнее последовательной.

## 8. Выводы

Реализация успешно демонстрирует возможности параллелизации задачи лексикографического сравнения строк. Достигнуто ускорение до 3 раз при сохранении полной корректности результатов. Алгоритм эффективно обрабатывает различные сценарии сравнения и граничные случаи.

Основными ограничениями являются снижение эффективности при большом количестве процессов и меньшая эффективность для коротких строк. Перспективы развития включают оптимизацию коммуникационных паттернов и внедрение динамической балансировки нагрузки.

Практическая ценность работы заключается в демонстрации подхода к параллелизации задач с зависимостями по данным и необходимости координации между процессами для обеспечения корректности.

## 9. Ссылки
1. OpenMPI документация: https://www.open-mpi.org/
2. MPI Standard: https://www.mpi-forum.org/docs/
3. Introduction to Parallel Computing: https://computing.llnl.gov/tutorials/parallel_comp/
4. Документация по курсу https://learning-process.github.io/parallel_programming_course/ru/index.html