# Реализация операции Scatter с использованием биномиального дерева

**Студент:** Пиходский Роман Владимирович, 3823Б1ФИ1  
**Технология:** SEQ, MPI  
**Вариант:** 4

---

## 1. Введение

Коллективные операции являются важной частью интерфейса MPI, позволяя эффективно организовывать взаимодействие между процессами. Операция `Scatter` распределяет данные от корневого процесса всем остальным процессам в коммуникаторе. 

В данной работе реализована собственная версия операции `Scatter` с использованием алгоритма биномиального дерева, что позволяет оптимизировать коммуникационные паттерны и улучшить производительность в распределенных системах.

---

## 2. Постановка задачи

Необходимо реализовать параллельную функцию распределения данных, эквивалентную стандартной `MPI_Scatter`, со следующими требованиями:

**Входные параметры:**
- `source_buffer`: буфер с данными на корневом процессе
- `elements_to_send`: количество элементов для каждого процесса
- `send_data_type`: тип отправляемых данных
- `destination_buffer`: буфер для приема данных
- `elements_to_receive`: количество принимаемых элементов
- `root_process`: ранг корневого процесса
- `communicator`: коммуникатор MPI

**Ограничения реализации:**
- Использовать только `MPI_Send` и `MPI_Recv`
- Поддерживать типы: `MPI_INT`, `MPI_FLOAT`, `MPI_DOUBLE`
- Работать с любым корневым процессом
- Применять топологию "биномиальное дерево"

---

## 3. Базовый алгоритм (Последовательный)

Последовательная реализация служит для проверки корректности работы с памятью и предоставления эталона для сравнения:

1. **Валидация параметров:** проверка размеров и типов данных
2. **Определение размера элемента:** вычисление размера в байтах
3. **Копирование данных:** прямое копирование из исходного буфера
4. **Сохранение результата:** формирование выходного вектора

Алгоритм гарантирует корректное копирование данных для однопроцессорного выполнения.

---

## 4. Схема распараллеливания

Используется алгоритм **биномиального дерева** для оптимизации коммуникаций:

**Ключевые концепции:**
1. **Виртуальное ранжирование:** для работы с произвольным корнем
   `relative_rank = (rank - root + size) % size`

2. **Итеративный процесс:**
   - Начало: максимальная степень двойки < размера коммуникатора
   - Цикл с уменьшением шага вдвое на каждой итерации

3. **Логика распределения:**
   - Если `relative_rank % (2 * stride) == 0`: процесс - отправитель
   - Если `relative_rank % (2 * stride) == stride`: процесс - получатель

**Пример для 8 процессов:**
```
Шаг 1 (stride=4): 0 → 4
Шаг 2 (stride=2): 0 → 2, 4 → 6  
Шаг 3 (stride=1): 0 → 1, 2 → 3, 4 → 5, 6 → 7
```

---

## 5. Детали реализации

**Структура проекта:**
```
pikhotskiy_r_scatter/
├── common/include/common.hpp
├── seq/           # SEQ реализация
├── mpi/           # MPI реализация  
└── tests/         # Тесты
```

**Основные компоненты MPI реализации:**

1. **Класс `PikhotskiyRScatterMPI`:**
   - Наследование от базового класса задачи
   - Методы валидации, выполнения и постобработки

2. **Функция `ExecScatterCycle`:**
   - Реализация цикла биномиального дерева
   - Динамическое обновление указателей на данные

3. **Подготовка данных:**
   - Реорганизация буфера для произвольного корня
   - Эффективное копирование с минимальными накладными расходами

---

## 6. Экспериментальная установка

**Окружение**
- Процессор: AMD Ryzen 5 5500U (4 ядра)
- Память: 12 GB
- ОС: Ubuntu
- Компилятор: g++ 13.3.0

**Параметры тестирования:**
- Функциональные тесты: проверка корректности для разных типов и размеров
- Тесты производительности: 10 миллионов целых чисел на процесс

---

## 7. Результаты и обсуждение

### 7.1 Корректность
Все функциональные тесты успешно пройдены, подтверждая:
- Правильное распределение данных между процессами
- Корректную работу с разными типами данных
- Надежную обработку различных корневых процессов

### 7.2 Производительность
Результаты тестирования производительности:

| Конфигурация | Время (сек) | Эффективность |
|--------------|-------------|---------------|
| SEQ          | 0.0084      | 1.00x         |
| MPI (1 proc) | 0.0119      | 0.71x         |
| MPI (2 proc) | 0.0247      | 0.34x         |
| MPI (4 proc) | 0.0584      | 0.14x         |
| MPI (8 proc) | 0.2649      | 0.03x         |

**Анализ результатов:**
1. **SEQ vs MPI:** MPI версия медленнее из-за накладных расходов
2. **Рост времени:** Увеличение с ростом числа процессов в виртуальной среде
3. **Причины замедления:** Накладные расходы MPI, особенности виртуальной среды

---

## 8. Заключение

Реализована операция `Scatter` с использованием алгоритма биномиального дерева:

**Достигнутые результаты:**
- ✅ Корректная работа подтверждена тестами
- ✅ Поддержка требуемых типов данных
- ✅ Работа с любым корневым процессом
- ✅ Использование только `MPI_Send`/`MPI_Recv`

**Основной вывод:** Алгоритм биномиального дерева эффективен теоретически, но в виртуальной среде преимущества параллельных коммуникаций ограничены.

---

## 9. Литература

1. Message Passing Interface Forum. MPI Standard.
2. Gropp, W., et al. Using MPI: Portable Parallel Programming.
3. Документация OpenMPI.
4. Руководство GoogleTest.

---

## 10. Приложение

**Основной цикл алгоритма:**
```cpp
void ExecScatterCycle(int size, int root, int rank, int count,
                     MPI_Datatype type, size_t type_size,
                     const uint8_t*& active_ptr,
                     std::vector<uint8_t>& buffer) {
    
    int virt_rank = (rank - root + size) % size;
    int stride = GetInitialStride(size);
    
    for (; stride > 0; stride >>= 1) {
        if (virt_rank % stride != 0) continue;
        
        if (virt_rank % (stride*2) == 0) {
            // Отправитель
            SendData(virt_rank + stride);
        } else {
            // Получатель
            ReceiveData(virt_rank - stride);
        }
    }
}
```