# Количество несовпадений символов двух строк

**Студент:** Овсянников Никита Владимирович  
**Группа:** 3823Б1ФИ2  
**Технология:** SEQ, MPI  
**Вариант:** 27  

---

## 1. Introduction

Цель данной работы — освоить применение технологии **MPI** для распараллеливания вычислений.  
В качестве демонстрационного примера выбрана задача сравнения двух строк.

Несмотря на простоту самой задачи, она хорошо подходит для изучения принципов распределения данных между процессами и последующего объединения частичных результатов.

---

## 2. Problem Statement

Даны две строки одинаковой длины.  
Необходимо пройти по ним и определить количество позиций, на которых символы различаются.

**Входные данные:**  
- две строки (`std::string`)

**Выходные данные:**  
- целое число — количество несовпадений символов

---

## 3. Baseline Algorithm (Sequential)

В последовательной версии алгоритм выполняется простым линейным проходом по строкам.

```cpp
int mismatch_count = 0;
size_t n = seq_one.size();
for (size_t i = 0; i < n; ++i) {
    if (seq_one[i] != seq_two[i]) {
        mismatch_count++;
    }
}
```
Временная сложность алгоритма — O(N).

## 4. Parallelization Scheme

Параллельная версия алгоритма реализована с использованием технологии **MPI**.  
Основная идея распараллеливания заключается в разбиении входных данных между процессами и последующем объединении частичных результатов.

Алгоритм работы имеет следующую структуру:

1. Процесс с рангом `0` определяет длину входных строк.
2. Исходные строки разбиваются на непрерывные фрагменты в соответствии с количеством MPI-процессов.
3. Процесс `0` распределяет соответствующие фрагменты строк между процессами с использованием функции `MPI_Scatterv`.
4. Каждый процесс независимо подсчитывает количество несовпадений символов в своём фрагменте.
5. Локальные результаты суммируются в общий результат с помощью функции `MPI_Allreduce`.

---

## 5. Implementation Details

Реализация задачи разделена на несколько логических модулей:

- **common**  
  Содержит общие типы данных, используемые как в последовательной, так и в параллельной версиях алгоритма.

- **seq**  
  Последовательная реализация задачи, основанная на линейном проходе по строкам.

- **mpi**  
  Параллельная реализация с использованием MPI.  
  Для передачи данных между процессами используются буферы и коллективные операции обмена.

- **tests**  
  Набор функциональных и производительных тестов, предназначенных для проверки корректности и оценки производительности алгоритмов.

---

## 6. Experimental Setup

Экспериментальные измерения проводились на следующей вычислительной системе:

- **Процессор:** 13th Gen Intel Core i5-13500H  
  (12 ядер: 4 производительных и 8 энергоэффективных, тактовая частота 2.60 GHz)
- **Оперативная память:** 16 ГБ DDR5 (4266 MT/s)
- **Операционная система:** Windows 11
- **Компилятор:** MSVC
- **Конфигурация сборки:** Release

---

## 7. Results and Discussion

### 7.1 Correctness

Корректность реализации подтверждена с помощью функциональных тестов.  
Результаты, полученные в параллельной MPI-версии, полностью совпадают с результатами последовательной реализации для всех рассмотренных тестовых случаев, включая:

- пустые строки,
- полное совпадение строк,
- частичное совпадение символов.

---

### 7.2 Performance

Измерение производительности проводилось на строках длиной **100 000 000 символов**.

В качестве базового времени (`T_seq`) использовалось время работы последовательной версии алгоритма:

**T_seq = 0.1734 s**

| Mode | Processes | Time (s) | Speedup | Efficiency |
|:----:|:---------:|:--------:|:-------:|:----------:|
| seq  | 1         | 0.1734   | 1.00    | 100%       |
| mpi  | 2         | 0.3410   | 0.51    | 25.5%      |
| mpi  | 4         | 0.3304   | 0.52    | 13.0%      |
| mpi  | 8         | 0.2650   | 0.65    | 8.1%       |
| mpi  | 12        | 0.3064   | 0.56    | 4.7%       |
| mpi  | 24        | 0.8192   | 0.21    | 0.9%       |

---

## 8. Conclusions

На основании полученных экспериментальных результатов можно сделать следующие выводы:

1. **Отрицательное ускорение**  
   Параллельная версия алгоритма на базе MPI во всех протестированных конфигурациях демонстрирует замедление по сравнению с последовательной реализацией (Speedup < 1).

2. **Влияние накладных расходов**  
   Из-за крайне низкой вычислительной сложности операции сравнения символов затраты на передачу данных и синхронизацию процессов существенно превышают время полезных вычислений.

3. **Масштабируемость**  
   Наилучший результат достигнут при использовании 8 MPI-процессов, однако даже в этом случае производительность уступает последовательной версии.

4. **Эффект переподписки**  
   При запуске с числом процессов, превышающим количество аппаратных потоков процессора, наблюдается резкое ухудшение производительности, вызванное частыми переключениями контекста и потерей кэш-локальности.

---

## 9. References

1. Лекции и практические материалы курса «Параллельное программирование».
