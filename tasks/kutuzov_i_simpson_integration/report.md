# Вычисление многомерных интегралов с использованием многошаговой схемы (метод Симпсона).

- Student: Кутузов Иван Арсеньевич, group 3823Б1ФИ3
- Technology: SEQ | MPI 
- Variant: 9

## 1. Introduction

Мотивация: Двумерные численные интегралы широко применяются в физических и инженерных задачах. Даже для двумерного случая при высокой точности вычисления могут быть вычислительно затратными, поэтому использование параллельных методов позволяет существенно сократить время расчёта.

Проблема: Последовательные алгоритмы численного интегрирования для двумерных интегралов плохо масштабируются при увеличении числа разбиений сетки. Требуется эффективная параллельная реализация многошаговой схемы.

Ожидаемый результат: Получение корректного и быстрого параллельного алгоритма вычисления двумерного интеграла с ускорением относительно последовательной версии.

## 2. Problem Statement

$$
I = \int_{a}^{b} \int_{c}^{d} f(x, y) , dx , dy.
$$

Функция $f(x, y)$ считается непрерывной на области интегрирования. Для численного решения используется многошаговая схема с равномерной сеткой по осям $x$ и $y$.

Входные данные:
* $n$ - число ячеек сетки по одной оси (общая сетка $n \times n$ ячеек);
* $x_{min} - x_{max}$ - начало и конец области интегрирования по оси $x$;
* $y_{min} - y_{max}$ - начало и конец области интегрирования по оси $y$;
* Функция $f(x)$;

В качестве функции подаётся `function_id`, определяющий какую из 4-х заготовленных функций использовать.

Результатом является приближённое значение определённого интеграла $I$.


## 3. Baseline Algorithm (Sequential)
SEQ реализация использует двойной цикл по координатам сетки. В каждой точке вычисляется значение функции, которое добавляется к общей сумме с учётом весов численной схемы. Итоговая сумма умножается на $\dfrac{\Delta x \cdot \Delta y}{9}$, где $\Delta x$ и $\Delta y$ - размеры ячейки сетки по соответствующим осям.

## 4. Parallelization Scheme
MPI реализация выполняется в 3 основных этапа:
1. **Рассылка данных:** входные данные рассылаются с процесса с рангом 0 на остальные процессы при помощь `MPI_Bcast`.
2. **Параллельное решение:** параллелизм применяется к внешнему циклу обхода сетки. Каждый процесс вычисляет начало и конец своего участка индексов по следующему прицнипу: каждому из $n$ процессов раздаются равные интервалы индексов. Остаток $r$, $r < n$ раздаётся первым $r$ процессам поровну (то есть по одному доп. индексу). Реализация выполнена так, что индексы, выданные на обработку одному процессу, идут подряд. Затем процессы выполняют свою часть вычислений аналогично последовательному алгоритму, суммируя результат в `local_sum` - локальную сумму.
3. **Сбор результатов:** при помощи вызова `MPI_Reduce` значения из `local_sum` со всех процессов суммируются в переменной `sum` на процессе с рангом 0. Затем результат домножается на $\dfrac{\Delta x \cdot \Delta y}{9}$ и рассылается на остальные процессы для прохождения проверок корректности.

## 5. Experimental Setup
* Hardware/OS: 12th gen Intel(R) Core(TM) i5-12500H, 12 ядер, 32 GB RAM, Windows 11 x64, laptop;
* Toolchain: compiler, version, build type (Release/RelWithDebInfo)
    * Cmake 3.28.3
    * Компилятор: g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    * Использовался Docker-контейнер.
    * Режим сборки: Release.

## 6. Results and Discussion
### 6.1 Correctness
Корректность проверена при помощи модульного тестирования, реализованного с использованием библиотеки GoogleTest с значением $n$, на различных размерах области интегрирования и на различных функциях.

### 6.2 Performance

Измерение производительности происводилоось на задаче подсчёта интеграла функции
```c++
double f(double x, double y) {
  double sum = 0.0;
  for (int i = 1; i <= 200; i++) {
    double add = (sin(0.3 * pow(x * i, 4) * pow(y, 2) + 0.5 * cos(y / i) * pow(x, 7) + 1.8 * pow(y, 5)));
    if (i % 2 == 0) {
      sum += add;
    } else {
      sum -= add;
    }
  }
  return sum;
}
```
на области интегрирования $x_{min} = y_{min} = -10, \ \ \ x_{max} = y_{max} = 10$, при $n = 5$.

| Mode | Process count | Time, s | Speedup  | Efficiency |
| -    | -             | -       | -        | -          |
| seq  | 1             | 8.948   | 1.000    | N/A        |
| mpi  | 2             | 4.521   | 1.979    | 98.9%      |
| mpi  | 3             | 3.099   | 2.887    | 96.2%      |
| mpi  | 4             | 2.355   | 3.799    | 94.9%      |
| mpi  | 5             | 2.213   | 4.043    | 80.8%      |
| mpi  | 6             | 1.949   | 4.591    | 76.5%      |

С ростом числа процессов от одного до четырёх наблюдается ускорение близкое к идеальному. При большем увеличении числа процессов накладные расходы на рассылку и сбор данных перевешивают, и эффективность параллелизма снижается.


## 7. Conclusions
В работе рассмотрено вычисление двумерного интеграла с использованием многошаговой численной схемы. Параллельный алгоритм позволяет значительно сократить время вычислений при сохранении корректности результатов.

## 8. References
* "Параллельное программирование для кластерных систем" ННГУ им. Лобачевского, ИИТММ.