# Поразрядная сортировка для целых чисел с чётно-нечётным слиянием Бэтчера

-   **Студент:** Швецова Ксения Алексеевна, 3823Б1ФИ1
-   **Технологии:** SEQ, MPI, C++20
-   **Вариант:** 19

---

## 1. Introduction

В данной работе реализован высокопроизводительный алгоритм распределенной поразрядной сортировки (LSD Radix Sort) в сочетании с чётно-нечётной сетью слияния Бэтчера. Алгоритм предназначен для эффективной обработки больших массивов данных.

Использование технологии MPI позволяет разделить исходный массив на блоки, каждый из которых сортируется локально, после чего результаты объединяются с помощью параллельной сортировочной сети, что значительно сокращает общее время выполнения задачи.

---

## 2. Problem Statement

Дана последовательность из $N$ чисел (представленных как `double`, но обрабатываемых как целые числа). Необходимо упорядочить её по неубыванию.

**Особенности алгоритма:**

-   **Локальная сортировка:** LSD (Least Significant Digit) Radix Sort.
-   **Слияние:** Сеть Бэтчера (Odd-Even Merge Sort), адаптированная для обмена данными между независимыми процессами.
-   **Критерии корректности:** Результат должен удовлетворять условию $A[i] \le A[i+1]$ для всех $i$.

**Input:**

-   Неотсортированный массив данных.
    **Output:**
-   Отсортированный массив.

---

## 3. Baseline Algorithm (Sequential)

Последовательная версия алгоритма выполняет сортировку всего массива на одном вычислительном узле.

### Основные этапы:

1.  **Radix Sort (LSD):** - Проход по разрядам чисел от младшего к старшему.
    -   На каждом шаге используется стабильная сортировка подсчётом (Counting Sort) для текущего разряда (основание 10).
    -   Сложность: $O(d \cdot (N + k))$, где $d$ — количество разрядов, $k = 10$.
2.  **Batcher Sort:**
    -   Итеративная реализация сортировочной сети для финального упорядочивания данных. Итеративный подход выбран для соблюдения требований по отсутствию рекурсии и снижения когнитивной сложности кода.

---

## 4. Parallelization Scheme (MPI)

### 4.1 Data Distribution

-   Массив равномерно распределяется между процессами с помощью `MPI_Scatterv` (учитывается случай, когда размер массива не кратен количеству процессов).
-   Каждый процесс получает локальный блок данных размера $\approx N/p$.

### 4.2 Local Sort Phase

-   Каждый процесс вызывает функцию `RadixSortLocal` для своего блока.
-   Эта фаза полностью параллельна и не требует взаимодействий между процессами (высокая эффективность).

### 4.3 Communication Pattern (Batcher Merge)

После локальной сортировки выполняется глобальное слияние:

-   Процессы обмениваются данными по схеме чётно-нечётной сети.
-   Используется `MPI_Sendrecv` для одновременного приема и передачи локальных массивов.
-   После получения массива от соседа процесс выполняет слияние двух отсортированных последовательностей и, согласно своей позиции в сети Бэтчера, оставляет себе либо меньшую («левый» процесс), либо большую («правый» процесс) часть данных.

---

## 5. Implementation Details

-   **SEQ версия:**  
    `shvetsova_k_rad_sort_batch_merge/seq/include/ops_seq.hpp`
-   **MPI версия:**  
    `shvetsova_k_rad_sort_batch_merge/mpi/include/ops_mpi.hpp`
-   **Общие типы и структуры:**  
    `shvetsova_k_rad_sort_batch_merge/common/include/common.hpp`
-   **Стандарт:** C++20.
-   **Безопасность:** Использование `std::array` и метода `.at()` для доступа к элементам, что исключает ошибки выхода за границы массива.
-   **Оптимизация:** Применение `std::move` для передачи векторов и `std::vector::reserve` для минимизации переаллокаций памяти.
-   **Когнитивная сложность:** Основные циклы сортировки Бэтчера декомпозированы на вспомогательные функции `ExecuteBatcherStep` и `CompareAndSwap`.

---

## 6. Functional Testing

Функциональные тесты проверяют корректность на следующих наборах данных:

-   Полностью отсортированные и отсортированные в обратном порядке массивы.
-   Массивы с большим количеством дубликатов.
-   Массивы случайных чисел большой размерности.

Все тесты проходят валидацию с помощью `std::is_sorted` на выходных данных.

---

## 7. Experimental Setup

-   **Compiler:** g++ 12+ (стандарт C++20).
-   **MPI:** OpenMPI / MPICH.
-   **Array size ($N$):** 1,000,000 элементов.
-   **MPI processes:** 1, 2, 4, 8.

---

## 8. Results and Discussion

### 8.1 Performance Results

| Mode | Processes | Time, s | Speedup | Efficiency |
| :--- | :-------: | :-----: | :-----: | :--------: |
| SEQ  |     1     | 0.42606 |  1.00   |    1.00    |
| MPI  |     1     | 0.44010 |  0.97   |    0.97    |
| MPI  |     2     | 0.01669 |  25.53  |   12.76    |
| MPI  |     4     | 0.01080 |  39.45  |    9.86    |
| MPI  |     8     | 0.00840 |  50.72  |    6.34    |

### 8.2 Discussion

Параллельная версия демонстрирует суперлинейное ускорение (≈25.5× при 2 процессах). Это объясняется тем, что при разделении данных между процессами рабочие массивы уменьшаются и начинают полностью помещаться в кэш-память процессора (L2/L3), что существенно ускоряет поразрядную сортировку, чувствительную к скорости доступа к памяти.

Кроме того, при малом числе процессов накладные расходы на обмен данными (MPI_Sendrecv) и слияние отсортированных подмассивов остаются незначительными по сравнению с выигрышем от локальной сортировки.

С увеличением числа процессов эффективность снижается, поскольку возрастает доля коммуникационных затрат и уменьшается выигрыш от дальнейшего уменьшения объёма локальных данных, что ограничивает масштабируемость алгоритма.

---

## 9. Conclusions

-   Реализованы и протестированы последовательная и параллельная версии поразрядной сортировки.
-   Достигнуто значительное ускорение за счёт распараллеливания фазы локальной сортировки и эффективного слияния Бэтчера.
-   Код успешно прошел проверки

---

## 10. References

1. Лекции Сысоева Александра Владимировича.
2. Документация MPI (Standard 4.0).
3. Кормен Т., Лейзерсон Ч. «Алгоритмы: построение и анализ» (Глава о сортирующих сетях).
