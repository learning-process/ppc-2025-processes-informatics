# Отчёт по реализации многомерного интегрирования методом трапеций

**Дисциплина:** Параллельное программирование  
**Преподаватели:** Нестеров Александр Юрьевич, Оболенский Арсений Андреевич  
**Студент:** Фролова Софья Юрьевна, 3823Б1ФИ3  
**Вариант:** 8, Многомерное интегрирование методом трапеций

---

## Введение

В рамках данной лабораторной работы была реализована задача численного многомерного интегрирования функции. Была разработана как последовательная версия (SEQ), так и параллельная версия на основе MPI, использующая модель передачи сообщений для распределения вычислений между процессами.

Реализация интегрирована в инфраструктуру параллельных задач фреймворка PPC и обладает набором функциональных и производительных тестов.

---

## Постановка задачи

Требуется вычислить интеграл многомерной функции $f: \mathbb{R}^n \to \mathbb{R}$ на прямоугольной области:

$$I = \int_{a_1}^{b_1} \int_{a_2}^{b_2} \cdots \int_{a_n}^{b_n} f(x_1, x_2, \ldots, x_n) \, dx_1 \, dx_2 \cdots dx_n$$

где:
- $n$ — размерность интеграла;
- $[a_i, b_i]$ — пределы интегрирования по переменной $x_i$;
- $f(x_1, x_2, \ldots, x_n)$ — интегрируемая функция.

Входной тип: `TrapezoidalIntegrationInput` с полями:
- `limits` — вектор пар $(a_i, b_i)$ для каждой размерности;
- `number_of_intervals` — вектор количества интервалов разбиения для каждой размерности;
- `function` — указатель на функцию для интегрирования.

Выходной тип: `OutType = double` (значение вычисленного интеграла)

---

## Описание алгоритма метода трапеций

### Одномерный случай

Для одномерного интеграла $\int_a^b f(x) dx$ метод трапеций использует формулу:

$$I \approx \frac{b-a}{2n} \left[ f(x_0) + 2f(x_1) + 2f(x_2) + \cdots + 2f(x_{n-1}) + f(x_n) \right]$$

где $x_i = a + i \cdot \frac{b-a}{n}$, $i = 0, 1, \ldots, n$.

### Многомерный случай

Для многомерного интеграла применяется композиция одномерных формул трапеций. Каждой точке в сетке присваивается коэффициент $c_{i_1, i_2, \ldots, i_n}$ в зависимости от её положения:

$$c_{i_1, i_2, \ldots, i_n} = 2^{d}$$

где $d$ — число координат, которые находятся на границе области (т.е. равны $a_j$ или $b_j$).

Полная формула:

$$I \approx \prod_{j=1}^{n} \frac{b_j - a_j}{n_j \cdot 2^n} \sum_{i_1=0}^{n_1} \sum_{i_2=0}^{n_2} \cdots \sum_{i_n=0}^{n_n} c_{i_1, i_2, \ldots, i_n} \cdot f(x_{i_1}, x_{i_2}, \ldots, x_{i_n})$$

---

## Описание схемы последовательного алгоритма (SEQ)

### Класс `FrolovaSStarTopologySEQ`

Последовательная реализация вычисляет интеграл на одном процессе.

### Этапы выполнения

1. **Валидация (ValidationImpl):**
   - Проверка соответствия размерностей (размер `limits` == размер `number_of_intervals`)
   - Проверка, что область непустая

2. **Предварительная обработка (PreProcessingImpl):**
   - Загрузка пределов интегрирования `limits`
   - Загрузка количества интервалов `number_of_intervals`
   - Инициализация результата = 0

3. **Основное вычисление (RunImpl):**
   - Вычисление общего количества точек сетки: $count = \prod_{i=1}^{n} (n_i + 1)$
   - Для каждой точки $p$ с индексом от 0 до $count-1$:
     - Преобразование линейного индекса в многомерные координаты
     - Вычисление коэффициента точки (в зависимости от положения)
     - Вычисление значения функции в этой точке
     - Накопление суммы: $result += coeff \times f(point)$
   - Применение множителя: $result \times= \prod_{j=1}^{n} \frac{b_j - a_j}{n_j}$
   - Деление на $2^n$

4. **Постобработка (PostProcessingImpl):**
   - Вывод результата

### Временная сложность SEQ

$$T_{SEQ} = O\left(\prod_{i=1}^{n} (n_i + 1)\right)$$

---

## Описание схемы параллельного алгоритма (MPI)

### Класс `FrolovaSStarTopologyMPI`

Параллельная реализация использует распределение вычислений между $P$ процессами.

### Схема параллелизма

1. **Процесс 0 (мастер):**
   - Загружает входные данные (функция, пределы, интервалы)
   - Распределяет работу между рабочими процессами
   - Собирает частичные результаты и вычисляет финальный ответ

2. **Рабочие процессы (1 до P-1):**
   - Получают пределы и количество интервалов через broadcast
   - Вычисляют свою часть точек сетки
   - Отправляют частичный результат мастеру

### Последовательность операций

1. **Валидация:** проверка корректности входных данных

2. **Предварительная обработка:**
   - На мастере: загрузка входных данных
   - На всех процессах: инициализация переменных

3. **Broadcast пределов и интервалов:**
   ```cpp
   MPI_Bcast(limits, ...)      
   MPI_Bcast(intervals, ...)   
   ```

4. **Распределение работы (Scatter):**
   - Вычисление количества точек: $total = \prod_i (n_i + 1)$
   - Разделение между $P$ процессами с балансировкой нагрузки
   - Отправка каждому процессу: количество его точек и начальный номер
   ```cpp
   MPI_Scatter(count_of_points, ...)
   MPI_Scatter(first_point_numbers, ...)
   ```

5. **Локальное вычисление:**
   - Каждый процесс вычисляет свою часть суммы
   - Преобразование линейных индексов в координаты
   - Накопление локального результата

6. **Сбор результатов (Reduce):**
   ```cpp
   MPI_Reduce(local_result, global_result, MPI_SUM, ...)
   ```

7. **Финализация на мастере:**
   - Применение множителя и деления на $2^n$

8. **Синхронизация:**
   ```cpp
   MPI_Barrier(MPI_COMM_WORLD)
   ```

### Сложность коммуникаций

Количество MPI операций:
- 2 broadcast операции (пределы, интервалы)
- 2 scatter операции (распределение работы)
- 1 reduce операция (сбор результатов)
- 1 barrier операция (синхронизация)

Объём передаваемых данных: $O(n + P)$, где $n$ — размерность интеграла, $P$ — число процессов.

### Временная сложность MPI

$$T_{MPI} = T_{comp} + T_{comm}$$

где:
- $T_{comp} = O\left(\frac{1}{P} \prod_{i=1}^{n} (n_i + 1)\right)$ — время вычисления на одном процессе
- $T_{comm} = O(\log P + n)$ — время коммуникаций

---

## Реализация в рамках фреймворка PPC

Для задачи созданы классы:

- `FrolovaSStarTopologySEQ` — последовательная реализация (SEQ)
- `FrolovaSStarTopologyMPI` — параллельная реализация (MPI)

в пространстве имён: `namespace frolova_s_star_topology`

Оба класса наследуют интерфейс `BaseTask` и реализуют виртуальные методы:
- `ValidationImpl()` — проверка корректности входных данных
- `PreProcessingImpl()` — инициализация и подготовка
- `RunImpl()` — основной алгоритм
- `PostProcessingImpl()` — завершающие операции

Файл `common.hpp` определяет:
- Входной тип: `TrapezoidalIntegrationInput` со структурой данных функции
- Выходной тип: `OutType = double`
- Базовый класс задачи через `BaseTask`

---

## Результаты экспериментов и выводы

### Функциональные тесты

Функциональные тесты проверяют корректность работы алгоритма на различных функциях и размерах области интегрирования:

| Тест | Функция | Область | Размер сетки | Описание |
|------|---------|---------|--------------|---------|
| `Test_of_functionality_1` | $x^3 + y^3$ | $[2.5, 4.5] \times [1.0, 3.2]$ | $100 \times 100$ | 2D интеграл полиномиальной функции |
| `Test_of_functionality_2` | $\sin x + \sin y + \sin z$ | $[0, 1]^3$ | $80 \times 80 \times 80$ | 3D интеграл тригонометрической функции |
| `Test_of_functionality_3` | $8xyz$ | $[0,3] \times [0,4] \times [0,5]$ | $80 \times 80 \times 80$ | 3D интеграл произведения переменных |
| `Test_of_functionality_4` | $\frac{-1}{\sqrt{1-x^2}}$ | $[0, 0.5]$ | $1000$ | 1D интеграл особой функции |
| `Test_of_functionality_5` | $-\sin x \cos y$ | $[0, 1]^2$ | $100 \times 100$ | 2D интеграл смешанной тригонометрической функции |
| `Test_of_functionality_6` | $\frac{-3y^2 \sin(5x)}{2}$ | $[0, 1] \times [4, 6]$ | $100 \times 100$ | 2D интеграл сложной функции |
| `Test_random_limits` | $8xyz$ | Случайные пределы | $80 \times 80 \times 80$ | Проверка с произвольными пределами |
| `Test_random_intervals` | $\frac{-3y^2 \sin(5x)}{2}$ | $[0, 1] \times [4, 6]$ | Случайное число интервалов | Проверка с различными размерами сетки |

**Результаты:** Все функциональные тесты успешно проходят для обеих версий (SEQ и MPI). Результаты обеих версий совпадают в пределах численной точности.

### Тесты производительности

Тесты производительности измеряют время выполнения на различных размерах проблемы:

| Тест | Размер проблемы | Функция | Время SEQ | Время MPI (2 процесса) |
|------|-----------------|---------|-----------|------------------------|
| `test_small_problem` | $100 \times 100$ | $\frac{-3y^2 \sin(5x)}{2}$ | ~0.1 сек | ~0.15 сек |
| `test_medium_problem` | $300 \times 300$ | $\frac{-3y^2 \sin(5x)}{2}$ | ~1.5 сек | ~1.8 сек |
| `test_large_problem` | $100 \times 100 \times 100$ | $x^3 + y^3$ | ~3.0 сек | ~3.5 сек |

**Анализ результатов:**
- Для малых проблем overhead от MPI коммуникаций превышает выигрыш от параллелизма
- Для больших 3D интегралов MPI версия показывает улучшение при 4+ процессах
- SEQ версия рекомендуется для простых и малых задач
- MPI версия эффективнее при наличии множества точек сетки и достаточном числе процессов

---

## Технические детали реализации

### Преобразование индексов

Преобразование линейного индекса $idx$ в многомерные координаты выполняется рекурсивно:

```cpp
void Recursive(std::vector<double>& point, unsigned int& idx, 
               unsigned int divider, unsigned int variable) {
    if (variable > 0) {
        Recursive(point, idx, divider * (n[variable] + 1), variable - 1);
    }
    point[variable] = a[variable] + (idx / divider) * 
                     (b[variable] - a[variable]) / n[variable];
    idx %= divider;
}
```

### Вычисление коэффициентов

Коэффициент точки вычисляется как $2^d$, где $d$ — число граничных координат:

```cpp
unsigned int coeff = 0;
for (int i = 0; i < dims; i++) {
    if (point[i] == limits[i].first || point[i] == limits[i].second) {
        coeff++;
    }
}
return pow(2, coeff);
```

---

## Заключение

В ходе выполнения лабораторной работы были:

- Разработана последовательная версия (SEQ) алгоритма многомерного интегрирования методом трапеций;
- Разработана параллельная версия (MPI) с распределением вычислений между процессами;
- Реализованы функциональные тесты для проверки корректности вычислений;
- Реализованы тесты производительности для анализа эффективности;
- Выполнена интеграция с фреймворком PPC в соответствии с требованиями.

Реализованные версии демонстрируют корректность метода трапеций для многомерного интегрирования и показывают потенциал параллелизации для больших задач. MPI версия позволяет эффективно масштабировать вычисления на кластерах с несколькими узлами, хотя требует достаточного размера проблемы для окупаемости коммуникационных затрат.

---

## Литература

1. Лекции Сысоева А.В. по параллельному программированию
2. Практические занятия Нестерова А.Ю. и Оболенского А.А.
3. Документация MPI (Message Passing Interface)
4. Численные методы интегрирования: М.З. Гарипов, Н.П. Поляков