# Подсчет числа слов в строке

- **Студент:** Волков Алексей Иванович, 3823Б1ФИ2
- **Технология:** SEQ, MPI
- **Вариант:** 24

## 1. Введение

Подсчет слов является фундаментальной задачей при обработке текстов. При работе с очень большими текстовыми объемами последовательное выполнение этой задачи может стать узким местом. Целью данной работы является разработка параллельного алгоритма для подсчета слов с использованием технологии MPI (Message Passing Interface) и сравнение его производительности с эталонной последовательной реализацией.

## 2. Постановка задачи

**Задача:** Необходимо подсчитать общее количество "слов" в заданной входной строке.

-   **Входные данные:** строка символов `std::string`,
-   **Выходные данные:** целое число `int`, представляющее общее количество слов,
-   **Определение слова:** "словом" считается непрерывная последовательность символов, которая включает:
    -   буквы латинского алфавита в верхнем и нижнем регистре (`a-z`, `A-Z`);
    -   цифры (`0-9`);
    -   символы дефиса (`-`) и подчеркивания (`_`).
-   **Ограничения:** слова разделяются одним или несколькими символами-разделителями, которые не входят в определение "слова". Входная строка может быть пустой, может не содержать слов, а также может начинаться или заканчиваться разделителями.

## 3. Описание алгоритма (базового/последовательного)

Для последовательной реализации был выбран однопроходный алгоритм, основанный на концепции конечного автомата (машины состояний). Алгоритм проходит по строке символ за символом, отслеживая одно из двух состояний:

1.  `IN_WORD` — текущий символ является частью слова.
2.  `IN_SEPARATOR` — текущий символ является разделителем.

Логика работы следующая:
-   изначально автомат находится в состоянии `IN_SEPARATOR`;
-   при переходе из состояния `IN_SEPARATOR` в `IN_WORD` (т.е. когда после разделителя встречается первый символ слова), счетчик слов увеличивается на единицу;
-   при переходе из `IN_WORD` в `IN_SEPARATOR`, состояние просто меняется;
-   если состояние не меняется (например, два символа слова подряд), никаких действий со счетчиком не происходит.
Этот подход позволяет обойтись без создания подстрок или сложных манипуляций с памятью, обеспечивая высокую производительность за счет одного линейного прохода по данным.

## 4. Схема распараллеливания

Параллельная версия реализована с использованием MPI по модели "Master/Worker". Процесс с рангом 0 выступает в роли "мастера", а все остальные процессы (включая ранг 0) — в роли "воркеров".

1.  **Распределение данных:**
    -   процесс 0 определяет общую длину входной строки и рассылает это значение всем остальным процессам с помощью коллективной операции `MPI_Bcast`;
    -   строка делится на N примерно равных непрерывных частей, где N — общее число процессов;
    -   для распределения этих частей по всем процессам используется операция `MPI_Scatterv`, так как она позволяет работать с частями неодинакового размера (что актуально, если длина строки не делится нацело на число процессов).

2.  **Схема коммуникаций и обработка границ:**
    -   главная проблема параллельного подсчета — слова, "разрезанные" на границе двух частей, принадлежащих разным процессам. Чтобы решить эту проблему, каждый процесс должен знать, каким символом закончилась часть его левого соседа;
    -   для этого используется операция `MPI_Sendrecv`. Каждый процесс `p` отправляет свой последний символ процессу `p+1` и одновременно получает последний символ от процесса `p-1`. Это позволяет каждому процессу корректно определить, является ли первое слово в его части новым или продолжением слова из предыдущей части. `MPI_Sendrecv` гарантирует отсутствие взаимоблокировок при обмене.

3.  **Агрегация результатов:**
    -   каждый процесс выполняет локальный подсчет слов в своей части данных с учетом полученного граничного символа;
    -   локальные результаты со всех процессов собираются на процессе 0 и суммируются с помощью коллективной операции `MPI_Reduce` с оператором `MPI_SUM`.


## 5. Детали реализации

Реализация задачи выполнена на языке C++ и разделена на несколько логических компонентов в соответствии со структурой предоставленного фреймворка.

### Структура кода

-   **`common/include/common.hpp`**: общий заголовочный файл, определяющий типы данных для задачи:
    -   `InType = std::string`: входные данные — стандартная строка;
    -   `OutType = int`: выходные данные — целое число (количество слов);
    -   `BaseTask`: "псевдоним" для базового класса `ppc::task::Task`,

-   **`seq/`**: директория с последовательной реализацией:
    -   `ops_seq.hpp`: объявление класса `VolkovACountWordLineSEQ`;
    -   `ops_seq.cpp`: реализация методов класса и вспомогательных функций,

-   **`mpi/`**: директория с параллельной реализацией:
    -   `ops_mpi.hpp`: объявление класса `VolkovACountWordLineMPI`;
    -   `ops_mpi.cpp`: реализация методов класса и вспомогательных функций для MPI,

-   **`tests/`**: содержит функциональные и производительные тесты для проверки корректности и измерения производительности.

### Ключевые классы и функции

Решение инкапсулировано в классах `VolkovACountWordLineSEQ` и `VolkovACountWordLineMPI`, унаследованных от `BaseTask`. Основная вычислительная логика находится в переопределенном методе `RunImpl`.

Для повышения читаемости, снижения когнитивной сложности основная логика подсчета слов была вынесена во внутренние вспомогательные функции, помещенные в анонимное пространство имен в соответствующих .cpp файлах:

1.  **`bool IsTokenChar(char c)`**:
    -   простая функция-предикат, которая возвращает `true`, если переданный символ является частью слова (буква, цифра, `_` или `-`), и `false` в противном случае. Функция была вынесена для переиспользования и улучшения читаемости основного алгоритма,

2.  **`int CountWords(const char* data, size_t n)` (в `ops_seq.cpp`)**:
    -   эта функция реализует основной алгоритм подсчета слов на основе "машины состояний" с двумя состояниями (`IN_WORD`, `IN_SEPARATOR`). Она проходит по данным за один проход, что обеспечивает высокую производительность,

3.  **`int CountWordsInChunk(const std::vector<char>& data, char prev_char)` (в `ops_mpi.cpp`)**:
    -   адаптированная версия `CountWords` для MPI-реализации. Она принимает дополнительный аргумент `prev_char` — последний символ из блока данных предыдущего процесса. Этот символ используется для определения начального состояния машины состояний, что позволяет корректно обрабатывать слова, "разрезанные" на границах между процессами.


## 6. Экспериментальные результаты

### Окружение

-   **CPU:** Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz (6 ядер, 12 потоков)
-   **ОС:** Ubuntu 22.04.2 LTS (запущенная через Docker Engive v28.5.2 на Windows 11)
-   **Компилятор:** g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0

### Производительность

Для тестов производительности использовался сгенерированный текст длиной 10 миллионов символов. Измерения времени проводились для последовательной реализации и для MPI-реализации на 2, 4 и 8 процессах.

| Режим | Число процессов | Время, с | Ускорение (Speedup) | Эффективность (Efficiency) |
|:------|:----------------:|:---------|:--------------------|:---------------------------|
| seq   | 1                | 0.0095    | 1.00                | 100.0%                    |
| mpi   | 2                | 0.0065    | 1.46                | 73.0%                     |
| mpi   | 4                | 0.0039    | 2.44                | 61.0%                     |
| mpi   | 8                | 0.0051    | 1.86                | 23.3%                     |

**Выводы:**
Полученные результаты демонстрируют несколько ключевых аспектов параллельного выполнения данной задачи на рассматриваемом окружении:
1. *эффективное масштабирование до 4 процессов:* при увеличении числа процессов с 1 до 4 наблюдается значительное ускорение (до 2.44x). Это подтверждает, что выбранный алгоритм распараллеливания с использованием MPI эффективно распределяет работу, и накладные расходы не перевешивают выгоду от параллельных вычислений;
2. *деградация производительности на 8 процессах:* время выполнения увеличилось с 0.0039 с до 0.0051 с, а эффективность упала до 23.3%. Это классический и довольно интересный пример ситуации, когда накладные расходы на параллелизм превысили выгоду.

## 7. Выводы

В ходе работы была успешно реализована и протестирована параллельная версия алгоритма подсчета слов в строке с использованием технологии MPI. Алгоритм продемонстрировал значительное ускорение по сравнению с последовательной версией, подтвердив эффективность выбранной схемы распараллеливания. Вот так :)

## 8. Источники:

1.  лекции и практики курса "Параллельное программирование для кластерных систем";
2.  стандарт MPI (форум MPI);
3.  документация по C++;
