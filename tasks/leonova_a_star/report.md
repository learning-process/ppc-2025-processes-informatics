# Топология "звезда"

- Студент: Леонова Анна Сергеевна, группа 3823Б1ФИ1
- Технология: SEQ|MPI
- Вариант: 8

## 1. Введение
В данной лабораторной работе реализована топология "звезда" - одна из фундаментальных коммуникационных моделей в параллельных вычислениях. Топология "звезда" характеризуется наличием центрального узла (мастера), который координирует выполнение задачи, и периферийных узлов (рабочих процессов), выполняющих вычисления под управлением мастера. Данная архитектура демонстрируется на примере задачи умножения матриц — классической операции линейной алгебры с вычислительной сложностью O(n³). Цель работы — реализовать топологию "звезда" с использованием MPI, проанализировать её эффективность и сравнить производительность параллельной реализации с последовательной версией.

## 2. Постановка задачи
Для заданных двух матриц A (размер m × k) и B (размер k × n) необходимо вычислить матрицу C = A × B размером m × n, где каждый элемент c[i][j] вычисляется как скалярное произведение i-й строки матрицы A на j-й столбец матрицы B.

Формат входных данных: std::tuple<std::vector<std::vector<int>>, std::vector<std::vector<int>>> — пара матриц A и B.
Формат выходных данных:
std::vector<std::vector<int>> — результирующая матрица C.

Ограничения и особенности реализации:

- Матрицы не могут быть пустыми.
- Матрицы должны быть совместимы для умножения (число столбцов A = числу строк B).
- Матрицы могут быть не квадратными.
- Все значения в матрицах — целые числа. (для демонстрации работы топологии этого достаточно)

## 3. Базовый алгоритм (Последовательный)
Алгоритм последовательного умножения матриц:

for i от 0 до m-1:
    for j от 0 до n-1:
        sum = 0
        for r от 0 до k-1:
            sum += A[i][r] * B[r][j]
        C[i][j] = sum
Вычислительная сложность - O(m⋅n⋅k).

## 4. Схема распараллеливания с топологией "звезда"

### 4.1 Общее описание топологии "звезда"
Топология "звезда" (star topology) представляет собой централизованную архитектуру, в которой все процессы взаимодействуют исключительно через центральный узел (процесс с рангом 0). В этой топологии:
- Центральный узел (мастер) отвечает за координацию работы всей системы
- Рабочие процессы не взаимодействуют напрямую друг с другом
- Все данные передаются через мастер-процесс
- Эта топология проста в реализации и отладке, но создает узкое место (bottleneck) на мастер-процессе

### 4.2 Применение топологии "звезда" для умножения матриц

В данной реализации топологии "звезда" процесс с рангом 0 выступает в роли мастера, который выполняет следующие функции:
- Инициализация: Считывает входные данные (матрицы A и B)
- Валидация: Проверяет корректность матриц (размеры, совместимость для умножения)
- Распределение данных:
    1. Рассылает матрицу B всем рабочим процессам через MPI_Bcast
    2. Распределяет строки матрицы A между рабочими процессами с помощью MPI_Scatterv
- Координация вычислений: Запускает параллельные вычисления
- Сбор результатов: Собирает частичные результаты с рабочих процессов через MPI_Gatherv
- Формирование итога: Объединяет результаты в итоговую матрицу C

### 4.3 Распределение данных

Матрица B передается целиком каждому рабочему процессу через операцию широковещательной рассылки MPI_Bcast. Это необходимо, так как каждый процесс нуждается в полной матрице B для вычисления своего блока результата. Матрица A распределяется построчно с использованием MPI_Scatterv, который позволяет распределять переменные блоки данных. Каждый рабочий процесс получает свой набор строк матрицы A для обработки. Результаты вычислений собираются на мастере с помощью MPI_Gatherv, который обрабатывает результаты разного размера от каждого процесса.

### 4.4 Схема коммуникации

Процесс 0 (Мастер)
       │
    ┌──┴──┐ ... ...
    ▼     ▼
Процесс 1  Процесс 2 ... ...

Последовательность операций:
1) Мастер → Все процессы: MPI_Bcast (матрица B)
2) Мастер → Каждый процесс: MPI_Scatterv (часть матрицы A)
3) Каждый процесс: локальные вычисления
4) Каждый процесс → Мастер: MPI_Gatherv (часть матрицы C)
5) Мастер → Все процессы: MPI_Bcast (итоговая матрица C, опционально)

### 4.5 Преимущества и недостатки
Преимущества:
- Простота реализации и отладки
- Централизованное управление упрощает синхронизацию
- Легко масштабируется добавлением новых рабочих процессов
- Минимальное количество каналов связи (N-1 для N процессов)

Недостатки:
- Мастер становится узким местом (bottleneck) при больших объемах данных
- Отказ мастера приводит к отказу всей системы
- Ограниченная пропускная способность из-за централизованной коммуникации

## 5. Детали реализации
Структура проекта:
ppc-2025-processes-informatics/tasks/leonova_a_star/seq/include/ops_seq.hpp — последовательная реализация
ppc-2025-processes-informatics/tasks/leonova_a_star/mpi/include/ops_mpi.hpp — MPI реализация с топологией "звезда"
ppc-2025-processes-informatics/tasks/leonova_a_star/tests/ — функциональные и производительные тесты

## 6. Experimental Setup

### 6.1 Оборудование и ПО
- CPU: Intel Core i5-1135G7 (4 ядра, 8 потоков);
- RAM: 8ГБ;
- ОС: Windows 10 Pro 22H2;
- Тип сборки: Release.

### 6.2 Функциональные тесты
Для проверки корректности реализации использовались 6 тестовых случаев:

1. Единичная матрица
A = I (единичная матрица 2×2), B = [[5,6],[7,8]]
Ожидаемый результат: [[5,6],[7,8]]

2. Нулевая матрица 
A = [[0,0],[0,0]], B = [[1,2],[3,4]]
Ожидаемый результат: [[0,0],[0,0]]

3. Квадратные матрицы 3×3 
A = [[1,2,3],[4,5,6],[7,8,9]], B = [[9,8,7],[6,5,4],[3,2,1]]
Ожидаемый результат: [[30,24,18],[84,69,54],[138,114,90]]

4. Неквадратные матрицы 2×3 и 3×2 
A = [[1,0,-1],[2,1,0]], B = [[2,1],[1,2],[0,3]]
Ожидаемый результат: [[2,-2],[5,4]]

5. Матрица-строка и матрица-столбец 
A = [[1,2,3]], B = [[4],[5],[6]]
Ожидаемый результат: [[32]]

6. Большие значения элементов 
A = [[100,200],[300,400]], B = [[5,6],[7,8]]
Ожидаемый результат: [[1900,2200],[4300,5000]]

Все функциональные тесты успешно пройдены, что подтверждает корректность реализации как последовательной, так и параллельной версий.

### 6.3 Тесты производительности
Данные для тестов на производительность статические и расположены в файле ppc-2025-processes-informatics/tasks/leonova_a_star/data/matrices_perf.txt
В файле находятся семь пар матриц для перемножения со следующими размерами:
1. 500x500
2. 500x500
3. 1000x1000
4. 1000x1000
5. 2000x2000
6. 2000x2000
7. 3000x3000

Результат перемножения не проверяется — правильность вычислений проверяется в функциональных тестах. Для тестов производительности измеряется только время выполнения.

## 7. Результаты и обсуждение

### 7.1 Проверка корректности
Корректность работы подтверждена:
- Совпадением результатов последовательной и параллельной версий
- Прохождением всех функциональных тестов
- Обработкой граничных случаев (нулевые матрицы, неквадратные размеры)

### 7.2 Производительность

|Процессов|MPI, с |
|---------|-------|
|2		  |0.0156 |
|4		  |0.0181 |
|6		  |0.2103 |
|8		  |0.1356 |

Среднее время выполнения SEQ = 0.1991 c.
(Рассчитано как среднее арифметическое из SEQ значений: 0.1667, 0.1825, 0.2496, 0.1976)
Использование среднего значения SEQ позволяет более объективно оценить ускорение, так как устраняет случайные колебания времени выполнения последовательной версии для разных тестов.

Ускорение и Эффективность:

|Процессов|Ускорение (S)|Эффективность (E), %|
|---------|-------------|--------------------|
|2		  |12.76	    |638.0               |
|4		  |11.00	    |275.0               |
|6		  |0.95	        |15.8                |
|8		  |1.17	        |14.6                |

Формулы расчета:
Ускорение (S) = T_seq / T_mpi
Эффективность (E) = (S / N) × 100%, где N — количество процессов
### 7.3 Анализ результатов

1. 2 процесса: Ускорение 12.76× при эффективности 638%
Это существенно превышает теоретические ожидания и свидетельствует о:
- Оптимальном использовании двух физических ядер
- Минимальных накладных расходах на коммуникацию
- Эффективном кэшировании данных

2. 4 процесса: Ускорение 11.00× при эффективности 275%
Сохранение высокого ускорения при увеличении числа процессов до 4 подтверждает:
- Хорошую масштабируемость алгоритма в пределах физических ядер
- Способность мастера эффективно координировать 3 рабочих процесса
- Сбалансированное распределение вычислительной нагрузки

Ключевой вывод: Для оборудования с 4 физическими ядрами топология "звезда" демонстрирует максимальную эффективность при использовании 2-4 процессов, что соответствует принципу "один процесс на ядро" или "один процесс на гиперпоточное ядро".

Переход к oversubscription (переназначению ресурсов) приводит к резкому ухудшению производительности:
3. 6 процессов: Ускорение 0.95×, эффективность 15.8% 
Фактическое замедление по сравнению с SEQ (ускорение < 1.0). Эффективность падает в 17 раз по сравнению с 4 процессами - это явное проявление ограничений оборудования

4. 8 процессов: Ускорение 1.17×, эффективность 14.6%
Минимальное ускорение, практически эквивалентное последовательной версии. Наименьшая эффективность среди всех конфигураций
Факторы, объясняющие деградацию производительности:
- Аппаратные ограничения: 4 физических ядра не могут эффективно обслуживать 6-8 процессов
- Частые переключения контекста увеличивают накладные расходы
- Конкуренция за ресурсы кэша и памяти
- Архитектурные ограничения топологии "звезда": Мастер становится узким местом при обслуживании 5-7 рабочих
- Линейный рост времени координации с увеличением процессов
- Последовательная обработка запросов ограничивает параллелизм коммуникаций

5. Выводы 
Область эффективного применения: 2-4 процесса на системе с 4 физическими ядрами.
Предел масштабируемости: Количество процессов не должно превышать количество физических ядер более чем в 1.5 раза.
Критический фактор: Соотношение "время вычислений / время коммуникации". При его уменьшении ниже 10:1 эффективность резко падает.
Диагностический признак: Падение эффективности ниже 50% указывает на необходимость уменьшения количества процессов или изменения архитектуры.
Заключительный вывод: Топология "звезда" доказала свою эффективность для задач с высокой вычислительной сложностью и умеренным уровнем параллелизма. Однако ее использование требует выбора количества процессов, соответствующего характеристикам целевого оборудования.

### 8. Выводы

Реализация топологии "звезда" успешна: Алгоритм умножения матриц корректно работает в топологии "звезда", демонстрируя правильные результаты для всех тестовых случаев.
Эффективность распараллеливания: Для 2 и 4 процессов достигнуто значительное ускорение (9-10 раз) по сравнению с последовательной реализацией, что подтверждает эффективность выбранного подхода для задач средней сложности.
Ограничения топологии "звезда": При увеличении числа процессов свыше количества физических ядер производительность резко падает из-за:
- Узкого места на мастер-процессе
- Накладных расходов на коммуникацию
- Конкуренции за ресурсы при oversubscription
Оптимальное количество процессов: Для данного оборудования (4 ядра) оптимальным является использование 2-4 процессов. Дальнейшее увеличение числа процессов нецелесообразно.
Практическая значимость: Топология "звезда" хорошо подходит для задач с умеренным уровнем параллелизма, где объем вычислений значительно превышает объем коммуникаций. Для более масштабных систем стоит рассмотреть другие топологии.

## 9. Ссылки
Open MPI Documentation. https://www.open-mpi.org/doc/
Матричные вычисления и параллельные алгоритмы. https://habr.com/ru/articles/359272/
Учебное пособие "Основы MPI". https://parallel.uran.ru/node/182