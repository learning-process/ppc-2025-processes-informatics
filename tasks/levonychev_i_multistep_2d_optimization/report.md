# Многошаговая двумерная оптимизация с использованием SEQ и MPI

- Студент: Левонычев Иван Александрович, группа 3823Б1ФИ3
- Технология: SEQ, MPI
- Вариант: 12

## 1. Введение
- Мотивация: изучить методы параллельной оптимизации на основе MPI, применить многошаговый алгоритм сужения области поиска для нахождения глобального минимума функции двух переменных.
- Проблема: задача глобальной оптимизации требует значительных вычислительных ресурсов при поиске по сетке на каждом шаге.
- Ожидаемый результат: MPI версия должна показать ускорение относительно последовательной версии благодаря параллельному поиску в различных сужённых регионах.

## 2. Постановка задачи
На вход программе подаются параметры оптимизации:
1. Функция для оптимизации (функция двух переменных, возвращающая double).
2. Начальные границы поиска: `x_min`, `x_max`, `y_min`, `y_max`.
3. Количество шагов оптимизации: `num_steps`.
4. Размер сетки на первом шаге: `grid_size_step1`.
5. Количество кандидатов для отбора: `candidates_per_step`.
6. Флаг использования локальной оптимизации: `use_local_optimization`.

Требуется найти точку глобального минимума функции в заданной области с использованием многошагового алгоритма.

## 3. Базовый алгоритм (последовательный)
Последовательный алгоритм работает следующим образом:

1. **Инициализация**: начиная с полной области поиска.
2. **На каждом шаге i (от 0 до num_steps-1)**:
   - Построить сетку размером `grid_size_step1 * 2^i` в текущей области.
   - Вычислить значение функции в каждой точке сетки.
   - Отсортировать точки по значению функции и выбрать топ `candidates_per_step` кандидатов.
   - Если это не последний шаг, построить новый регион вокруг лучшего кандидата.
3. **Финальный поиск**: выполнить поиск в финальной области.
4. **Локальная оптимизация**: если включена, применить локальную оптимизацию к найденной лучшей точке.

## 4. Описание параллельного алгоритма
Параллельный алгоритм MPI основан на распределении кандидатов между процессами:

1. **Инициализация**: каждый процесс вычисляет свой сегмент исходной области (разделение по оси X).
2. **На каждом шаге**:
   - Все процессы параллельно выполняют поиск в своих текущих регионах.
   - Каждый процесс выбирает `candidates_per_step` топ кандидатов из своего региона.
   - Используется `MPI_Gather` для сбора всех кандидатов на rank 0.
   - Rank 0 выбирает топ `candidates_per_step` глобальных кандидатов и сортирует их.
   - Используется `MPI_Bcast` для распределения лучших кандидатов всем процессам.
   - Каждый процесс строит новый регион вокруг кандидата.
3. **Финальный поиск**: каждый процесс выполняет финальный поиск в своем финальном регионе.
4. **Сбор результатов**: используется `MPI_Gather` для сбора лучших точек от всех процессов, затем выбирается глобальный минимум.

**Ключевое отличие**: на каждом шаге все процессы работают параллельно в разных регионах.

## 5. Experimental Setup
- Hardware/OS: Intel i5-12450H, 8 ядер, RAM 16GB, Windows 11
- Toolchain: Microsoft Visual C++ (MSVC), Release
- Data: Тестовые функции с указанными областями поиска

## 6. Результаты

### 6.1 Корректность
Корректность алгоритмов проверена функциональными тестами. Обе версии (SEQ и MPI) находят одну и ту же точку минимума. Проверено:
- Граничные случаи (минимум на границе области)
- Минимум внутри области

### 6.2 Производительность
Входные данные: Функция Розенброка, область поиска [-2,2]x[-2,2], 6 шагов оптимизации, сетка 100x100 на первом шаге, 10 кандидатов.

| Mode        | Count | Time, s | Speedup | Efficiency |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 1.808   | 1.00    | N/A        |
| mpi         | 2     | 0.905   | 1.99    | 99.8%      |
| mpi         | 4     | 0.455   | 3.97    | 99.3%      |


## 7. Выводы
На основе результатов производительности можно сделать следующие выводы:

1. **Корректность**: Обе версии дают идентичные результаты оптимизации.
2. **Параллелизм**: MPI версия обеспечивает истинный параллелизм за счет распределения регионов-кандидатов между процессами.
3. **Масштабируемость**: Ожидается линейное или близкое к линейному ускорение при увеличении числа процессов.

## 8. Литература
1. Стандарт MPI.
2. Лекции и практики по параллельному программированию.

