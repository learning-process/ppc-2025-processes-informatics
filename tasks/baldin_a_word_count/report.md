# Подсчёт числа слов в строке
- Студент: Балдин Андрей Леонидович, 3823Б1ФИ3
- Технология: SEQ, MPI 
- Вариант: 24

---

## 1. Введение
Задача подсчёта числа слов в тексте является базовой операцией обработки строк. Она широко используется в анализе текстов, поисковых системах и системах статического анализа.
Цель работы - реализовать параллельную версию алгоритма подсчёта слов с использованием технологии MPI, оценить корректность и исследовать ускорение относительно последовательного варианта.

---

## 2. Постановка задачи
**Задано**: строка (текст произвольной длины), состоящая из букв, цифр, символов дефиса `-`, подчёркивания  `_` и разделителей (пробелы, пунктуация и т.д.).

**Требуется**: определить количество слов в тексте.
Под словом будем понимать последовательность символов, состоящую из букв, цифр, символов `-` и `_`.

**Входные данные**: строка произвольной длины.
**Выходные данные:** одно целое число - количество слов.
**Ограничения**:
- длина строки может быть большой (несколько мегабайт);
- программа должна корректно работать при любом количестве MPI-процессов;
- границы фрагментов, распределённых между процессами, не должны нарушать корректность подсчёта слов.

---

## 3. Базовый алгоритм (последовательный)
Последовательная версия проходит по всей строке один раз и считает переходы из состояния "вне слова" в состояние "внутрь слова".

Псевдокод: 
```cpp
count = 0;
in_word = false;
for char c in input:
	if (c - цифра или буква) or (c == '-') or (c == '_') :
		if not in_word:
			in_word = true
			count += 1
		else 
			in_word = false
```
Сложность алгоритма - O(n), где n - длина текста.

---

## 4.  Схема распараллеливания
- **Декомпозиция данных**:
	- Исходная строка разбивается на равные части по числу процессов.
	- Каждый процесс получает свой участок строки через `MPI_Scatterv`
	- Чтобы избежать потери слова на границе фрагментов, каждому процессу отправляется дополнительный символ справа.
- **Вычисления на процессе**:
	Каждый процесс независимо выполняет подсчёт слов в своём подотрезке, используя функцию `CountLocalWords` и исключая двойной подсчёт, если слово пересекает границу сегмента.
- **Коммуникация**:
	После локальных подсчётов выполняется редукция (`MPI_Allreduce`) с операцией суммы, чтобы получить общее количество слов.
- **Топология и обмен**:
	Используется коммуникатор `MPI_COMM_WORLD` без явной топологии (все процессы равноправны).  
	Тип обмена — коллективные операции (`Scatterv`, `Allreduce`).


---
## 5.  Детали реализации
- **Ключевые файлы:**
	- `baldin_a_word_count/seq/include/ops_seq.hpp` и `baldin_a_word_count/seq/src/ops_seq.cpp` - последовательная реализация.
	- `baldin_a_word_count/mpi/include/ops_mpi.hpp` и `baldin_a_word_count/mpi/src/ops_mpi.cpp` - параллельная реализация.
	- `baldin_a_word_count/common/include/common.hpp` - общие определения типов и интерфейсов.
- **Ocновные функции**:
	- `IsWordCount(char)` - проверка, является ли символ частью слова.
	- `CountWords(std::string)` - подсчёт слов для последовательной версии.
	- `CountLocalWords(std::vector<char>, int)` - подсчёт слов во фрагменте каждого процесса.
- **Особенности**:
	- **Проверка на пустую строку.**  
	    В начале параллельного алгоритма выполняется проверка на нулевую длину входной строки. Если строка пуста, программа сразу возвращает результат `0`, избегая ненужных коммуникаций между процессами.
	- **Обработка случая, когда процессов больше, чем символов.**  
	    Если количество MPI-процессов превышает длину входной строки, используется последовательный подсчёт слов. Это обусловлено тем, что в такой ситуации накладные расходы на распределение данных и синхронизацию процессов значительно превосходят время, необходимое для линейного прохода по строке на одном процессе.
	- **Дополнение строки до кратности числу процессов.**  
	    После всех проверок на граничные случаи исходная строка дополняется пробелами так, чтобы её длина стала кратна количеству процессов.  
	    Это решение упрощает логику деления данных и работу с последним процессом, которому иначе могло бы достаться меньше символов, чем остальным.  
	    Добавление нескольких дополнительных символов (максимум `число процессов - 1`) не оказывает существенного влияния на производительность и, как правило, не вызывает перевыделения или копирования строки в памяти.
	- **Передача фрагментов данных процессам.**  
	    Каждый процесс получает свой подотрезок строки длиной `part` символов, а также дополнительный символ из начала следующего фрагмента (`part + 1` символ в буфере).  
	    Это позволяет проверить, не разделилось ли слово между двумя процессами. Таким образом, каждый процесс обрабатывает только свои `part` символов в основном цикле, а затем выполняет дополнительную проверку:
	    ```cpp
	    if (in_word && (IsWordChar(local_buf[part]))) {
			local_cnt--;
		}
	    ```
	    Данное условие уменьшает локальное количество слов на единицу, если процесс завершил обработку своего участка внутри слова, а следующий символ (принадлежащий соседнему процессу) также является частью слова. Это предотвращает двойной учёт слов, пересекающих границы сегментов.
	- **Буфер фиксированного размера для каждого процесса.**  
		Так как всем процессам выделяются одинаковые объёмы данных, каждый локальный буфер создаётся размером `part + 1` символ, где дополнительный символ используется исключительно для проверки границы между процессами. Это обеспечивает простоту и симметричность распределения данных по всем процессам.

---

## 6. Экспериментальная установка
- **Аппаратное обеспечение**: 
	Apple M1 Pro (8 ядер CPU)  
	ОЗУ — 16 ГБ LPDDR5
- **Операционная система:** macOS Sonoma 14.5
- **Компилятор:** Apple Clang 21.1.4
- **MPI-библиотека:** Open MPI 5.0.8
- **Тип сборки:** Release (`-O3`)

---

## 7.  Результаты и обсуждение
### 7.1 Корректность
- Корректность проверялась сравнением результатов MPI-версии с эталонной последовательной реализацией.
- Для различных строк (включая пустые, из одного слова, с разделителями и смешанными символами) результаты совпадают.

### 7.2 Производительность
Производительность замерялась на системе, указанной в пункте 6.

Тест 1. Текст длиной 3 * 10^6 символов.

| Mode | Count | Time, s | Speedup | Efficiency |
| ---- | ----- | ------- | ------- | ---------- |
| seq  | 1     | 0,0029  | 1.00    | N/A        |
| omp  | 2     | 0.0026  | 1.097   | 54.85%     |
| omp  | 4     | 0.0019  | 1.459   | 36.47%     |
| omp  | 8     | 0.0024  | 1.247   | 15.58%     |

Тест 2. Текст длиной 10^7 символов.

| Mode | Count | Time, s | Speedup | Efficiency |
| ---- | ----- | ------- | ------- | ---------- |
| seq  | 1     | 0.0095  | 1.00    | N/A        |
| omp  | 2     | 0.0065  | 1.459   | 72.95%     |
| omp  | 4     | 0.0039  | 2.562   | 64.05%     |
| omp  | 8     | 0.0051  | 2.103   | 26.28%     |

Тест 3. Текст длиной 5 * 10^7 символов.

| Mode | Count | Time, s | Speedup | Efficiency |
| ---- | ----- | ------- | ------- | ---------- |
| seq  | 1     | 0.0488  | 1.00    | N/A        |
| omp  | 2     | 0.0297  | 1.64    | 82.00%     |
| omp  | 4     | 0.0177  | 2.695   | 67.37%     |
| omp  | 8     | 0.0252  | 2.111   | 26.38%     |

- При относительно небольших объёмах текста выигрыш от распараллеливания незначителен или отсутствует из-за накладных расходов коммуникации.
- Максимальная эффективность достигается при 4 процессах.
- Эффективность растёт при увеличении размера входных данных.
- В целом, параллельный подход оправдан при обработке длинных текстов, где нагрузка на каждый процесс достаточно велика для затрат на координацию.

---

## 8. Заключение
- Реализованный алгоритм корректно выполняет подсчёт слов в строке в параллельном режиме с использованием MPI.  
- Наблюдается существенное ускорение при использовании параллельного подхода.  
- Основные ограничения — затраты на обмен данными между процессами и неэффективность при малых объёмах текста.

---

## 9. Источники
- Лекции и практики курса "Параллельное программирование"