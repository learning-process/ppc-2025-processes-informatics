# Поразрядная сортировка для вещественных чисел с простым слиянием

- Студент: Леонова Анна Сергеевна, группа 3823Б1ФИ1
- Технология: SEQ | MPI
- Вариант: 20

## 1. Введение
В данной работе реализован гибридный алгоритм сортировки вещественных чисел типа double, сочетающий поразрядную сортировку (Radix Sort) и сортировку слиянием (Merge Sort). Алгоритм использует поразрядную сортировку для небольших подмассивов (размером ≤ 32) и слияние для объединения отсортированных частей. Важной особенностью реализации является использование итеративного (нерекурсивного) подхода для обхода дерева сортировки слиянием, что позволяет избежать проблем с глубиной рекурсии и повысить стабильность работы на больших массивах. Цель работы — сравнить производительность последовательной и параллельной (MPI) реализаций алгоритма на различных наборах данных.

## 2. Постановка задачи
На вход приходит вектор вещественных чисел, о порядке чисел ничего не известно. На выходе необходимо получить вектор такого же размера, все числа в нем должны быть отсортированы в порядку возрастания.

Входные данные: std::vector<double> — вектор вещественных чисел.
Выходные данные: std::vector<double> — отсортированный по возрастанию вектор.

Ограничения и особенности реализации:

- Поддержка специальных значений (NaN, Inf) не предусмотрена.
- В векторе должен быть хотя бы один элемент
- Тип данных в векторе - строго double
- Порог переключения между RadixSort и MergeSort: 32 элемента.

## 3. Базовый алгоритм (Последовательный)

### 3.1 Преобразование double в ключ для сортировки
cpp
uint64_t TransformDoubleToKey(double value) {
    uint64_t int_value;
    memcpy(&int_value, &value, sizeof(double));
    constexpr uint64_t SIGN_BIT_MASK = 0x8000000000000000ULL;
    return (int_value & SIGN_BIT_MASK) ? ~int_value : (int_value | SIGN_BIT_MASK);
}
Это преобразование необходимо, потому что:
- Отрицательные числа в формате IEEE 754 имеют установленный старший бит (знаковый бит)
- Без преобразования они отсортировались бы после положительных
Алгоритм превращает двоичное представление в монотонную последовательность

### 3.2 Поразрядная сортировка (Radix Sort)
Применяется для подмассивов размером ≤ kRadixThreshold (32). Сортировка идет по байтам (8 байт для double). Использует counting sort для каждого байта:
text
Для каждого элемента массива:
    Извлечь текущий байт из ключа (byte_pos от 0 до 7)
    Увеличить счетчик для этого байта

Вычислить префиксные суммы счетчиков

Для каждого элемента массива:
    Определить позицию в выходном массиве через префиксные суммы
    Скопировать элемент в соответствующую позицию

### 3.3 Итеративная сортировка слиянием (Merge Sort)
Вместо традиционной рекурсии используется явный стек для обхода дерева сортировки. Это позволяет избежать потенциальных проблем с глубиной рекурсии и улучшить контроль над использованием памяти.

Структура задачи:

cpp
struct SortTask {
    size_t left;     // Левая граница подмассива
    size_t right;    // Правая граница подмассива
    bool sorted;     // Флаг: false - нужно отсортировать, true - нужно слить
};

Алгоритм:

RadixMergeSort(массив, left, right):
    Инициализировать пустой стек
    Добавить задачу {left, right, false} в стек
    
    Пока стек не пуст:
        current = извлечь задачу из стека
        size = current.right - current.left
        
        Если size <= 1:
            пропустить (массив уже отсортирован)
        
        Если size <= 32:  # Порог kRadixThreshold
            выполнить RadixSort для current.left..current.right
            продолжить
        
        Если current.sorted == false:
            mid = current.left + size / 2
            # Добавляем задачи в обратном порядке (LIFO):
            добавить {current.left, current.right, true}  # Задача на слияние
            добавить {mid, current.right, false}          # Сортировка правой части
            добавить {current.left, mid, false}           # Сортировка левой части
        Иначе:
            mid = current.left + size / 2
            SimpleRadixMerge(current.left, mid, current.right)


### 3.4 Пример сортировки
Исходный массив (34 элемента):
arr = [12.5, -3.2, 7.1, 0.0, -15.8, 42.3, 1.5, -1.5, 9.9, 3.14,
 2.71, -7.7, 5.0, 8.8, -0.5, 10.1, 6.6, 4.4, 11.11, -12.12,
 13.13, 14.14, -8.8, 15.0, 16.1, 17.2, 18.3, -9.9, 19.4, 20.5,
 21.6, 22.7, 23.8, 24.9]

- Шаг 1: Инициализация стека
- Шаг 2: Обработка первой задачи

Извлекаем: {0, 34, false}
size = 34 > 32 → используем Merge Sort
mid = 17
Добавляем в стек (в порядке LIFO):
  1. {0, 34, true}    # Задача на слияние
  2. {17, 34, false}  # Сортировка правой части  
  3. {0, 17, false}   # Сортировка левой части
Стек: [{0, 17, false}, {17, 34, false}, {0, 34, true}]

- Шаг 3: Сортировка левой части (0-17)

Извлекаем: {0, 17, false}
size = 17 ≤ 32 → используем RadixSort
Сортируем элементы [0..17] с помощью RadixSort
Результат: [-15.8, -12.12, -9.9, -8.8, -7.7, -3.2, -1.5, -0.5, 0.0, 
            1.5, 2.71, 3.14, 4.4, 5.0, 6.6, 7.1, 8.8]
Стек: [{17, 34, false}, {0, 34, true}]

- Шаг 4: Сортировка правой части (17-34)

Извлекаем: {17, 34, false}
size = 17 ≤ 32 → используем RadixSort
Сортируем элементы [17..34] с помощью RadixSort
Результат: [9.9, 10.1, 11.11, 12.5, 13.13, 14.14, 15.0, 16.1, 17.2,
            18.3, 19.4, 20.5, 21.6, 22.7, 23.8, 24.9, 42.3]
Стек: [{0, 34, true}]

- Шаг 5: Слияние двух отсортированных половин

Извлекаем: {0, 34, true}
Выполняем SimpleRadixMerge(0, 17, 34)
Слияние отсортированных половин:
  Левая: [-15.8...8.8]
  Правая: [9.9...42.3]
Результат: [-15.8...42.3] (полностью отсортированный массив)
Стек: [] (пуст)

- Шаг 6: Итоговый результат
[-15.8, -12.12, -9.9, -8.8, -7.7, -3.2, -1.5, -0.5, 0.0, 1.5,
 2.71, 3.14, 4.4, 5.0, 6.6, 7.1, 8.8, 9.9, 10.1, 11.11, 12.5,
 13.13, 14.14, 15.0, 16.1, 17.2, 18.3, 19.4, 20.5, 21.6, 22.7,
 23.8, 24.9, 42.3]
Стек: [{0, 34, false}]

### 3.5 Сложность гибридной сортировки
Radix Sort: O(n × k), где k = 8 (байт в double), константа ≈ O(n)
Merge Sort: O(n log n)
Гибридный подход: O(n log n) в худшем случае, но с меньшей константой для маленьких подмассивов

## 4. Схема распараллеливания

### 4.1 Распределение данных
Массив делится на блоки между процессами и передается с использованием MPI_Scatterv.
cpp
// Вычисление размеров блоков для каждого процесса
int base_size = total_size / world_size_;
int remainder = total_size % world_size_;
for (int i = 0; i < world_size_; ++i) {
    send_counts[i] = base_size + (i < remainder ? 1 : 0);
    if (i > 0) {
        displacements[i] = displacements[i - 1] + send_counts[i - 1];
    }
}

Пример распределения для N=3 процессов и массива из 10 элементов:

Всего элементов: 10
Процессов: 3
Базовый размер: 10 / 3 = 3
Остаток: 10 % 3 = 1

Распределение:
- Процесс 0: 3 + 1 = 4 элемента (индексы 0-3)
- Процесс 1: 3 + 0 = 3 элемента (индексы 4-6) 
- Процесс 2: 3 + 0 = 3 элемента (индексы 7-9)

Каждый процесс сортирует свою часть локально с помощью RadixMergeSort.
Так же учтен случай когда процессов больше чем необходимо.
Если total_size < world_size_, то некоторые процессы получат 0 элементов (send_counts[i] = 0). Эти процессы пропускают этап локальной сортировки. Они участвуют только в коммуникационной схеме.

Пример (4 процесса, 2 элемента):

send_counts = [1, 1, 0, 0]
displacements = [0, 1, 2, 2]

- Процесс 0: 1 элемент
- Процесс 1: 1 элемент  
- Процесс 2: 0 элементов (не выполняет сортировку)
- Процесс 3: 0 элементов (не выполняет сортировку)

### 4.2 Иерархическое простое слияние (Hierarchical Merge)
Процессы объединяются попарно на каждом шаге. Отправитель передает данные получателю, который выполняет слияние. Процесс 0 собирает окончательный результат.

step = 1
Пока step < world_size:
    mask = step * 2
    Если rank % mask == 0:
        partner = rank + step
        Если partner существует:
            Получаем данные от partner
            Сливаем свои данные с данными partner
    Иначе если rank % mask == step:
        partner = rank - step
        Отправляем свои данные partner
        Завершаем работу
    step *= 2

Наглядно это можно представить на схеме:

Процесс 0 ──┐
           ├─ Слияние ──┐
Процесс 1 ──┘          
                        ├─ Слияние
Процесс 2 ──┐              
           ├─ Слияние ──┘
Процесс 3 ──┘        

## 5. Детали реализации
Структура проекта:
- common.hpp — общие типы данных.
- ops_seq.hpp/cpp — последовательная реализация.
- ops_mpi.hpp/cpp — параллельная реализация (MPI).
- main.cpp — функциональные и производительные тесты.

Ключевые методы:
- RadixMergeSort() — основной метод сортировки.
- TransformDoubleToKey() — преобразование double в сортируемый ключ.
- HierarchicalMerge() — параллельное слияние в MPI.

## 6. Experimental Setup
### 6.1 Оборудование и ПО
- CPU: Intel Core i5-1135G7 (4 ядра, 8 потоков);
- RAM: 8ГБ;
- ОС: Windows 10 Pro 22H2;
- Тип сборки: Release.

### 6.2 Функциональные тесты
Для проверки корректности реализации использовались 20 тестовых случаев:
1. Базовые случаи:
- 1 элемент: {42.0} → {42.0}
- 2 элемента: {3.14, 2.71} → {2.71, 3.14}
- 5 элементов, случайные: {5.0, 1.0, 4.0, 2.0, 3.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
2. Специальные числовые случаи:
- Отрицательные числа: {-5.0, 0.0, 5.0, -10.0, 10.0} → {-10.0, -5.0, 0.0, 5.0, 10.0}
- Дробные числа: {0.1, 0.01, 0.001, 1.0, 10.0, 100.0} → {0.001, 0.01, 0.1, 1.0, 10.0, 100.0}
- Большой диапазон: {1e10, 1e-10, 1e5, 1e-5, 0.0} → {0.0, 1e-10, 1e-5, 1e5, 1e10}
- Ноль и -ноль: {0.0, -0.0, 1.0, -1.0} → {-1.0, 0.0, 0.0, 1.0}
3. Упорядоченные последовательности:
- Уже отсортированный: {1.0, 2.0, 3.0, 4.0, 5.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
- Обратно отсортированный: {5.0, 4.0, 3.0, 2.0, 1.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
4. Граничные значения порога:
- Ровно 32 элемента (порог kRadixThreshold): массив от 32.0 до 1.0
- 33 элемента (чуть больше порога): массив от 33.0 до 1.0
5. Массивы с дубликатами:
- Все одинаковые: {25, 7.7} → {25, 7.7}
- Дубликаты: {2.0, 2.0, 1.0, 1.0, 3.0, 3.0} → {1.0, 1.0, 2.0, 2.0, 3.0, 3.0}
- Чередование: {1.0, -1.0, 2.0, -2.0, 3.0, -3.0, 4.0, -4.0} → {-4.0, -3.0, -2.0, -1.0, 1.0, 2.0, 3.0, 4.0}
- Смешанные значения: {-10.5, 3.14, 0.0, -3.14, 10.5, -1.0, 1.0} → {-10.5, -3.14, -1.0, 0.0, 1.0, 3.14, 10.5}
6. Разные размеры массивов:
- 50 элементов: обратно отсортированный массив 50..1
- 64 элемента (степень двойки): 64..1 → 1..64
- 127 элементов (не степень двойки): 127..1 → 1..127
- 100 элементов: обратно отсортированный массив 100..1
- 200 элементов: обратно отсортированный массив 200..

Все функциональные тесты успешно пройдены, что подтверждает корректность реализации как последовательной, так и параллельной версий.
### 6.3 Тесты производительности
Тесты производительности проводились на 7 парах массивов вещественных чисел, расположенных в файле test_data.txt. Все массивы записаны в файл парами несортированный + сортированный. Массивы в файле имеют размеры 100 000, 150 000, 200 000, 250 000, 300 000, 350 000, 400 000 элементов.

## 7. Результаты и обсуждение

### 7.1 Корректность
Корректность работы алгоритмов проверялась с помощью:

- 20 функциональных тестов, охватывающих различные сценарии (от 1 до 200 элементов, отрицательные и дробные числа, дубликаты, граничные случаи порога 32 элемента)
- Сравнения результатов с заранее известным верным результатом
- Обработки граничных случаев (массив из одного элемента, уже отсортированные массивы)

Все функциональные тесты успешно пройдены, что подтверждает корректность реализации как последовательной, так и параллельной версий.

### 7.2 Производительность

Результаты выполнения тестов на производительность представлены в таблице:

|Процессы  |Время (сек) |Ускорение (S) |Эффективность (E), %|
|----------|------------|--------------|--------------------|
|SEQ (сред)|0.030956	|1.00	       |100.0               |
|2	       |0.008502	|3.64	       |182.0               |
|4	       |0.008311	|3.73	       |93.3                |
|6	       |0.022069	|1.40	       |23.3                |
|8	       |0.030051	|1.03	       |12.9                |

Формулы расчета:
Ускорение (S) = T_seq / T_mpi
Эффективность (E) = (S / N) × 100%, где N — количество процессов

### 7.3 Анализ результатов

- 2 процесса: Ускорение 3.64× при эффективности 182%. Это превышение эффективности 100% свидетельствует о:
1) Оптимальном использовании кэш-памяти при распределении данных
2) Минимальных накладных расходах на коммуникацию между двумя процессами
3) Эффективной работе иерархического слияния для пары процессов

- 4 процесса: Ускорение 3.73× при эффективности 93.3%. Сохранение высокой эффективности при увеличении числа процессов до 4 подтверждает:
1) Хорошую масштабируемость алгоритма в пределах физических ядер
2) Сбалансированность вычислительной нагрузки
3) Эффективность схемы иерархического слияния для 4 процессов

- 6 процессов: Ускорение 1.40× при эффективности 23.3%. Значительное падение эффективности указывает на:
1) Превышение количества процессов над физическими ядрами (флаг oversubscription)
2) Увеличение накладных расходов на коммуникацию
3) Конкуренцию за вычислительные ресурсы

- 8 процессов: Ускорение 1.03× при эффективности 12.9%. Практическое отсутствие ускорения по сравнению с последовательной версией демонстрирует:
1) Предел масштабируемости алгоритма для данного устройства
2) Преобладание времени коммуникации над временем вычислений
3) Ограничения архитектуры при большом количестве процессов

Эти результаты говорят о том, что оптимальное количество процессов для выполнения данной задачи - 2-4 для системы с 4 физическими ядрами. Лучшая эффективность достигается при использовании 2 процессов. Эффективность превысила 100% (182%), что может объясняться оптимальным использованием кэш-памяти процессора после разбиения большого массива между процессами, в то время как последовательная версия могла вызывать больше промахов кэша.

## 8. Выводы

Параллельная реализация эффективна для 2-4 процессов: достигнуто ускорение 3.64-3.73× по сравнению с последовательной версией при эффективности 93-182%.

Ограничения масштабируемости: алгоритм демонстрирует хорошую масштабируемость до 4 процессов, но при использовании 6-8 процессов эффективность резко падает из-за:

- Превышения количества процессов над физическими ядрами
- Увеличения накладных расходов на коммуникацию
- Конкуренции за вычислительные ресурсы

Алгоритм очень эффективен для массивов размером от 100,000 элементов.
Разработанный гибридный алгоритм поразрядной сортировки с простым слиянием эффективно решает задачу сортировки вещественных чисел и демонстрирует хорошую масштабируемость при использовании оптимального количества процессов, соответствующего характеристикам целевого оборудования.

## 9. References
1. Open MPI Documentation. https://www.open-mpi.org/doc/
2. Учебное пособие "Основы MPI". https://parallel.uran.ru/node/182
3. Cormen, T. H. "Introduction to Algorithms"