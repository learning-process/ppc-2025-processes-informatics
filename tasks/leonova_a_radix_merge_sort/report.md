# Поразрядная сортировка для вещественных чисел с простым слиянием

- Студент: Леонова Анна Сергеевна, группа 3823Б1ФИ1
- Технология: SEQ | MPI
- Вариант: 20

## 1. Введение
В данной работе реализован гибридный алгоритм сортировки вещественных чисел типа double, сочетающий поразрядную сортировку (Radix Sort) и сортировку слиянием (Merge Sort). Алгоритм использует поразрядную сортировку для небольших подмассивов (размером ≤ 32) и слияние для объединения отсортированных частей. Цель работы — сравнить производительность последовательной и параллельной (MPI) реализаций алгоритма на различных наборах данных.

## 2. Постановка задачи
На вход приходит вектор вещественных чисел, о порядке чисел ничего не известно. На выходе необходимо получить вектор такого же размера, все числа в нем должны быть отсортированы в порядку возрастания.

Входные данные: std::vector<double> — вектор вещественных чисел.
Выходные данные: std::vector<double> — отсортированный по возрастанию вектор.

Ограничения и особенности реализации:

- Поддержка специальных значений (NaN, Inf) не предусмотрена.
- В векторе должен быть хотя бы один элемент
- Тип данных в векторе - строго double
- Порог переключения между RadixSort и MergeSort: 32 элемента.

## 3. Базовый алгоритм (Последовательный)

### 3.1 Преобразование double в ключ для сортировки
cpp
uint64_t TransformDoubleToKey(double value) {
    uint64_t int_value;
    memcpy(&int_value, &value, sizeof(double));
    constexpr uint64_t SIGN_BIT_MASK = 0x8000000000000000ULL;
    return (int_value & SIGN_BIT_MASK) ? ~int_value : (int_value | SIGN_BIT_MASK);
}
Это преобразование необходимо, потому что:
- Отрицательные числа в формате IEEE 754 имеют установленный старший бит (знаковый бит)
- Без преобразования они отсортировались бы после положительных
Алгоритм превращает двоичное представление в монотонную последовательность

### 3.2 Поразрядная сортировка (Radix Sort)
Применяется для подмассивов размером ≤ kRadixThreshold (32). Сортировка идет по байтам (8 байт для double). Использует counting sort для каждого байта:
text
Для каждого элемента массива:
    Извлечь текущий байт из ключа (byte_pos от 0 до 7)
    Увеличить счетчик для этого байта

Вычислить префиксные суммы счетчиков

Для каждого элемента массива:
    Определить позицию в выходном массиве через префиксные суммы
    Скопировать элемент в соответствующую позицию

### 3.3 Сортировка слиянием (Merge Sort)
Рекурсивное деление массива. Для подмассивов ≤ 32 используется RadixSort. Слияние отсортированных частей с использованием преобразованных ключей.
text
RadixMergeSort(массив, left, right):
    если (right - left) <= 32:  # Порог kRadixThreshold
        выполнить RadixSort
        вернуться
    иначе:
        mid = left + (right - left) / 2
        RadixMergeSort(left, mid)
        RadixMergeSort(mid, right)
        SimpleRadixMerge(left, mid, right)

### 3.4 Пример сортировки
Исходный массив (34 элемента):
arr = [12.5, -3.2, 7.1, 0.0, -15.8, 42.3, 1.5, -1.5, 9.9, 3.14,
 2.71, -7.7, 5.0, 8.8, -0.5, 10.1, 6.6, 4.4, 11.11, -12.12,
 13.13, 14.14, -8.8, 15.0, 16.1, 17.2, 18.3, -9.9, 19.4, 20.5,
 21.6, 22.7, 23.8, 24.9]

- Шаг 1: Начало рекурсии

RadixMergeSort(arr, 0, 34):
  size = 34 > 32 (порог) → используем Merge Sort
  mid = 0 + 34/2 = 17

а) Рекурсивный вызов левой половины:
RadixMergeSort(arr, 0, 17):
  size = 17 ≤ 32 → используем Radix Sort

Сортируем элементы [0..17] с помощью RadixSort:
Преобразуем все double в ключи через TransformDoubleToKey()

12.5 → 0x4029000000000000 → ключ
-3.2 → 0xC00A666666666666 → ключ
...

Выполняем Counting Sort по 8 байтам:

Байт 0 (младший): сортируем по 0-255
Байт 1: сортируем по 0-255
...
Байт 7 (старший): сортируем по 0-255

Левая половина после RadixSort (первые 17 элементов):
[-15.8, -12.12, -9.9, -8.8, -7.7, -3.2, -1.5, -0.5, 0.0, 
 1.5, 2.71, 3.14, 4.4, 5.0, 6.6, 7.1, 8.8]

б) Рекурсивный вызов правой половины:
RadixMergeSort(arr, 17, 34):
  size = 17 ≤ 32 → используем Radix Sort

Сортируем элементы [17..34] с помощью RadixSort:
Правая половина после RadixSort (элементы 17-34):
[9.9, 10.1, 11.11, 12.5, 13.13, 14.14, 15.0, 16.1, 17.2,
 18.3, 19.4, 20.5, 21.6, 22.7, 23.8, 24.9, 42.3]

- Шаг 2: Слияние двух отсортированных половин

i = 0 (левый индекс), j = 0 (правый индекс), k = 0 (индекс в merged)

Шаг 1: Сравниваем keys[-15.8] и keys[9.9]
        -15.8 < 9.9 → добавляем -15.8 в результат

Шаг 2: Сравниваем keys[-12.12] и keys[9.9]
        -12.12 < 9.9 → добавляем -12.12

... продолжаем пока левые элементы отрицательные ...

Шаг 8: После добавления всех отрицательных чисел:
       Добавлено: [-15.8, -12.12, -9.9, -8.8, -7.7, -3.2, -1.5, -0.5, 0.0, 1.5, 2.71, 3.14, 4.4, 5.0, 6.6, 7.1, 8.8]
       i = 17 (левый массив закончился)
       j = 0 (правый массив еще не начат)

Шаг 9: Добавляем все оставшиеся элементы правого массива:
       [9.9, 10.1, 11.11, 12.5, 13.13, 14.14, 15.0, 16.1, 17.2,
        18.3, 19.4, 20.5, 21.6, 22.7, 23.8, 24.9, 42.3]

- Шаг 3: Итоговый результат
[-15.8, -12.12, -9.9, -8.8, -7.7, -3.2, -1.5, -0.5, 0.0, 1.5,
 2.71, 3.14, 4.4, 5.0, 6.6, 7.1, 8.8, 9.9, 10.1, 11.11, 12.5,
 13.13, 14.14, 15.0, 16.1, 17.2, 18.3, 19.4, 20.5, 21.6, 22.7,
 23.8, 24.9, 42.3]

 Визуальная схема процесса:

            RadixMergeSort(0, 34)
                   │
         size=34 > 32 → Merge Sort
                   │
               mid = 17
                   │
        ┌──────────┴──────────┐
        │                     │
RadixMergeSort(0,17)   RadixMergeSort(17,34)
        │                     │
   size=17 ≤ 32          size=17 ≤ 32
        │                     │
    RadixSort            RadixSort
        │                     │
   [-15.8...8.8]         [9.9...42.3]
        │                     │
        └──────────┬──────────┘
                   │
           SimpleRadixMerge(0,17,34)
                   │
       [-15.8...8.8, 9.9...42.3]

### 3.5 Сложность гибридной сортировки
Radix Sort: O(n × k), где k = 8 (байт в double), константа ≈ O(n)
Merge Sort: O(n log n)
Гибридный подход: O(n log n) в худшем случае, но с меньшей константой для маленьких подмассивов

## 4. Схема распараллеливания

### 4.1 Распределение данных
Массив делится на блоки между процессами и передается с использованием MPI_Scatterv.
cpp
// Вычисление размеров блоков для каждого процесса
int base_size = total_size / world_size_;
int remainder = total_size % world_size_;
for (int i = 0; i < world_size_; ++i) {
    send_counts[i] = base_size + (i < remainder ? 1 : 0);
    if (i > 0) {
        displacements[i] = displacements[i - 1] + send_counts[i - 1];
    }
}

Пример распределения для N=3 процессов и массива из 10 элементов:

Всего элементов: 10
Процессов: 3
Базовый размер: 10 / 3 = 3
Остаток: 10 % 3 = 1

Распределение:
- Процесс 0: 3 + 1 = 4 элемента (индексы 0-3)
- Процесс 1: 3 + 0 = 3 элемента (индексы 4-6) 
- Процесс 2: 3 + 0 = 3 элемента (индексы 7-9)

Каждый процесс сортирует свою часть локально с помощью RadixMergeSort.
Так же учтен случай когда процессов больше чем необходимо.
Если total_size < world_size_, то:

Некоторые процессы получат 0 элементов (send_counts[i] = 0)
Эти процессы пропускают этап локальной сортировки
Участвуют только в коммуникационной схеме

Пример (4 процесса, 2 элемента):

send_counts = [1, 1, 0, 0]
displacements = [0, 1, 2, 2]

- Процесс 0: 1 элемент
- Процесс 1: 1 элемент  
- Процесс 2: 0 элементов (не выполняет сортировку)
- Процесс 3: 0 элементов (не выполняет сортировку)

### 4.2 Иерархическое простое слияние (Hierarchical Merge)
Процессы объединяются попарно на каждом шаге. Отправитель передает данные получателю, который выполняет слияние. Процесс 0 собирает окончательный результат.

step = 1
Пока step < world_size:
    mask = step * 2
    Если rank % mask == 0:
        partner = rank + step
        Если partner существует:
            Получаем данные от partner
            Сливаем свои данные с данными partner
    Иначе если rank % mask == step:
        partner = rank - step
        Отправляем свои данные partner
        Завершаем работу
    step *= 2

Наглядно это можно представить на схеме:

Процесс 0 ──┐
           ├─ Слияние ──┐
Процесс 1 ──┘          
                        ├─ Слияние
Процесс 2 ──┐              
           ├─ Слияние ──┘
Процесс 3 ──┘        

## 5. Детали реализации
Структура проекта:
- common.hpp — общие типы данных.
- ops_seq.hpp/cpp — последовательная реализация.
- ops_mpi.hpp/cpp — параллельная реализация (MPI).
- main.cpp — функциональные и производительные тесты.

Ключевые методы:
- RadixMergeSort() — основной метод сортировки.
- TransformDoubleToKey() — преобразование double в сортируемый ключ.
- HierarchicalMerge() — параллельное слияние в MPI.

## 6. Experimental Setup
### 6.1 Оборудование и ПО
- CPU: Intel Core i5-1135G7 (4 ядра, 8 потоков);
- RAM: 8ГБ;
- ОС: Windows 10 Pro 22H2;
- Тип сборки: Release.

### 6.2 Функциональные тесты
Для проверки корректности реализации использовались 20 тестовых случаев:
1. Базовые случаи:
- 1 элемент: {42.0} → {42.0}
- 2 элемента: {3.14, 2.71} → {2.71, 3.14}
- 5 элементов, случайные: {5.0, 1.0, 4.0, 2.0, 3.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
2. Специальные числовые случаи:
- Отрицательные числа: {-5.0, 0.0, 5.0, -10.0, 10.0} → {-10.0, -5.0, 0.0, 5.0, 10.0}
- Дробные числа: {0.1, 0.01, 0.001, 1.0, 10.0, 100.0} → {0.001, 0.01, 0.1, 1.0, 10.0, 100.0}
- Большой диапазон: {1e10, 1e-10, 1e5, 1e-5, 0.0} → {0.0, 1e-10, 1e-5, 1e5, 1e10}
- Ноль и -ноль: {0.0, -0.0, 1.0, -1.0} → {-1.0, 0.0, 0.0, 1.0}
3. Упорядоченные последовательности:
- Уже отсортированный: {1.0, 2.0, 3.0, 4.0, 5.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
- Обратно отсортированный: {5.0, 4.0, 3.0, 2.0, 1.0} → {1.0, 2.0, 3.0, 4.0, 5.0}
4. Граничные значения порога:
- Ровно 32 элемента (порог kRadixThreshold): массив от 32.0 до 1.0
- 33 элемента (чуть больше порога): массив от 33.0 до 1.0
5. Массивы с дубликатами:
- Все одинаковые: {25, 7.7} → {25, 7.7}
- Дубликаты: {2.0, 2.0, 1.0, 1.0, 3.0, 3.0} → {1.0, 1.0, 2.0, 2.0, 3.0, 3.0}
- Чередование: {1.0, -1.0, 2.0, -2.0, 3.0, -3.0, 4.0, -4.0} → {-4.0, -3.0, -2.0, -1.0, 1.0, 2.0, 3.0, 4.0}
- Смешанные значения: {-10.5, 3.14, 0.0, -3.14, 10.5, -1.0, 1.0} → {-10.5, -3.14, -1.0, 0.0, 1.0, 3.14, 10.5}
6. Разные размеры массивов:
- 50 элементов: обратно отсортированный массив 50..1
- 64 элемента (степень двойки): 64..1 → 1..64
- 127 элементов (не степень двойки): 127..1 → 1..127
- 100 элементов: обратно отсортированный массив 100..1
- 200 элементов: обратно отсортированный массив 200..

Все функциональные тесты успешно пройдены, что подтверждает корректность реализации как последовательной, так и параллельной версий.
### 6.3 Тесты производительности
Данные для тестов на производительность статические и расположены в файле ppc-2025-processes-informatics/tasks/leonova_a_radix_merge_sort/data/test_data.txt
В файле находятся семь пар наборов вещественных чисел (несортированный и сортированный вид) со следующими размерами:

## 7. Результаты и обсуждение

### 7.1 Корректность
Корректность работы алгоритмов проверялась с помощью:

- 20 функциональных тестов, охватывающих различные сценарии (от 1 до 200 элементов, отрицательные и дробные числа, дубликаты, граничные случаи порога 32 элемента)
- Сравнения результатов с заранее известным верным результатом
- Обработки граничных случаев (массив из одного элемента, уже отсортированные массивы)

Все функциональные тесты успешно пройдены, что подтверждает корректность реализации как последовательной, так и параллельной версий.

### 7.2 Производительность

Тесты производительности проводились на 7 массивах вещественных чисел расположенных в файле test_data.txt. Все массивы записаны в файл парами несортированный + сортированный. Массивы в файле имеют размеры размерами 100 000, 150 000, 200 000, 250 000, 300 000, 350 000, 400 000 элементов. Результаты представлены в таблице:


|Процессы  |Время (сек) |Ускорение (S) |Эффективность (E), %|
|----------|------------|--------------|--------------------|
|SEQ (сред)|0.030956	|1.00	       |100.0               |
|2	       |0.008502	|3.64	       |182.0               |
|4	       |0.008311	|3.73	       |93.3                |
|6	       |0.022069	|1.40	       |23.3                |
|8	       |0.030051	|1.03	       |12.9                |

Формулы расчета:
Ускорение (S) = T_seq / T_mpi
Эффективность (E) = (S / N) × 100%, где N — количество процессов

### 7.3 Анализ результатов

- 2 процесса: Ускорение 3.64× при эффективности 182%. Это превышение эффективности 100% свидетельствует о:
1) Оптимальном использовании кэш-памяти при распределении данных
2) Минимальных накладных расходах на коммуникацию между двумя процессами
3) Эффективной работе иерархического слияния для пары процессов

- 4 процесса: Ускорение 3.73× при эффективности 93.3%. Сохранение высокой эффективности при увеличении числа процессов до 4 подтверждает:
1) Хорошую масштабируемость алгоритма в пределах физических ядер
2) Сбалансированность вычислительной нагрузки
3) Эффективность схемы иерархического слияния для 4 процессов

- 6 процессов: Ускорение 1.40× при эффективности 23.3%. Значительное падение эффективности указывает на:
1) Превышение количества процессов над физическими ядрами (флаг oversubscription)
2) Увеличение накладных расходов на коммуникацию
3) Конкуренцию за вычислительные ресурсы

- 8 процессов: Ускорение 1.03× при эффективности 12.9%. Практическое отсутствие ускорения по сравнению с последовательной версией демонстрирует:
1) Предел масштабируемости алгоритма для данного устройства
2) Преобладание времени коммуникации над временем вычислений
3) Ограничения архитектуры при большом количестве процессов

Эти результаты говорят о том, что оптимальное количество процессов для выполнения данной задачи - 2-4 для системы с 4 физическими ядрами. Лучшая эффективность достигается при использовании 2 процессов. Эффективность превысила 100% (182%), что может объясняться оптимальным использованием кэш-памяти процессора после разбиения большого массива между процессами, в то время как последовательная версия могла вызывать больше промахов кэша.

## 8. Выводы

Параллельная реализация эффективна для 2-4 процессов: достигнуто ускорение 3.64-3.73× по сравнению с последовательной версией при эффективности 93-182%.

Ограничения масштабируемости: алгоритм демонстрирует хорошую масштабируемость до 4 процессов, но при использовании 6-8 процессов эффективность резко падает из-за:

- Превышения количества процессов над физическими ядрами
- Увеличения накладных расходов на коммуникацию
- Конкуренции за вычислительные ресурсы

Алгоритм очень эффективен для массивов размером от 100,000 элементов.
Разработанный гибридный алгоритм поразрядной сортировки с простым слиянием эффективно решает задачу сортировки вещественных чисел и демонстрирует хорошую масштабируемость при использовании оптимального количества процессов, соответствующего характеристикам целевого оборудования.

## 9. References
1. Open MPI Documentation. https://www.open-mpi.org/doc/
2. Учебное пособие "Основы MPI". https://parallel.uran.ru/node/182
3. Cormen, T. H. "Introduction to Algorithms"