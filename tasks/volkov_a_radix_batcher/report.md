# Поразрядная сортировка для вещественных чисел (тип double) с четно-нечетным слиянием Бэтчера

- **Студент:** Волков Алексей, группа 3823Б1ФИ2
- **Технология:** SEQ, MPI
- **Вариант:** 21

## 1. Введение
Сортировка больших массивов данных является одной из фундаментальных задач в параллельном программировании. Поразрядная сортировка (Radix Sort) обладает линейной временной сложностью $O(N)$, что делает её крайне эффективной для больших объемов данных. Однако классическая реализация работает только с целыми числами. Для применения к типу `double` требуется специфическое битовое преобразование, сохраняющее порядок сравнения.

Целью данной лабораторной работы является реализация параллельного алгоритма сортировки, сочетающего локальную поразрядную сортировку (Radix Sort) и глобальное слияние частей массива между процессами с использованием схемы четно-нечетного слияния Бэтчера (Batcher's Odd-Even Merge).

## 2. Постановка задачи
Необходимо реализовать два класса (задачи) в рамках заданного фреймворка:
1.  **SEQ (`VolkovARadixBatcherSEQ`):** Последовательная версия для проверки корректности и замера базового времени.
2.  **MPI (`VolkovARadixBatcherMPI`):** Параллельная версия, использующая интерфейс передачи сообщений.

**Формальные требования:**
- **Входные данные (`InType`):** `std::vector<double>`.
- **Выходные данные (`OutType`):** `std::vector<double>`, содержащий элементы входного вектора в неубывающем порядке.
- **Условия:**
    - Результат на корневом процессе (rank 0) должен совпадать с эталонной сортировкой `std::ranges::sort`.
    - Алгоритм должен корректно обрабатывать пустые векторы и векторы с произвольным распределением значений (включая отрицательные числа).
    - Параллельное взаимодействие должно быть реализовано через `MPI_Scatterv`, `MPI_Gatherv` и `MPI_Sendrecv`.

## 3. Базовый алгоритм (Sequential)
В основе лежит **LSD (Least Significant Digit) Radix Sort**. Для работы с `double` (IEEE 754) применяется следующий метод:

1.  **Битовое отображение (Mapping):** `double` копируется в `uint64_t`.
    - Если число отрицательное (знаковый бит = 1), инвертируются все биты.
    - Если число положительное (знаковый бит = 0), инвертируется только знаковый бит.
    - *Результат:* Полученные `uint64_t` можно сравнивать как обычные беззнаковые числа, и их порядок будет соответствовать порядку исходных `double`.
2.  **Сортировка:** Выполняется побайтовая сортировка подсчетом (Counting Sort) — 8 проходов по 8 бит (256 корзин).
3.  **Обратное отображение:** Восстановление исходного `double` из отсортированных `uint64_t`.

## 4. Схема распараллеливания
Для MPI-версии выбрана стратегия геометрического параллелизма (Domain Decomposition):

1.  **Распределение данных:**
    - Входной массив делится на части. Используется `MPI_Scatterv` для рассылки частей по процессам.

2.  **Локальная сортировка:**
    - Каждый процесс независимо сортирует свой кусок данных алгоритмом Radix Sort (см. п. 3).

3.  **Сеть слияния Бэтчера (Batcher's Odd-Even Merge):**
    - В отличие от простой линейной схемы, используется итеративная сеть слияния.
    - Алгоритм состоит из итераций по размеру объединяемых блоков (`stage`: 1, 2, 4...) и шагу сравнения (`step`: stage, stage/2 ... 1).
    - **Логика обмена:**
        - На каждом шаге определяются пары процессов-партнеров на расстоянии `step`.
        - Если пара должна выполнять сравнение (согласно логике компараторов Бэтчера), происходит обмен данными (`MPI_Sendrecv`).
        - Процесс с меньшим рангом оставляет себе "младшую" половину объединенного массива, процесс с большим рангом — "старшую".
    - Количество этапов коммуникации составляет $O(\log^2 P)$, что значительно эффективнее линейной схемы $O(P)$ для большого числа процессов.

4.  **Сбор результатов:**
    - Итоговый массив собирается на Rank 0 с помощью `MPI_Gatherv`.

## 5. Детали реализации

**Файловая структура:**
- `volkov_a_radix_batcher/seq/src/ops_seq.cpp`: Класс `VolkovARadixBatcherSEQ`. Содержит методы `DoubleToOrderedInt` и `RadixSortDouble`.
- `volkov_a_radix_batcher/mpi/src/ops_mpi.cpp`: Класс `VolkovARadixBatcherMPI`. Реализует `ParallelMergeSort` и вспомогательные функции.

## 6. Экспериментальное окружение

### Окружение

- **CPU**: Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz (6 ядер, 12 потоков).
- **OC**: Ubuntu 22.04.2 LTS (запущенная через Docker Engine v28.5.2 на Windows 11).
- **Компилятор**: g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0.

### Производительность
Замеры времени для массива размера $2 \cdot 10^6$:

| Mode | Count | Time, s | Speedup | Efficiency |
|------|-------|---------|---------|------------|
| seq  | 1     | 0.450   | 1.00    | 100%       |
| mpi  | 2     | 0.240   | 1.87    | 93.5%      |
| mpi  | 4     | 0.145   | 3.10    | 77.5%      |
| mpi  | 8     | 0.105   | 4.28    | 53.5%      |

Использование сети Бэтчера позволяет сократить количество этапов синхронизации по сравнению с простейшими схемами. Однако, при малом объеме данных на процесс, накладные расходы на передачу полных массивов между узлами начинают доминировать над вычислениями, что снижает эффективность на 8 процессах. Также влияние оказывает архитектура процессора (6 физических ядер при запуске 8 процессов).

## 7. Заключение
В ходе лабораторной работы успешно реализована параллельная поразрядная сортировка вещественных чисел.
1. Механизм битового преобразования позволил использовать эффективный алгоритм Radix Sort для типа `double`.
2. Реализована масштабируемая схема глобального слияния на основе сети Бэтчера ($O(\log^2 P)$ этапов).
3. Достигнуто ускорение в ~4.3 раза на 8 процессах.

## 8. Список литературы
1. Лекции и практики курса "Параллельное программирование для кластерных систем".
2. Стандарт MPI (форум MPI).
3. Документация по C++.