# Параллельная сортировка пузырьком (Четно-нечетная перестановка)

- Студент: Волков Алексей Иванович, 3823Б1ФИ2
- Технология: SEQ | MPI
- Вариант: 21

## 1. Введение
Сортировка данных — фундаментальная операция в информатике. В то время как обычная сортировка пузырьком неэффективна ($O(N^2)$) для последовательного выполнения, её модификация — четно-нечетная перестановка (Odd-Even Transposition Sort) — идеально подходит для распараллеливания на топологиях типа "линейная цепочка". Целью данной работы является реализация этого алгоритма с использованием технологии MPI для распределения нагрузки. Ожидается получение значительного ускорения за счет комбинации декомпозиции данных и гибридного подхода (быстрая локальная сортировка + распределенный обмен).

## 2. Постановка задачи
**Определение:**
Дана последовательность из $N$ целых чисел $A = \{a_0, a_1, \dots, a_{N-1}\}$ и набор из $P$ процессов.
Необходимо переупорядочить элементы таким образом, чтобы:
1. данные были разбиты на части между $P$ процессами;
2. глобальная последовательность была отсортирована: $a'_i \le a'_{i+1}$ для всех $0 \le i < N-1$;
3. для любых двух процессов с рангами $r$ и $r+1$ выполнялось условие $\max(LocalBuf_r) \le \min(LocalBuf_{r+1})$.

**Ограничения:**
- модель распределенной памяти (MPI).
- входные данные могут быть произвольными целыми числами.
- $N$ может не делиться на $P$ нацело.

## 3. Базовый алгоритм (SEQ)
В качестве базового алгоритма используется оптимизированная четно-нечетная сортировка, реализованная в классе `OddEvenSortSeq`.
**Шаги алгоритма:**
1. цикл выполняется, пока массив не станет отсортированным;
2. **нечетная фаза:** Сравнение и обмен элементов с индексами $(2k+1, 2k+2)$;
3. **четная фаза:** Сравнение и обмен элементов с индексами $(2k, 2k+1)$;
4. если за обе фазы не произошло ни одного обмена, алгоритм завершается.

**Сложность:** $O(N^2)$ в худшем случае.

## 4. Схема распараллеливания
Реализована схема **блочной декомпозиции** в сочетании с операцией **Compare-and-Split**.

**Распределение данных:**
- Размер входа $N$ рассылается всем процессам.
- Массив разбивается на блоки размера $\approx N/P$ с помощью `MPI_Scatterv` (для обработки остатков от деления).

**Логика алгоритма (Гибридная):**
1. **локальная сортировка:** Каждый процесс сортирует свой блок, используя `std::ranges::sort` (IntroSort, сложность $O(M \log M)$, где $M = N/P$). Это ключевая оптимизация по сравнению с чистым пузырьком;
2. **глобальные итерации:** Выполняется $P$ итераций:
    - **четный шаг:** Ранг $2k$ обменивается с $2k+1$;
    - **нечетный шаг:** Ранг $2k+1$ обменивается с $2k+2$;
3. **Compare-and-Split (Сравнение и разделение):**
    - процессы $i$ и $j$ ($i < j$) обмениваются буферами;
    - оба процесса сливают данные во временный буфер размера $2M$;
    - процесс $i$ оставляет себе нижнюю половину (меньшие элементы);
    - процесс $j$ оставляет себе верхнюю половину (большие элементы);

**Топология:** линейная (1D).

## 5. Детали реализации
- **Структура:**
    - `ops_seq.hpp/cpp`: последовательная реализация.
    - `ops_mpi.hpp/cpp`: MPI реализация.
    - `common.hpp`: определения типов (`std::vector<int>`).
- **Ключевые методы:**
    - `PerformCompareSplit`: статический метод для выполнения `MPI_Sendrecv` и слияния `std::ranges::merge`.
    - `GetNeighbor`: логика определения ранга партнера в зависимости от текущей фазы.
- **Работа с памятью:** использование `std::vector` для динамического управления памятью. Использование `MPI_Sendrecv` предотвращает взаимные блокировки (deadlocks).
- **Граничные случаи:**
    - $N < P$: обрабатывается корректно (некоторые процессы получают пустые буферы);
    - $N=0$ или $N=1$: ранний выход;
    - уже отсортированный или обратно отсортированный массив.

## 6. Экспериментальное окружение
- **CPU:** Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz (6 ядер, 12 потоков),
- **OC:** CPU,
- **Компилятор:** g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0.

## 7. Результаты и обсуждение

### 7.1 Корректность

### 7.2 Производительность
Результаты для сортировки 50 000 целых чисел:

| Mode | Count | Time, s | Speedup | Efficiency |
|------|-------|---------|---------|------------|
| seq  | 1     | 1.2481  | 1.00    | N/A        |
| mpi  | 2     | 0.3015  | 4.11    | 207.0%     |
| mpi  | 4     | 0.0884  | 14.12   | 353.0%     |
| mpi  | 8     | 0.0321  | 38.88   | 648.0%     |
| mpi  | 12    | 0.0185  | 67.27   | 560.6%     |


**Обсуждение:**
Наблюдаемое **суперлинейное ускорение** (эффективность > 100%) объясняется алгоритмическим изменением. Последовательная версия работает за $O(N^2)$. Параллельная версия фактически работает за $O(\frac{N}{P} \log \frac{N}{P})$ на этапе локальной сортировки плюс накладные расходы на $P$ линейных слияний. Кроме того, разбиение данных позволяет рабочему набору каждого процесса помещаться в кэш процессора (L1/L2), что значительно снижает задержки памяти.

## 8. Заключение
Алгоритм четно-нечетной перестановки успешно реализован с использованием MPI. Гибридный подход (локальная быстрая сортировка + глобальный обмен) показал высокую эффективность, продемонстрировав значительное ускорение по сравнению с наивной последовательной сортировкой пузырьком. Реализация устойчива к различным входным данным и корректно управляет ресурсами.

## 9. Список литературы
1. лекции и практики курса "Параллельное программирование для кластерных систем";
2. стандарт MPI (форум MPI);
3. документация по C++;