# Передача от всех одному (reduce)

**Студент:** Кондаков Владислав Сергеевич, группа 3823Б1ФИ1  
**Технологии:** SEQ, MPI  
**Вариант:** 2

---

## 1. Введение

Операция reduce является одной из базовых операций параллельных вычислений и используется для сведения массива данных к одному значению. К таким операциям относятся сумма, произведение, минимум и максимум.

Последовательная реализация операции reduce проста и эффективна, однако при больших объёмах данных возможно применение параллельных технологий. В данной работе используется MPI для параллельной реализации операции reduce.

Цель работы - реализовать и сравнить последовательную и MPI-версии операции reduce.

---

## 2. Постановка задачи

Требуется реализовать алгоритм свёртки одномерного массива целых чисел с использованием одной из операций:

- сумма,
- произведение,
- минимум,
- максимум.

### Входные данные

- Вектор целых чисел `vector<int>`
- Тип операции reduce

### Выходные данные

- Одно целое число - результат операции reduce.

---

## 3. Последовательный алгоритм (SEQ)

Последовательный алгоритм выполняет линейный проход по массиву:

1. Начальное значение инициализируется первым элементом массива.
2. Каждый следующий элемент объединяется с текущим результатом выбранной операцией.
3. После завершения обхода возвращается итоговое значение.

Временная сложность алгоритма — **O(n)**.

---

## 4. Схема параллельной обработки (MPI)

### Распределение данных

Исходный массив равномерно распределяется между процессами MPI. При наличии остатка первые процессы получают по одному дополнительному элементу.

### Локальная обработка

Каждый процесс независимо вычисляет операцию reduce для своего локального подмассива. Если процесс не получил данных, используется нейтральный элемент операции.

### Сбор результатов

Частичные результаты объединяются по схеме **бинарного дерева** с использованием `MPI_Send` и `MPI_Recv`. Финальный результат формируется на процессе с `rank = 0`.

---

## 5. Детали реализации

Структура проекта:

- `common` — общие типы и функции,
- `seq` — последовательная реализация,
- `mpi` — MPI-реализация,
- `tests` — функциональные и performance-тесты.

---

## 6. Окружение

- **CPU:** AMD Ryzen 5 5650U  
- **RAM:** 16 GB  
- **ОС:** Ubuntu 22.04  
- **Компилятор:** Clang (Release)  
- **MPI:** OpenMPI  

---

## 7. Результаты и обсуждение

### 7.1 Проверка корректности

Корректность реализации подтверждена выполнением всех функциональных тестов.  
Результаты последовательной и MPI-версий совпадают. Проверка осуществляется на процессе с `rank = 0`.

---

### 7.2 Производительность

Тестирование проводилось на массиве из **5 000 000** элементов для операции суммы (`task_run`, `kondakov_v_reduce`).

| Mode | Count | Time (s) | Speedup | Efficiency |
|------|-------|----------|---------|------------|
| seq  | 1 | 0.0020496 | 1.00 | – |
| mpi  | 2 | 0.0012106 | 1.69 | 0.85 |
| mpi  | 4 | 0.0009513 | 2.15 | 0.54 |
| mpi  | 6 | 0.0003832 | 5.35 | 0.89 |

---

### Обсуждение результатов

Полученные результаты показывают, что параллельная версия операции reduce демонстрирует ускорение при увеличении числа процессов. Однако эффективность параллелизации остаётся ограниченной из-за накладных расходов MPI на коммуникацию и синхронизацию, а также отсутствия низкоуровневых оптимизаций.

---

## 8. Заключение

В работе были реализованы последовательная и MPI-версии операции reduce над массивом целых чисел. Реализация корректна для всех поддерживаемых операций.

MPI-реализация использует схему бинарного дерева и обеспечивает ускорение при увеличении числа процессов, однако эффективность снижается из-за доминирования накладных расходов над вычислениями при простой арифметической нагрузке.

---

## 9. Список литературы

1. MPI Standard Documentation — https://www.mpi-forum.org/docs/  
2. Лекции по параллельному программированию
