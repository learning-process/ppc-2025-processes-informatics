# Отчет по лабораторной работе №2.
## "Умножение матриц. Ленточные схемы"

**Студент:** Шеленкова Мария Сергеевна  
**Группа:** 3823Б1ФИ1  
**Вариант:** 14

### 1. Введение
**Мотивация.** Умножение матриц является базовой операцией во множестве научных и инженерных задач. Исследование полосового распараллеливания помогает оценить эффективность простых схем распределения данных.  
**Проблематика.** Необходимо обеспечить равномерное распределение строк матрицы `A` и избежать лишних коммуникаций при передаче `B`.  
**Ожидаемый результат.** Ленточная схема должна демонстрировать ускорение уже на умеренных размерах входных данных благодаря значительной вычислительной нагрузке.

### 2. Постановка задачи
**Задано:** матрицы `A (m x k)` и `B (k x n)` с вещественными элементами.  
**Требуется:** вычислить матрицу `C = A x B`.  
**Входные данные:** структуры `Matrix` с полями размеров и одномерными массивами значений.  
**Выходные данные:** матрица `C` с размерами `m x n`.

### 3. Последовательный алгоритм
1. Проверяются размерности и целостность входных данных.
2. Создается результирующая матрица `C`, инициализируемая нулями.
3. Выполняется тройной цикл по индексам `i`, `j`, `t` с накоплением суммы `A[i][t] * B[t][j]`. Для лучшей локальности используется заранее вычисленная транспонированная матрица `B`.
4. Сложность алгоритма составляет `O(m * k * n)`, дополнительные затраты памяти обусловлены хранением `C` и транспонированного `B`.

### 4. Схема распараллеливания
**Декомпозиция данных.** Строки матрицы `A` делятся на блоки, различающиеся максимум на одну строку. Каждый процесс получает свой фрагмент.  
**Коммуникация.** Метаданные и матрица `B` рассылаются через `MPI_Bcast`. После локальных вычислений блоки результата собираются на корневом процессе с помощью `MPI_Gatherv`; при необходимости матрица `C` распространяется обратно.  
**Синхронизация.** Количество коллективных операций ограничено двумя вызовами, дополнительных барьеров не требуется.

### 5. Экспериментальная установка
* Процессор: 13th Gen Intel(R) Core(TM) i9-13980HX (24 физических ядра, 32 логических потока).
* Оперативная память: 32 GB.
* Операционная система: Microsoft Windows 11 Pro.
* Компилятор: MSVC 19.40, конфигурация Release x64.
* MPI-библиотека: Microsoft MPI 10.1.12498.52.

### 6. Результаты и обсуждение
#### 6.1. Корректность
Проверка выполнена командой `ppc_func_tests.exe --gtest_filter=*matrix_band_multiplication*`. Тестовый набор включает прямоугольные и квадратные матрицы; расхождений между последовательной и параллельной версиями не обнаружено.

#### 6.2. Производительность
Измерения проводились при помощи `ppc_perf_tests.exe`. Последовательная реализация запускалась на одном процессе, параллельная - на восьми (`mpiexec -n 8`).

| Реализация | Процессов | Режим теста | Время, сек |
|-----------:|----------:|-------------|-----------:|
| seq        | 1         | pipeline    | 0.0040988 |
| seq        | 1         | task_only   | 0.0038847 |
| mpi        | 8         | pipeline    | 0.0020780 |
| mpi        | 8         | task_only   | 0.0007786 |

Полная конвейерная цепочка на восьми процессах приблизительно вдвое быстрее, чем последовательная реализация. Время рассылки матрицы `B` и сборки результата заметно, но не перекрывает выгоду от параллельных вычислений.

### 7. Выводы
Полосовое разбиение обеспечивает корректную работу и ускорение при увеличении числа процессов. Реализация удовлетворяет требованиям варианта и может служить базой для дальнейших улучшений, включая переход к блочному распределению.
