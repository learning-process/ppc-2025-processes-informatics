# Параллельное вычисление двойного интеграла методом Симпсона с использованием MPI

**Дисциплина:** Параллельное программирование  
**Преподаватель:** Нестеров Александр Юрьевич, Оболенский Арсений Андреевич  
**Студент:** Спичек Денис Игоревич  
**Группа:** 3823Б1ФИ1  
**Вариант:** 9  

---

## Введение

Распараллеливание является ключевым подходом для ускорения вычислений в наукоемких задачах.  
В данной работе рассматривается реализация алгоритма вычисления двойного интеграла

\[
\iint f(x, y)\,dx\,dy
\]

на прямоугольной области \([0, 1] \times [0, 1]\) с использованием составной формулы Симпсона.  
Реализация выполнена как в последовательной, так и в параллельной форме с применением технологии **MPI (Message Passing Interface)**.

**Цель работы** — реализовать и сравнить эффективность последовательного и параллельного алгоритмов вычисления двойного интеграла, а также подтвердить корректность MPI-версии.

---

## Постановка задачи

Необходимо вычислить двойной интеграл от функции

\[
f(x, y) = x^2 + y^2
\]

на области \([0, 1] \times [0, 1]\) с использованием составной формулы Симпсона.

---

## Аналитическое решение

Аналитическое значение интеграла:

\[
\iint_{[0,1]^2} (x^2 + y^2)\,dx\,dy = \frac{2}{3} \approx 0.666\ldots
\]

Для целей тестирования результат округляется до ближайшего целого числа:

\[
\text{round}\left(\frac{2}{3}\right) = 1
\]

---

## Требуется

- Реализовать последовательную версию вычисления (формула Симпсона для двойного интеграла);  
- Реализовать параллельную версию с использованием MPI;  
- Провести сравнение времени выполнения и подтвердить корректность вычислений.

---

## Описание алгоритма

Двойной интеграл

\[
\iint_R f(x, y)\,dx\,dy
\]

на прямоугольной области  
\(R = [a, b] \times [c, d]\)  
с использованием составной формулы Симпсона при \(N\) разбиениях по каждой координате (где \(N\) — чётное) вычисляется по формуле:

\[
\iint_R f(x, y)\,dx\,dy \approx
\frac{h_x h_y}{9}
\sum_{i=0}^{N} \sum_{j=0}^{N} w_i w_j f(x_i, y_j)
\]

где:

- \(h_x = h_y = h = \frac{1}{N}\) (для области \([0, 1] \times [0, 1]\));  
- весовые коэффициенты \(w_k\) определяются так:
  - \(w_0 = 1\);  
  - \(w_N = 1\);  
  - \(w_k = 4\), если \(k\) нечётное;  
  - \(w_k = 2\), если \(k\) чётное и \(k \neq 0, N\).

---

## 1. Последовательный алгоритм (`ops_seq.cpp`)

Последовательный алгоритм выполняет прямой расчёт двойной суммы, используя два вложенных цикла и функцию `GetSimpsonWeight` для определения весовых коэффициентов \(w_i\) и \(w_j\).

Итоговый результат вычисляется по формуле:

\[
\text{result} = \frac{\text{sum} \cdot h \cdot h}{9.0}
\]

---

## 2. Параллельный алгоритм (`ops_mpi.cpp`)

В параллельной версии используется распределение работы по внешнему циклу (по индексу \(i\)).

Основные этапы:

1. **Инициализация MPI** и определение ранга процесса (`rank`) и числа процессов (`size`);  
2. **Распространение данных:** число разбиений \(N\) рассылается всем процессам с помощью `MPI_Bcast`;  
3. **Распределение нагрузки:** каждый процесс вычисляет локальную сумму `local_sum` для непересекающихся значений индекса \(i\) с шагом, равным числу процессов (`size`):

```cpp
// Distribute rows (i) among processes
for (int i = rank; i <= n; i += size) {
    // ... внутренний цикл по j ...
}
```

4. **Сбор результатов:** частичные суммы собираются и суммируются в глобальную сумму `global_sum` с помощью `MPI_Allreduce` с операцией `MPI_SUM`;  
5. **Финальный результат:** каждый процесс вычисляет итоговое значение интеграла:

\[
\text{result} = \frac{\text{global\_sum} \cdot h \cdot h}{9.0}
\]

---

## Описание программной реализации (MPI-версия)

Реализация выполнена на языке **C++** с использованием библиотеки **MPI** в классе `SpichekDSimpsonIntegralMPI`.

Ключевые особенности реализации:

- блочно-циклическое распределение работы по внешнему индексу \(i\), обеспечивающее балансировку нагрузки;  
- обмен данными сводится к одной коллективной операции `MPI_Allreduce`;  
- весовые коэффициенты вычисляются с помощью функции `GetSimpsonWeight`.

---

## Результаты экспериментов

### Условия экспериментов

- Число разбиений: \(N = 10000\);  
- Среда: Windows, MS-MPI;  
- Оборудование: локальная рабочая станция;  
- Методика: измерение времени встроенными средствами тестового фреймворка, усреднённые значения для режима *pipeline*.

---

### Результаты замеров времени (pipeline)

| Кол-во процессов (MPI) | Время MPI (сек) | Время SEQ (сек) | Ускорение (отн. MPI-1) | Примечание |
|------------------------|-----------------|-----------------|------------------------|------------|
| 1 | 0.0978 | 0.0972 | 1.00× | Базовое время MPI/SEQ |
| 2 | 0.0501 | 0.0996 | 1.95× | Значительное ускорение |
| 3 | 0.0373 | 0.1052 | 2.62× | Хорошая масштабируемость |
| 4 | 0.0269 | 0.1095 | 3.64× | Лучшее время выполнения |

---

## Анализ результатов

### Сравнение MPI и SEQ

- В задаче вычисления двойного интеграла сложность алгоритма составляет \(O(N^2)\), что обеспечивает высокий выигрыш от распараллеливания;  
- Для одного MPI-процесса время выполнения сопоставимо с последовательной версией;  
- Начиная с двух процессов MPI-версия демонстрирует значительное ускорение.

### Масштабируемость MPI

- При увеличении числа процессов с 1 до 4 время выполнения уменьшилось с 0.0978 с до 0.0269 с;  
- Достигнуто ускорение ≈ 3.64, что близко к идеальному ускорению в 4 раза.

---

## Подтверждение корректности

Функциональные тесты для различных значений \(N\) (10, 20, 40) и для обоих режимов (SEQ и MPI) завершились со статусом **[ PASSED ]**.  

Результаты параллельных вычислений полностью совпадают с последовательной реализацией и аналитическим значением \(\approx 0.666\) (округлённым до 1).

---

## Выводы

- Реализованы последовательная и параллельная (MPI) версии алгоритма вычисления двойного интеграла методом Симпсона;  
- Параллельная реализация демонстрирует хорошую масштабируемость и ускорение до 3.64 раза на 4 процессах;  
- Показано, что для вычислительно сложных задач преимущества MPI перевешивают накладные расходы на коммуникации;  
- Эффективно использованы коллективные операции `MPI_Bcast` и `MPI_Allreduce`.
