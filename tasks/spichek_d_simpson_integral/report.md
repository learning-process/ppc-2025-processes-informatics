# Отчёт по лабораторной работе
## «Параллельное вычисление двойного интеграла методом Симпсона с использованием MPI»

**Дисциплина:** Параллельное программирование  
**Преподаватель:** Нестеров Александр Юрьевич и Оболенский Арсений Андреевич  
**Студент:** Спичек Денис Игоревич 3823Б1ФИ1  
**Вариант:** 9  

---

## Введение

Распараллеливание является ключевым подходом для ускорения вычислений в наукоемких задачах. В данной работе рассматривается реализация алгоритма вычисления двойного интеграла

\[
\iint f(x, y) \, dx \, dy
\]

на прямоугольной области \([0, 1] \times [0, 1]\) с использованием составной формулы Симпсона. Реализация выполнена как в последовательной, так и в параллельной форме с использованием технологии MPI (Message Passing Interface).

**Цель работы** — реализовать и сравнить эффективность последовательного и параллельного алгоритмов вычисления двойного интеграла, а также подтвердить корректность MPI-версии.

---

## Постановка задачи

Необходимо вычислить двойной интеграл от функции

\[
f(x, y) = x^2 + y^2
\]

на области \([0, 1] \times [0, 1]\) с использованием составной **формулы Симпсона**.

### Аналитическое решение
Аналитическое значение интеграла:

\[
\iint_{[0, 1]^2} (x^2 + y^2) \, dx \, dy = \frac{2}{3} \approx 0.666\ldots
\]

Результат округляется до ближайшего целого числа для тестирования: 

\[
\text{round}\left(\frac{2}{3}\right) = 1
\]

### Требуется:
1.  Реализовать **последовательную версию** вычисления (формула Симпсона для двойного интеграла).
2.  Реализовать **параллельную версию** с использованием **MPI**.
3.  Провести сравнение времени выполнения и подтвердить корректность вычислений.

---

## Описание алгоритма

Двойной интеграл 

\[
\iint_R f(x, y) \, dx \, dy
\]

на прямоугольной области \(R = [a, b] \times [c, d]\) с использованием составной формулы Симпсона при \(N\) разбиениях по каждой координате (\(N\) — чётное) вычисляется по формуле:

\[
\iint_R f(x, y) \, dx \, dy \approx \frac{h_x h_y}{9} \sum_{i=0}^{N} \sum_{j=0}^{N} w_i w_j f(x_i, y_j)
\]

где \(h_x = h_y = h = 1/N\) (для области \([0,1] \times [0,1]\)), а весовые коэффициенты \(w_k\) определяются так:

* \(w_0 = 1\)  
* \(w_N = 1\)  
* \(w_k = 4\), если \(k\) нечётное  
* \(w_k = 2\), если \(k\) чётное и \(k \neq 0, N\)

---

### 1. Последовательный алгоритм (`ops_seq.cpp`)

Последовательный алгоритм выполняет прямой расчёт двойной суммы. Он использует два вложенных цикла и вспомогательную функцию `GetSimpsonWeight` для определения весовых коэффициентов \(w_i\) и \(w_j\). Итоговый результат вычисляется как 

\[
\text{result} = \frac{\text{sum} \cdot h \cdot h}{9.0}
\]

---

### 2. Параллельный алгоритм (`ops_mpi.cpp`)

В параллельной версии используется распределение работы по внешнему циклу (по индексу $i$) с помощью **блочно-циклического распределения**:

1.  **Инициализация MPI** и определение ранга (`rank`) и числа процессов (`size`).
2.  **Распространение данных:** Число разбиений $N$ рассылается всем процессам с помощью `MPI_Bcast`.
3.  **Распределение нагрузки:** Каждый процесс вычисляет свою локальную сумму (`local_sum`) для непересекающихся рядов (индексов $i$) с шагом, равным общему числу процессов (`size`):
    ```cpp
    for (int i = rank; i <= n; i += size) {
        // ...
    }
    ```
4.  **Сбор результатов:** Частичные суммы (`local_sum`) собираются и суммируются в глобальную сумму (`global_sum`) с использованием коллективной операции `MPI_Allreduce` с операцией `MPI_SUM`.
5.  **Финальный результат:** Каждый процесс вычисляет итоговый интеграл: `result = global_sum * h * h / 9.0`.

---

## Описание программной реализации (MPI-версия)

Реализация выполнена на языке **C++** с использованием **библиотеки MPI** в классе `SpichekDSimpsonIntegralMPI`.

**Ключевые особенности реализации:**
-   Используется блочно-циклическое распределение работы по внешнему индексу $i$, обеспечивающее хорошую балансировку нагрузки.
-   Обмен данными минимизирован до единственной операции `MPI_Allreduce` для сбора частичных сумм, что является эффективным подходом для задач типа "Вычислить и Собрать".
-   Для обработки весовых коэффициентов используется вспомогательная функция `GetSimpsonWeight`.

---

## Результаты экспериментов

### Условия экспериментов
-   **Входной параметр (количество разбиений N):** $10000$.
-   **Среда выполнения:** Windows, MS-MPI.
-   **Оборудование:** Локальная рабочая станция.
-   **Методика:** Измерение времени проводилось встроенными средствами тестового фреймворка. Приведены усредненные значения времени выполнения для режима `pipeline`.

### Результаты замеров времени (pipeline)

| Кол-во процессов (MPI) | Время MPI (сек) | Время SEQ (сек) | Ускорение (отн. MPI-1) | Примечание |
|:---:|---:|---:|:---:|:---|
| **1** | 0.0978 | 0.0972 | 1.00x | Базовое время MPI/SEQ |
| **2** | 0.0501 | 0.0996 | 1.95x | Значительное ускорение |
| **3** | 0.0373 | 0.1052 | 2.62x | Хорошая масштабируемость |
| **4** | 0.0269 | 0.1095 | 3.64x | Лучшее время выполнения |

### Анализ результатов

1.  **Сравнение MPI vs SEQ:**
    В данной задаче (двойной интеграл) сложность вычислений (двойная сумма $O(N^2)$) достаточно велика, и выигрыш от распараллеливания **превышает** накладные расходы MPI. Начиная с 2 процессов, MPI-версия становится **быстрее** последовательной.

2.  **Масштабируемость MPI:**
    Наблюдается **положительная масштабируемость**. При увеличении числа процессов с **1 до 4** время выполнения сократилось с **0.0978 с до 0.0269 с**. Достигнутое ускорение составляет примерно **3.64 раза**, что близко к идеальному ускорению в 4 раза и подтверждает эффективность распараллеливания.

---

## Подтверждение корректности
Результаты функциональных тестов для обоих режимов (SEQ и MPI) прошли успешно для различных значений $N$ (10, 20, 40). Итоговые суммы, вычисленные параллельно, полностью совпадают с результатами последовательного алгоритма и ожидаемым аналитическим значением $\approx 0.666$ (округленным до 1).

---

## Выводы
1.  Реализованы две версии алгоритма вычисления двойного интеграла методом Симпсона — последовательная и MPI.
2.  Параллельная реализация успешно масштабируется: при добавлении процессов (с 1 до 4) достигнуто ускорение в **3.64 раза**.
3.  Продемонстрировано, что для задач с высокой вычислительной сложностью, преимущества параллелизма с использованием MPI перевешивают коммуникационные накладные расходы.
4.  Успешно использованы коллективные операции MPI (`Bcast`, `Allreduce`) для синхронизации и сбора результатов.