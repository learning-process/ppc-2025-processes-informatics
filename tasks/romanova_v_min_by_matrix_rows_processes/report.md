# Нахождение минимальных значений по строкам матрицы

- Студентка: Романова Василиса Дмитриевна, группа 3823Б1ФИ3
- Технология: SEQ, MPI
- Вариант: 17

## 1. Введение
В рамках данной работы рассматривается задача освоения базовых возможностей MPI на примере реализации алгоритма поиска минимума в строках матрицы. Эта операция агрегации данных является распространенной в таких областях, как научные вычисления и машинное обучение, однако при последовательном выполнении становится узким местом из-за больших объемов данных. Ожидается, что параллельная реализация позволит добиться снижения времени работы алгоритма за счет распределения вычислительной нагрузки между несколькими процессами.

## 2. Постановка задачи
На вход подается матрица, необходимо найти минимальные значения в каждой из ее строк.

- **Входные данные:** `std::vector<std::vector<int>>`.
- **Выходные данные:** `std::vector<int>` — вектор минимальных значений, на i-ой позиции расположено минимальное значение в i-ой строке матрицы.

**Ограничения:** матрица и её строки должны быть непустыми.

## 3. Базовый алгоритм (последовательный)
Программа итерируется по строкам матрицы. Для каждой строки временная переменная `min_val` инициализируется 0-ым значением в строке, затем запускается обход всех элементов строки. На каждом шаге переменной `min_val` присваивается минимум из её текущего значения и значения просматриваемого элемента строки. В конце обхода i-ой строки полученное минимальное значение сохраняется в `res_[i]`, где `res_` — вектор минимальных значений.

## 4. Описание параллельного алгоритма
Параллельная реализация алгоритма основана на распределении строк матрицы между несколькими процессами. Распределение строк осуществляется процессом с рангом 0, который вычисляет количество строк для обработки каждым процессом. Если общее количество строк не кратно числу процессов, оставшиеся строки назначаются процессу с наибольшим рангом. Полученные данные рассылаются всем процессам с помощью функции `MPI_Bcast`.
На основе этой информации каждый процесс независимо определяет начальный и конечный индексы обрабатываемых строк, после чего приступает к поиску минимумов.
После завершения вычислений всеми процессами происходит сбор результатов на процессе с рангом 0 с применением функции `MPI_Gatherv` и синхронизация итоговых данных между всеми потоками при помощи `MPI_Bcast`.

## 5. Experimental Setup
- Hardware/OS: CPU model, cores/threads, RAM, OS version
- Toolchain: compiler, version, build type (Release/RelWithDebInfo)
- Environment: PPC_NUM_THREADS / PPC_NUM_PROC, other relevant vars
- Data: how test data is generated or sourced (relative paths)

## 6. Результаты

### 6.1 Корректность


### 6.2 Производительность
| Mode        | Count | Time, s | Speedup | Efficiency |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 1.234   | 1.00    | N/A        |
| omp         | 2     | 0.700   | 1.76    | 88.0%      |
| omp         | 4     | 0.390   | 3.16    | 79.0%      |

## 7. Выводы


## 8. Литература
1. Стандарт MPI.
2. Лекции и практики по параллельному программированию.

## 9. Приложение

```cpp
int main(){ return 0; }
```