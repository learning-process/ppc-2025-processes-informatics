# Метод простой итерации
- Студент: Гонозов Леонид Андреевич, 3823Б1ФИ3
- Технология: SEQ, MPI 
- Вариант: 11

---

## 1. Введение
Методы решения многоэкстремальных задач широко встречаются в приложениях, например, при проектировании радиотетехнических устройств, и зачастую для решенния многоэкстремальных задач недостаточно нахождения локального мнимимума. Он может как не удовлетворять заданным требованиям и не показывать точную картину для поставленной задачи, так и быть разделённым существенным выигрышем по отношению к глобальному минимуму. На этой почве и возникает потребность в алгоритмах глобальной оптимизации. Одним из которых как раз и является алгоритм глобального поиска или алгоритм Стронгина. Он позволит найти глобальный минимум на отрезке (в случае одномерного варианта - отрезок вещественной оси) для заданной функции.

Цель работы — реализовать параллельную версию одномерного алгоритма глобального поиска с использованием технологии MPI, оценить корректность работы и исследовать ускорение относительно последовательного варианта.

---

## 2. Постановка задачи
**Определение**: На вход подаются минимизируемая функция, левая и правая граница отрезка, параметр остановки и коэффициент r. Последнее значение характеризует по сути то, насколько сильно нам нужна точность вычислений. Главным из всех условий, которые накладываются на входные данные, является то, что коэффициент r должен быть строго больше нуля. Алгоритм в ходе своей работы будет выбирать новые точки испытаний, исходя из заданных коэффициентов, координат прошлых испытаний и значений функции в точках испытаний. Завершение алгоритма происходит в случае, если координаты границ отрезка нового испытания отличаются друг от друга на величину не превышающие параметр остановки. За начальные испытания принимаются точки в границах заданного отрезка. 

**Входные данные**: минимизируемая функция, левая и правая граница отрезка, параметр остановки и коэффициент r
**Выходные данные:** координата глобального минимума для функции на заданном отрезке

**Ограничения**:
- минизируемая функция должна быть непрерывной и удовлятворяющей условию Липшица на указанном отрезке
- параметр остановки рекомендуется брать не более 0.01
- коэффициень r должен быть строго больше нуля
- любая координата начального испытания не должна приводить к расхождению результата алгоритма с истинным значением 
- различное количество процессов не должно приводить к непредвиденным последствиям.

---

## 3. Описание базового алгоритма 
В начале инициализируются переменные координаты глобального минимума и значения в точке глоабльного минимума. Для них выбирается наименьший по значению вариант из границ отрезка, на котором задана функция.
Далее идёт сам алгоритм, его можно условно разбить на шаги:
1. Сортировка всех координат в порядке возрастания. Все координаты хранятся в *std::vector<double> testSequence*
2. Подсчёт коэффициента M, являющегося максимальным абсолютным значением относительной первой разности
3. Подсчёт коэффициента m - функции от коэффициента M и r: *(M == 0.0) ? 1.0 : r * M*
4. Подсчёт характеристик интервала и определение индекса t интервала, соответствующего самой большой характеристике
5. Вычисление координаты нового испытания, исходя из коэффициента m и координат, соотносящихся с индексом t
```cpp
double newElemSequence = 0.5 * (testSequence[t] + testSequence[t - 1]) -
                             0.5 / m * (function(testSequence[t]) - function(testSequence[t - 1]));
```                        
6. Проверка на минимальность координаты нового испытания
7. Проверка выполнения условия остановки, где epsilon - заранее заданный параметр остановки
```cpp
abs(testSequence[t] - testSequence[t - 1]) > epsilon
```             
---

## 4.  Схема распараллеливания
- **Декомпозиция данных**:
    - Каждый процесс производит вычисления характеристик только для своей части вектора *testSequence* 
    - Локально для каждого процесса вычисляется то, в каких именно интервалах ему нужно посчитать характеристики
    - Пересылается всегда весь *testSequence* через `MPI_Bcast`, так как пересчёт на каждой итерации массивов для `MPI_Scatterv` показал себя ужасно
- **Вычисления на процессе**:
    Каждый процесс вычисляет характеристику для тех интервалов, которые достались ему при распредлении данных между процессами.
- **Коммуникация**:
    `MPI_Bcast` множество раз используется для пересылки той информации, которая была получена только на основном процессе: это и пересылка нового вектора испытаний, и подсчёт параметров M и m, после чего m пересылается всем процессам, и проверка достижения вычислениями параметра остановки.
    Для сбора информации о индексе интервала со всех процессов на корневом используется `MPI_Reduce` со специфической операцией *MPI_MAXLOC*, в которой происходит нахождение максимального элемента по первому полю структуры, а отправка второго. В нашем случае поля представлены Характеритстикой интервала и индексом того интервала, где она была подсчитана.

- **Топология и обмен**:
	Используется коммуникатор `MPI_COMM_WORLD` без явной топологии (все процессы равноправны).  
	Тип обмена — коллективные операции (`MPI_Bcast`, `MPI_Reduce`).

 
---
## 5.  Детали реализации
- **Ключевые файлы:**
	- `tasks/gonozov_l_global_search/seq/include/ops_seq.hpp` и `tasks/gonozov_l_global_search/seq/src/ops_seq.cpp` - последовательная реализация.
	- `tasks/gonozov_l_simple_global_search/mpi/include/ops_mpi.hpp` и `tasks/gonozov_l_global_search/mpi/src/ops_mpi.cpp` - параллельная реализация.
	- `tasks/gonozov_l_simple_global_search/common/include/common.hpp` - общие определения типов и интерфейсов.
- **Особенности**:
- **Разбиение данных на части по числу процессов**
	Для каждого процесса высчитывается l и r_i - левая и правая границы подвектора испытаний, для которого нужно посчитать характеристику:
```cpp
    int intervals = n - 1; // количество элементов в векторе testSequence
    int per_proc = intervals / proc_num; // каждый процесс гарантировано получит для подсчёта per_proc элементов
    int rem = intervals % proc_num; // остаток, количество нераспределённых данных

    int l = proc_rank * per_proc + std::min(proc_rank, rem); // то, сколько данных получили процессы до текущего, используется как левая граница интервала для подсчёта
    int r_i = l + per_proc + (proc_rank < rem ? 1 : 0); // правая граница интервала для подсчёта
```
- **Передача процессам данных, требуемых для вычислений**
    Рассылается размер *testSequence* и сама *testSequence*, рассылается коэффициент m, а в конце итерации пересылается условие прдолжения. Все эти опреации производятся с помощью `MPI_Bcast`

- **Вычисления на каждом отдельно взятом процессе**
    На каждом отдельно взятом процессе происходит вычисление характеристик интервалов для этого фрагмента *testSequence* и определение максимальной характеристики и индекса этой характеристики
    Вычисление первых приближений, где my_first_row - смещение, характеризующее положение диагонального элемента для взятой строки:
	```cpp
    double local_max = -std::numeric_limits<double>::infinity();
    int local_idx = -1;

    if (l < r_i) {
      for (int i = l + 1; i <= r_i; ++i) {
        double R = IntervalCharacteristic(testSequence[i - 1], testSequence[i], function(testSequence[i - 1]), function(testSequence[i]), m);
        if (R > local_max) {
          local_max = R;
          local_idx = i;
        }
      }
    }
	```
- **Вычисления на корневом процессе** 
    На корневом процессе высчитываются M, зависящее от прошлых M, индекса t интервала с максимальной характеристикой прошлого шага, координат испытаний и значений функции в этих координатах, и m, зависящее от коэффициентов M и r.
    Подсчёт нового испытания и его проверка на мнимальность:
    ```cpp
    double x_new = 0.5 * (testSequence[t] + testSequence[t - 1]) - (function(testSequence[t]) - function(testSequence[t - 1])) / (2.0 * m);
    double fx = function(x_new);
    if (fx < global_min_value) {
        global_min_value = fx;
        global_min_x = x_new;
    }
    testSequence.push_back(x_new);
    ```
    Условие остановки:
    ```cpp
    continue_iteration = std::abs(testSequence[t] - testSequence[t - 1]) > eps;
    ```
- **Сбор промежуточных данных** 
    Осуществляется с помощью `MPI_Reduce`.
    Пересылаемые с каждого процесса данные - это структура, имеющая поля значение (используется для максимальной характеристики, посчитанной процессом) и индекс (соответствующий максимальной характеристике), в MPI такой тип данных соответствует *MPI_DOUBLE_INT*.
    ```cpp
    struct {
      double val;
      int idx;
    } loc, glob;
    loc.val = local_max;
    loc.idx = local_idx;
    ```
    Над этими данными совершается операция *MPI_MAXLOC*, выбирающая максимальное значение из первого поля структуры, но отправляющая в качестве результата второе поле структуры.

- **Получение конечного результата**
    Через `MPI_Bcast` каждый процесс получает значение координаты глобального минимума с корневого процесса
---

## 6. Экспериментальная установка
- **Аппаратное обеспечение**: 
	12th Gen Intel(R) Core(TM) i7-12650H (2.30 GHz) (6 производительных ядер и 4 энергоэффективных)  
	ОЗУ — 16,0 ГБ
- **Операционная система:** Windows 11 Pro
- **Инструменты:**
	- Компилятор: g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0 
	- CMake 4.1.1
	- Режим сборки: Release.
	- Был использован Docker-container
- **Данные:**
    Матрица размерности N = 300, где все элементы равны 1, а диагональные N? и вектор значений b, где каждое значение равно N * 2 - 1

---

## 7.  Результаты и обсуждение

### 7.1 Корректность
Корректность проверялась сравнением результатов полученных в ходе алгоритма и заранее заготовленных значений. При этом на вход подавались вектора различной длины заполненных единицами.

### 7.2 Производительность

Тест 1.   epsilon = 1e-7, a = -1.0, b = 1.0, r = 2.0.
minimized_function = [](double x) {
    double s = 0.0;
    for (int i = 0; i < 32; ++i) {
      s += std::sin(10.0 * x) * std::sin(10.0 * x);
    }
    return x * x + 0.01 * s;
};

| Mode | Count | Time,  s | Speedup | Efficiency |
| ---- | ----- | -------- | ------- | ---------- |
| seq  | 1     | 0.098169 | 1.00    | N/A        |
| mpi  | 2     | 0.054741 | 1,793   | 89,6 %     |
| mpi  | 4     | 0.056547 | 1,736   | 43,4 %     |
| mpi  | 8     | 0.103887 | 0,94496 | 11,8 %     |

Тест 2. Изменение по сравнению с тестом 1: r = 3.

| Mode | Count | Time,  s | Speedup | Efficiency |
| ---- | ----- | -------- | ------- | ---------- |
| seq  | 1     | 0.170196 | 1.00    | N/A        |
| mpi  | 2     | 0.117995 | 1,848   | 92,4 %     |
| mpi  | 4     | 0.120340 | 2,7     | 67,5 %     |
| mpi  | 8     | 0.201197 | 2,17    | 27,1 %     |

Тест 3. Изменение по сравнению с тестом 1: eps = 1e-5.

| Mode | Count | Time,  s | Speedup | Efficiency |
| ---- | ----- | -------- | ------- | ---------- |
| seq  | 1     | 0.000987 | 1.00    | N/A        |
| mpi  | 2     | 0.001251 | 0,788   | 39,45 %    |
| mpi  | 4     | 0.00106  | 0,931   | 23,28 %    |
| mpi  | 8     | 0.001785 | 0,55    | 6,91 %     |

- После проведённых тестов очевидно: для того чтобы mpi версия показала себя в наиболее выгодном положении, требуется, чтобы испытание в точке (вычисление значения функции) было очень затратно по вычислениям, тогда за счёт распараллеливания скорость программы вырастет и эффективность будет достаточно большой 
- Изменение в меньшую сторону параметра остановки ведёт к меньшему количеству вычислений, что приводит к падению эффективности
- Увеличение коэффициента r ведёт к тому, что испытания в точках происходят с меньшим шагом, что ведёт к тому, что очередь испытаний вырастает до огромных размеров и эффективность алгоритма уменьшается за счёт того, что мы вынуждены передавать эту очередь
- При большем количестве процессов при одних и тех же входных данных падает эффективность, это обусловлено увелечением числа накладных раскодов (расходов на коммуникацию между процессами)

---

## 8. Заключение
Реализованный в ходе работы параллельный вариант одномерного алгоритма глобального поиска успешно решает поставленную задачу и демонстрирует значительное ускорение относительно последовательной версии. Распараллеливание алгоритма является достаточно специфичным, так как эффективность напрямую вытекает из входных значений, которые нужно подбирать  таким образом, чтобы вычисление функции занимало достаточно большое количество времени.

---

## 9. Источники
- Лекции и практики курса "Параллельное программирование", https://cppreference.com/, https://www.open-mpi.org/ 
