# Отчёт по реализации многомерного интегрирования методом трапеций

**Дисциплина:** Параллельное программирование  
**Преподаватели:** Нестеров Александр Юрьевич, Оболенский Арсений Андреевич  
**Студент:** Фролова Софья Юрьевна, 3823Б1ФИ3  
**Вариант:** 8, Многомерное интегрирование методом трапеций

---

## Введение

В рамках данной лабораторной работы была реализована задача численного многомерного интегрирования функции. Была разработана как последовательная версия (SEQ), так и параллельная версия на основе MPI, использующая модель передачи сообщений для распределения вычислений между процессами.

Реализация интегрирована в инфраструктуру параллельных задач фреймворка PPC и обладает набором функциональных и производительных тестов.

---

## Постановка задачи

Требуется вычислить интеграл многомерной функции $f: \mathbb{R}^n \to \mathbb{R}$ на прямоугольной области:

$$I = \int_{a_1}^{b_1} \int_{a_2}^{b_2} \cdots \int_{a_n}^{b_n} f(x_1, x_2, \ldots, x_n) \, dx_1 \, dx_2 \cdots dx_n$$

где:
- $n$ — размерность интеграла;
- $[a_i, b_i]$ — пределы интегрирования по переменной $x_i$;
- $f(x_1, x_2, \ldots, x_n)$ — интегрируемая функция.

**Входной тип:** `TrapezoidalIntegrationInput` (в коде `InType`) с полями:
- `limits` — вектор пар $(a_i, b_i)$ для каждой размерности;
- `number_of_intervals` — вектор количества интервалов разбиения для каждой размерности;
- `function` — функциональный объект для интегрирования.

**Выходной тип:** `OutType = double` (значение вычисленного интеграла).

---

## Описание алгоритма метода трапеций

### Одномерный случай

Для одномерного интеграла $\int_a^b f(x) dx$ метод трапеций использует формулу:

$$I \approx \frac{b-a}{2n} \left[ f(x_0) + 2f(x_1) + \cdots + 2f(x_{n-1}) + f(x_n) \right]$$

### Многомерный случай

Для многомерного интеграла применяется композиция одномерных формул. Каждой точке в сетке присваивается коэффициент $c_{i_1, \ldots, i_n}$ в зависимости от её положения (внутри области или на границе).



Вес вычисляется как $c_{point} = 2^{d}$, где $d$ — число координат точки, **не** лежащих на границе интегрирования.

Полная формула:

$$I \approx \left( \prod_{j=1}^{n} \frac{b_j - a_j}{n_j \cdot 2^n} \right) \sum_{k=0}^{TotalPoints} c_k \cdot f(point_k)$$

---

## Описание схемы последовательного алгоритма (SEQ)

### Класс `FrolovaSMultIntTrapezSEQ`

Последовательная реализация вычисляет интеграл на одном процессе, перебирая все точки сетки в линеаризованном цикле.

### Этапы выполнения

1. **Валидация (ValidationImpl):**
   - Проверка непустоты входных векторов.
   - Проверка соответствия размеров `limits` и `number_of_intervals`.
   - Проверка корректности пределов ($a_i < b_i$).

2. **Предварительная обработка (PreProcessingImpl):**
   - Копирование входных данных.
   - Инициализация аккумулятора результата `result_ = 0.0`.

3. **Основное вычисление (RunImpl):**
   - Вычисление общего количества точек: $count = \prod (n_i + 1)$.
   - Цикл `for (i = 0; i < count; i++)`:
     - Восстановление многомерных координат точки из индекса `i`.
     - Вычисление весового коэффициента.
     - Накопление суммы: $result\_ += coeff \times f(point)$.
   - Применение множителя шагов и деление на $2^n$.

4. **Постобработка (PostProcessingImpl):**
   - Запись результата в `GetOutput()`.

**Временная сложность SEQ:** $O\left(\prod_{i=1}^{n} (n_i + 1)\right)$

---

## Описание схемы параллельного алгоритма (MPI)

### Класс `FrolovaSMultIntTrapezMPI`

Параллельная реализация использует статическое распределение диапазона индексов между процессами. Это позволяет избежать пересылки самих задач (индексов), так как каждый процесс может вычислить свой диапазон самостоятельно.



### Схема параллелизма

1. **Инициализация и рассылка (Broadcast):**
   - Процесс 0 (Root) считывает данные.
   - Рассылка размерности `dims`.
   - Рассылка векторов `limits` и `number_of_intervals` всем процессам.

2. **Статическая балансировка (Static Load Balancing):**
   - Вычисление общего числа точек: $total\_points = \prod (n_i + 1)$.
   - Определение диапазона для текущего ранга:
     ```cpp
     base_delta = total_points / size;
     remainder = total_points % size;
     local_count = base_delta + (rank < remainder ? 1 : 0);
     local_start = rank * base_delta + (rank < remainder ? rank : remainder);
     ```

3. **Локальное вычисление:**
   - Каждый процесс итерируется от `local_start` до `local_start + local_count`.
   - Для каждого индекса восстанавливаются координаты точки и вычисляется локальная сумма.

4. **Сбор результатов (Reduce):**
   - Суммирование всех `local_sum` в `result_` на процессе 0 с помощью `MPI_Reduce` (операция `MPI_SUM`).

5. **Финализация:**
   - Процесс 0 применяет общий множитель (произведение шагов сетки) и нормировку.

### Сложность коммуникаций

Количество MPI операций минимально:
- 3 операции `MPI_Bcast` (инициализация).
- 1 операция `MPI_Reduce` (сбор данных).

Объем передаваемых данных: $O(n)$, где $n$ — размерность пространства.

---

## Реализация в рамках фреймворка PPC

Для задачи созданы классы в пространстве имён `frolova_s_mult_int_trapez`:
- `FrolovaSMultIntTrapezSEQ` — последовательная реализация.
- `FrolovaSMultIntTrapezMPI` — параллельная реализация.

Оба класса наследуют `BaseTask`. Реализация методов `ValidationImpl`, `PreProcessingImpl`, `RunImpl`, `PostProcessingImpl` находится в соответствующих cpp-файлах.

---

## Результаты экспериментов и выводы

### Функциональные тесты

Тесты проверяют корректность работы на известных интегралах.

| Тест | Функция | Размерность | Сетка | Описание |
|------|---------|-------------|-------|----------|
| `quadratic` | $x^2 + y^2$ | 2D | $50 \times 50$ | Интеграл квадратичной функции |
| `cubic` | $x \cdot y \cdot z$ | 3D | $30^3$ | Произведение переменных |
| `sine` | $\sin(x)$ | 1D | $100$ | Тригонометрическая функция |

**Результаты:** Все функциональные тесты успешно проходят. Результаты MPI и SEQ версий совпадают.

### Тесты производительности

Тесты производительности (`RunPerfModes`) измеряют время выполнения на задачах разного объема.

| Тест | Размерность | Функция | Сетка | Общее число точек |
|------|-------------|---------|-------|-------------------|
| `small` | 2D | $x^3 + y^3$ | $500 \times 500$ | ~2.5 $\cdot 10^5$ |
| `medium` | 3D | $\sum x_i^2$ | $200^3$ | ~8 $\cdot 10^6$ |
| `large` | 4D | $\sum x_i^2$ | $100^4$ | ~1 $\cdot 10^8$ |

**Анализ:**
- На тесте **Small** ускорение отсутствует из-за накладных расходов на инициализацию MPI и коммуникации.
- На тестах **Medium** и **Large** параллельная версия демонстрирует ускорение, близкое к линейному, так как вычислительная сложность значительно превосходит коммуникационные издержки.

---

## Технические детали реализации

### Преобразование индексов (Recursive)

Используется алгоритм перевода числа в систему счисления со смешанными основаниями для восстановления координат точки из линейного индекса, что позволяет экономить память (не хранить сетку).

### Вычисление коэффициентов

Для проверки граничных условий используется `std::abs(val - limit) < 1e-9` для компенсации погрешности float:

```cpp
if ((std::abs(limits_[i].first - point[i]) < 1e-9) || 
    (std::abs(limits_[i].second - point[i]) < 1e-9)) { 
    degree--; 
}
return pow(2, degree);

## Заключение

В ходе выполнения лабораторной работы были:

- Разработана последовательная версия (SEQ) алгоритма многомерного интегрирования методом трапеций;
- Разработана параллельная версия (MPI) с распределением вычислений между процессами;
- Реализованы функциональные тесты для проверки корректности вычислений;
- Реализованы тесты производительности для анализа эффективности;
- Выполнена интеграция с фреймворком PPC в соответствии с требованиями.

Реализованные версии демонстрируют корректность метода трапеций для многомерного интегрирования и показывают потенциал параллелизации для больших задач. MPI версия позволяет эффективно масштабировать вычисления на кластерах с несколькими узлами, хотя требует достаточного размера проблемы для окупаемости коммуникационных затрат.

---

## Литература

1. Лекции Сысоева А.В. по параллельному программированию
2. Практические занятия Нестерова А.Ю. и Оболенского А.А.
3. Документация MPI (Message Passing Interface)
4. Численные методы интегрирования: М.З. Гарипов, Н.П. Поляков