# Алгоритм глобального поиска (Стронгина) для одномерных задач оптимизации. Распараллеливание по характеристикам

**Студент:** Кондаков Владислав Сергеевич, группа 3823Б1ФИ1  
**Технологии:** SEQ, MPI  
**Вариант:** 11

---

## 1. Введение

Алгоритмы глобальной оптимизации предназначены для поиска глобального минимума (или максимума) функции на заданном интервале. Метод Стронгина — один из эффективных подходов для одномерных задач, основанный на оценке константы Липшица и характеристике интервалов.

Цель данной работы — реализовать и сравнить последовательную и параллельную (MPI) версии алгоритма Стронгина с распараллеливанием по характеристикам интервалов. Параллельная версия предполагает одновременное исследование нескольких перспективных интервалов с последующей синхронизацией состояния между процессами.

---

## 2. Постановка задачи

Необходимо найти приближение к точке глобального минимума вещественной функции f(x) на отрезке [a, b], удовлетворяющее заданной точности e.

### Входные данные
- Функция f
- Границы интервала поиска a < b
- Точность e > 0
- Надёжность оценки r > 0
- Максимальное число итераций N_max

### Выходные данные
- Приближённое значение аргумента минимума x
- Значение функции f(x)
- Фактическое число вычислений функции
- Флаг сходимости

---

## 3. Последовательный алгоритм (SEQ)

Алгоритм начинает с оценки функции на концах отрезка [a, b]. Затем на каждой итерации:
1. Вычисляется адаптивная оценка константы Липшица на основе уже известных значений функции.
2. Для каждого интервала между соседними точками вычисляется характеристика, отражающая перспективность интервала для поиска минимума.
3. Выбирается интервал с наибольшей характеристикой.
4. В нём генерируется новая пробная точка, в которой вычисляется значение функции.
5. Точка и её значение вставляются в упорядоченные списки.
6. Процесс повторяется до достижения заданной точности или исчерпания лимита итераций.

---

## 4. Схема параллельной обработки (MPI)

### Распараллеливание по характеристикам

В MPI-версии на каждой итерации:
1. Все процессы синхронизируют глобальное состояние (множество точек и значений функции).
2. Каждый процесс независимо вычисляет характеристики всех интервалов и сортирует их.
3. Выбираются P лучших интервалов, где P — число MPI-процессов.
4. Каждый процесс i (до P-1) оценивает функцию в пробной точке, сгенерированной из i-го лучшего интервала.
5. Результаты всех вычислений собираются на корневом процессе (rank = 0) и вставляются в глобальную структуру данных.
6. Обновлённое состояние рассылается всем процессам.

Такой подход позволяет одновременно исследовать до P перспективных направлений поиска и потенциально ускорить сходимость.

### Синхронизация

- После каждой итерации полное состояние (векторы точек и значений) рассылается через `MPI_Bcast`.
- Результаты вычислений собираются с помощью `MPI_Allgatherv`.

---

## 5. Детали реализации

Структура проекта:
- `common/` — общие типы
- `seq/` — последовательная реализация (`KondakovVGlobalSearchSEQ`)
- `mpi/` — MPI-реализация (`KondakovVGlobalSearchMPI`)
- `tests/` — функциональные и производительностные тесты

---

## 6. Окружение

- **CPU:** AMD Ryzen 5 5650U (6 ядер / 12 потоков)  
- **RAM:** 16 ГБ  
- **ОС:** Ubuntu 22.04  
- **Компилятор:** Clang
- **MPI:** OpenMPI  

---

## 7. Результаты и обсуждение

Тестирование проводилось на функции `input_data_.func = [](double x) { return (x-3.14)*(x-3.14) + 0.1*std::sin(50*x); }`; с параметрами:
- a = 0.0, b = 6.28
- ε = 10^-7
- r = 2.0
- N_max = 15000

### 7.1 Корректность

Результаты SEQ и MPI совпадают, все функциональные тесты пройдены.

### 7.2 Производительность

| Mode | Count | Time (s) | Speedup | Efficiency |
|------|-----------|-----------|-----------|----------------|
| seq  | 1         | 0.00114   | 1.00      | –              |
| mpi  | 2         | 0.00868   | 0.13      | 0.07           |
| mpi  | 4         | 0.00525   | 0.22      | 0.05           |
| mpi  | 6         | 0.00431   | 0.26      | 0.04           |

### 7.3 Обсуждение

Наблюдается замедление при переходе к MPI-версии. Это объясняется следующими факторами:

1. **Низкая вычислительная сложность целевой функции.** В тестах использовалась простая аналитическая функция, вычисление которой занимает доли микросекунды. Стоимость вызова `MPI_Bcast` и `MPI_Allgatherv` многократно превышает выгоду от распараллеливания.
2. **Частая синхронизация.** Алгоритм требует обмена полным состоянием после **каждой** итерации, что создаёт значительные коммуникационные задержки.
3. **Небольшой объём работы на итерацию.** Число интервалов растёт медленно (линейно от числа итераций), поэтому параллельная обработка P интервалов не компенсирует накладные расходы.

Тем не менее, при использовании дорогостоящей целевой функции (например, моделирование, численное интегрирование), MPI-версия может продемонстрировать реальное ускорение, так как доля коммуникаций перестанет так сильно влиять на общий результат.

---

## 8. Заключение

Реализованы корректные последовательная и MPI-версии алгоритма глобального поиска Стронгина с распараллеливанием по характеристикам интервалов. Архитектура кода соответствует модульным принципам: разделение SEQ/MPI, выделение вспомогательных функций, строгая валидация входных данных.

На тестовых функциях с низкой вычислительной стоимостью MPI-версия оказывается медленнее из-за накладных расходов на коммуникацию. Однако подход остаётся перспективным для задач с дорогой целевой функцией .

---

## 9. Список литературы

1. MPI Forum. https://www.mpi-forum.org/docs/  
2. Лекции по курсу «Параллельное программирование»
