# Выделение ребер на изображении с использованием оператора Собеля

- Студент: Чащин Владимир Александрович, группа 3823Б1ФИ3
- Технология: SEQ, MPI
- Вариант: 29

## 1. Введение

Выделение границ и контуров на изображениях является одной из базовых задач компьютерного зрения и обработки изображений. Оно широко применяется в анализе изображений, распознавании объектов, медицинской диагностике, робототехнике и машинном обучении. Одним из классических методов для решения этой задачи является оператор Собеля, который позволяет оценивать градиент яркости изображения в горизонтальном и вертикальном направлениях и выявлять области резкого изменения интенсивности — то есть границы объектов.

Задача выделения ребер обладает хорошо структурированным характером: каждая точка изображения обрабатывается локально с использованием маски 3×3, что делает её естественной для параллельной реализации. Однако на практике эффективность параллельной обработки может быть ограничена особенностями распределения данных и накладными расходами на передачу граничных данных между блоками изображения.

Цель работы — реализовать последовательную и параллельную MPI-версии алгоритма выделения границ на изображениях с использованием оператора Собеля, исследовать их производительность на больших изображениях, проанализировать масштабируемость и выявить факторы, влияющие на эффективность параллельной реализации.
## 2. Постановка задачи

**Дано:** изображение размером `N × M`, представляемое как матрица пикселей (`std::vector<std::vector<Pixel>>`). Каждый пиксель содержит значения компонент цвета (R, G, B).

**Требуется:** построить вектор длины `N`, где каждый элемент — максимальный элемент соответствующей строки матрицы.

**Входные данные:** `tuple<std::vector<std::vector<Pixel>>, int, int>;` — двумерная матрица и размеры изображения.
**Выходные данные:** `std::vector<std::vector<Pixel>>` — матрица пикселей после применения оператора Собеля.

**Ограничения:** Изображение может иметь любую ширину и высоту `(N и M ≥ 1)`.
Алгоритм должен корректно обрабатывать граничные пиксели, используя padding или подходящие условия.
Реализация должна корректно работать в параллельной MPI-версии, учитывая, что количество строк не всегда делится нацело на количество процессов.

## 3. Последовательный алгоритм

Последовательный алгоритм реализует прямую свёртку изображения с масками оператора Собеля. Для каждого пикселя исходного изображения вычисляются градиенты по горизонтали (Gx) и вертикали (Gy) с помощью масок 3×3, после чего определяется итоговая величина градиента:
`G =sqrt (gx^2 + gy^2)`
Для обработки границ изображения используются padding или специальные условия, чтобы избежать выхода за пределы массива. Результатом работы алгоритма является изображение того же размера, представленное в оттенках серого (R = G = B = G).
## Анализ алгоритма
* Для каждого пикселя выполняется 9 умножений и 8 сумм для Gx и Gy, а также вычисление квадратного корня.
* Общая сложность алгоритма — O(N * M), где N × M — размеры изображения.
* Основная нагрузка приходится на доступ к памяти и вычисление градиента, а не на условные проверки.
* Современные компиляторы (включая Intel C++ Compiler 2025) способны эффективно векторизовать циклы свёртки, что ускоряет выполнение последовательной версии.
* Важное следствие: при распараллеливании с использованием MPI эффективность может ограничиваться накладными расходами на обмен граничными данными между процессами, особенно для небольших блоков изображения.

Данный анализ показывает, что последовательная реализация хорошо оптимизируется, однако при больших изображениях появляется необходимость в MPI-параллелизации для ускорения обработки.

## 4. Схема распараллеливания

Используется модель Master–Worker с распределением строк изображения между процессами.

## Разбиение строк

Процесс 0 вычисляет диапазон строк для каждого процесса:
* `base = N / size` — минимальное число строк на процесс
* `rem = N % size` — остаток, который добавляется по одной строке к первым rem процессам
Таким образом, нагрузка распределена почти равномерно, что обеспечивает баланс между процессами.

## Передача данных

1.	Подготовка буферов и sendcounts
	* Процесс 0 формирует одномерный буфер `PreProcessGray_` с padding и overlap для корректной работы оператора Собеля.
	* Вектор `ScatterSendCounts_` содержит количество элементов, которые каждый процесс должен получить.

2. Распространение информации о размере блоков
	* Используется `MPI_Bcast`, чтобы все процессы узнали свои `recvcount`.
	* Рабочие процессы выделяют локальные буферы `local_block` нужного размера.

3. Передача блоков данных
	* Используется `MPI_Scatterv` для распределения строк изображения:
	* Мастер передаёт каждому процессу его часть буфера `PreProcessGray_`.
	* Рабочие процессы получают данные в `local_block`.

4. Обработка локальных данных.
	* После приёма всех строк процесс вычисляет максимальные элементы по каждой строке.
	* Результаты затем собираются обратно у мастера (сбор не описан в этом фрагменте).

## Обработка локальных данных

* Каждый процесс последовательно обходит свои строки и столбцы и применяет оператор Собеля с помощью функции `SobelAt`.

* Результаты сохраняются в локальном буфере `local_output`.

## Сбор результатов

* Мастер формирует векторы recvcounts и displs_out для вызова MPI_Gatherv.

* Каждый процесс отправляет свои вычисленные строки обратно мастеру.

* Мастер собирает все локальные блоки в финальный буфер PostProcessGray_, получая полное изображение после обработки.

## 4. Экспериментальная установка

	* CPU: Intel Core i5-12500H
	* 4 производительных ядра
	* 8 энергоэффективных ядер
	* RAM: 16 GB
	* OS: Windows 11 Pro 24H2
	* Компилятор: Intel C++ Compiler 2025
	* Изображение: детерминированное, квадратное, 8000×8000
	* Время — среднее по 8 повторениям.

## 6. Результаты и обсуждение

### 6.1 Корректность

Все тесты пройдены, расхождений нет.
Корректность параллельной реализации подтверждена.

### 6.2 Производительность

Для оценки производительности измерялось чистое время выполнения алгоритма без учета создания тестовых данных. На основе полученных данных были рассчитаны метрики ускорения (Speedup) и эффективности (Efficiency).
|  p | T_obs (ms) | T_ideal (ms) | O = T_obs − T_ideal (ms) |
| -: | ---------: | -----------: | -----------------------: |
|  1 |        558 |          524 |                       34 |
|  2 |        374 |          262 |                      112 |
|  4 |        297 |          131 |                      166 |
|  8 |        232 |         65.5 |                    166.5 |
| 12 |        247 |         43.7 |                    203.3 |
| 16 |        231 |        32.75 |                   198.25 |


| Режим | Число процессов | Время, ms | Ускорение         | Эффективность         | T_ideal (ms) | O = T_obs − T_ideal (ms) |
| ----- | --------------- | --------- | ----------------- | --------------------- | -----------  | -----------------------  |
| seq   | 1               | 524       | 1.00              | —                     |              |                          |
| mpi   | 1               | 558       | 524 / 558 ≈ 0.939 | 0.939 / 1 × 100 ≈ 94% |          524 |                       34 |
| mpi   | 2               | 374       | 524 / 374 ≈ 1.401 | 1.401 / 2 × 100 ≈ 70% |          262 |                      112 |
| mpi   | 4               | 297       | 524 / 297 ≈ 1.765 | 1.765 / 4 × 100 ≈ 44% |          131 |                      166 |
| mpi   | 8               | 232       | 524 / 232 ≈ 2.26  | 2.26 / 8 × 100 ≈ 28%  |         65.5 |                    166.5 |
| mpi   | 12              | 247       | 524 / 247 ≈ 2.12  | 2.12 / 12 × 100 ≈ 18% |         43.7 |                    203.3 |
| mpi   | 16              | 231       | 524 / 231 ≈ 2.27  | 2.27 / 16 × 100 ≈ 14% |        32.75 |                   198.25 |

**Анализ результатов:**
* На одном процессе MPI показал худшее время по сравнению с последовательной версией (558 ms vs 524 ms), что объясняется накладными расходами на инициализацию и управление MPI.
* При малом числе процессов (2–4) ускорение наблюдается, но эффективность падает быстро (до 44 % на 4 процессах). Основная причина — высокие затраты на коммуникацию и пересылку дополнительных строк (ghost rows) для корректной работы оператора Собеля.
* Ускорение появляется только при 8 и более процессах, однако эффективность остаётся низкой: 28 % на 8 процессах и 14 % на 16 процессах. Это указывает на то, что фиксированные накладные расходы на Scatterv/Gatherv и padding становятся доминирующими.
* Даже при 16 процессах ускорение составляет всего 2.27×, что значительно ниже идеальной линейной зависимости.
* Наблюдаемая стабилизация оверхеда (~160–200 ms) при росте числа процессов подтверждает, что большая часть времени MPI-версии тратится на передачу данных и подготовку буферов, а не на вычисления.
* Последовательная версия остаётся конкурентоспособной благодаря векторизации и кэш-локальности, поэтому масштабируемость MPI ограничена архитектурными особенностями текущей реализации.
## 8. Выводы

* Последовательная реализация алгоритма Собеля проста, эффективна и хорошо векторизуется, при этом её производительность ограничена пропускной способностью памяти (memory-bound).
* MPI-версия корректно вычисляет результат, но масштабируемость ограничена высоким уровнем коммуникационных накладных расходов и фиксированными оверхедами.
* Мастер-процесс является узким местом: он формирует буферы и собирает результаты, что увеличивает задержки при росте числа процессов.
* Вычислительная нагрузка на одну строку изображения невелика и не компенсирует затраты на передачу данных между процессами.
* На тестовом изображении размером 20000×20000 пикселей ускорение при 16 процессах составило всего 2.27×, а эффективность — 14 %, что подчёркивает ограниченное соотношение вычислений к коммуникациям (computation-to-communication ratio).

## 9. Источники

1.  Parallel Programming Course — https://learning-process.github.io/parallel_programming_course/ru/
2.  Parallel Programming 2025–2026 Video Lectures — https://disk.yandex.ru/d/NvHFyhOJCQU65w
3.  Open MPI Documentation — https://www.open-mpi.org/doc/
4.  C++ Reference (cppreference.com) — https://en.cppreference.com/w/cpp/algorithm/ranges/min_element
5.  Sobel Operator Overview and Image Processing References — https://en.wikipedia.org/wiki/Sobel_operator