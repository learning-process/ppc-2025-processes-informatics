# Подсчёт числа предложений в строке
- Студент: Гусев Дмитрий Алексеевич, 3823Б1ФИ1
- Технология: SEQ, MPI 
- Вариант: 25

---

## 1. Введение
Подсчёт предложений в текстовых данных — одна из базовых задач анализа текста. Такая функциональность востребована в системах обработки естественного языка, инструментах оценки сложности текста, а также в приложениях для автоматического создания аннотаций.

В рамках данной работы разработана параллельная реализация алгоритма подсчёта предложений на базе MPI. Проведена верификация корректности работы и исследование масштабируемости решения относительно последовательной версии.

---

## 2. Постановка задачи
**Исходные данные**: произвольная текстовая строка, содержащая буквенные символы, цифры, знаки препинания и пробельные символы.

**Цель**: вычислить число предложений в данной строке.

**Определение предложения**: фрагмент текста, оканчивающийся терминатором — точкой (`.`), восклицательным (`!`) или вопросительным (`?`) знаком. Группы идущих подряд терминаторов (типа `!!!` или `...`) трактуются как окончание одного предложения.

**Вход**: строка произвольной длины.
**Выход**: целое неотрицательное число — количество предложений.

**Требования**:
- алгоритм должен обрабатывать строки значительного размера (мегабайты);
- решение должно функционировать с произвольным числом MPI-процессов;
- разбиение текста на части между процессами не должно приводить к ошибкам в подсчёте.

---

## 3. Последовательный алгоритм
Алгоритм последовательной обработки выполняет однократный проход по строке. При обнаружении терминатора проверяется, не является ли следующий символ также терминатором. Если нет (или достигнут конец строки), счётчик предложений увеличивается.

Алгоритм:
```cpp
sentence_count = 0;
for i from 0 to length(input) - 1:
	if input[i] in {'.', '!', '?'}:
		if i + 1 >= length(input) or input[i + 1] not in {'.', '!', '?'}:
			sentence_count += 1
```

Временная сложность: O(n), где n — длина входной строки.

---

## 4. Параллельная схема
- **Разделение данных**:
	- Текст делится на равномерные сегменты, количество которых равно числу процессов.
	- Распределение сегментов выполняется посредством `MPI_Scatterv`.
	- Для корректной обработки границ каждому процессу передаётся один дополнительный символ из следующего сегмента.
- **Локальные вычисления**:
	Процессы параллельно анализируют свои сегменты функцией `CountSentencesInChunk`, определяя терминаторы и проверяя, что за ними не следует другой терминатор.
- **Сбор результатов**:
	Локальные счётчики суммируются через `MPI_Reduce` на процессе с рангом 0.
- **Коммуникационная модель**:
	Применяется стандартный коммуникатор `MPI_COMM_WORLD` с равноправными процессами. Используются коллективные операции распределения и редукции.

---

## 5. Реализация
- **Структура проекта:**
	- `gusev_d_sentence_count/seq/include/ops_seq.hpp` и `gusev_d_sentence_count/seq/src/ops_seq.cpp` — однопоточная версия.
	- `gusev_d_sentence_count/mpi/include/ops_mpi.hpp` и `gusev_d_sentence_count/mpi/src/ops_mpi.cpp` — MPI-версия.
	- `gusev_d_sentence_count/common/include/common.hpp` — общие типы и интерфейсы.
- **Функциональность**:
	- `IsTerminator(char)` — определяет, является ли символ терминатором (`.`, `!`, `?`).
	- `CountSentencesInChunk(std::vector<char>, int)` — считает предложения в локальном сегменте процесса.
- **Реализационные детали**:
	- **Обработка пустой строки.**  
	    На старте MPI-алгоритма проверяется, не пуста ли входная строка. При пустой строке сразу возвращается `0`, что исключает лишние коммуникационные операции.
	- **Выравнивание длины строки.**  
	    Длина строки приводится к кратности числу процессов путём добавления пробелов в конец.  
	    Это упрощает равномерное распределение данных и устраняет необходимость специальной обработки последнего процесса.  
	    Расширение строки максимум на `comm_size - 1` символов практически не влияет на производительность и обычно не требует переаллокации памяти.
	- **Распределение сегментов.**  
	    Процесс получает свой блок из `chunk_size` символов плюс один символ из начала следующего блока (итого `chunk_size + 1` в буфере).  
	    Это даёт возможность корректно обработать ситуацию, когда предложение разорвано между процессами. В основном цикле обрабатываются только `chunk_size` символов, при этом для каждого найденного терминатора проверяется следующий символ:
	    ```cpp
	    if (IsTerminator(local_chunk[i])) {
			if (!IsTerminator(local_chunk[i + 1])) {
				sentence_count++;
			}
		}
	    ```
	    Такой подход обеспечивает правильный учёт групп терминаторов (например, `!!!`, `...`) как одного предложения, даже если они попадают на разные процессы.
	- **Единообразные буферы.**  
		Все процессы получают буферы одинакового размера `chunk_size + 1`, где лишний символ нужен только для проверки границы. Это делает распределение данных симметричным и упрощает код.

---

## 6. Тестовая конфигурация
- **Оборудование**: 
	Процессор: Intel(R) Core(TM) Ultra 9 185H (16 ядер, 22 логических процессора)  
	ОЗУ: 32 ГБ
- **ОС:** Windows 10 IoT Enterprise Subscription 2009
- **Компилятор:** Microsoft Visual C++ версии 19.44.35220
- **MPI:** Microsoft MPI версии 10.1.12498.18
- **Режим компиляции:** Release с оптимизацией (`/O2`)

---

## 7. Результаты экспериментов
### 7.1 Верификация
Проверка корректности работы алгоритма выполнялась путём сравнения результатов параллельной MPI-реализации с эталонной последовательной версией.

Тестирование проводилось на широком наборе входных данных:
- пустые строки;
- тексты без терминаторов;
- строки с одним предложением;
- тексты с множественными терминаторами;
- комбинации различных символов и терминаторов;
- граничные случаи: группы терминаторов (`!!!`, `...`, `?!`), терминаторы в начале и конце строки.

Во всех тестовых сценариях результаты параллельной и последовательной версий полностью совпадают, что подтверждает корректность реализации алгоритма.

### 7.2 Измерения производительности
Эксперименты по оценке производительности выполнялись на конфигурации, описанной в разделе 6. В качестве тестовых данных использовался текстовый файл значительного размера (порядка нескольких мегабайт).

Измерения времени выполнения проводились для последовательной (SEQ) и параллельной (MPI) версий при различном количестве процессов. Результаты представлены в таблице ниже.

| Mode | Count | Time, s | Speedup | Efficiency |
|------|-------|---------|---------|------------|
| seq  |   1   | 0.01609 |   1.00  |     N/A    |
| mpi  |   2   | 0.01072 |   1.50  |    75.1%   |
| mpi  |   4   | 0.00751 |   2.14  |    53.5%   |
| mpi  |   8   | 0.01402 |   1.15  |    14.4%   |

**Анализ результатов:**
- Последовательная версия (seq) выполнялась за 0.01609 секунды и использовалась как базовое значение для расчёта ускорения.
- При использовании 2 процессов MPI-версия демонстрирует ускорение 1.50 относительно последовательной версии с эффективностью 75.1%, что указывает на хорошую масштабируемость алгоритма для данного количества процессов.
- При увеличении числа процессов до 4 наблюдается максимальное ускорение 2.14, однако эффективность снижается до 53.5%. Это объясняется ростом накладных расходов на коммуникацию и синхронизацию между процессами.
- При использовании 8 процессов производительность значительно ухудшается: время выполнения увеличивается до 0.01402 секунды, что хуже, чем при 4 процессах (0.00751 секунды). Ускорение составляет всего 1.15 с эффективностью 14.4%. Это демонстрирует, что дальнейшее увеличение числа процессов нецелесообразно из-за преобладания накладных расходов над вычислительной нагрузкой.
- Результаты подтверждают целесообразность использования параллельного подхода для обработки больших текстовых данных, при этом оптимальное количество процессов для данной задачи — 2 или 4, в зависимости от приоритета эффективности или максимального ускорения.

---

## 8. Выводы
- Разработанный параллельный алгоритм корректно выполняет подсчёт предложений в текстовой строке с использованием технологии MPI.
- Параллельная реализация демонстрирует ускорение по сравнению с последовательной версией, достигая максимального ускорения 2.14 при использовании 4 процессов.
- Оптимальное количество процессов для данной задачи — 2 или 4: при 2 процессах достигается наилучшая эффективность (75.1%), а при 4 процессах — максимальное ускорение (2.14).
- Основными факторами, ограничивающими дальнейшее масштабирование, являются накладные расходы на межпроцессное взаимодействие и синхронизацию. При использовании 8 процессов эти расходы начинают преобладать, что приводит к снижению производительности.
- Алгоритм успешно обрабатывает все граничные случаи, включая пустые строки, группы терминаторов и различные комбинации символов.

---

## 9. Литература
- Материалы курса "Параллельное программирование"
- Справочная документация Open MPI
- Документация Microsoft MPI
- Документация Microsoft Visual C++

---

## 10. Приложение

```cpp
namespace {

bool IsTerminator(char c) {
  return c == '.' || c == '!' || c == '?';
}

size_t CountSentencesInChunk(const std::vector<char> &local_chunk, int chunk_size) {
  size_t sentence_count = 0;

  for (int i = 0; i < chunk_size; ++i) {
    if (IsTerminator(local_chunk[i])) {
      if (!IsTerminator(local_chunk[i + 1])) {
        sentence_count++;
      }
    }
  }
  return sentence_count;
}

}  // namespace

bool GusevDSentenceCountMPI::RunImpl() {
  int rank = 0;
  int comm_size = 0;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &comm_size);

  std::string &text_data = GetInput();

  if (text_data.empty()) {
    GetOutput() = 0;
    return true;
  }

  int chunk_size = 0;
  if (rank == 0) {
    size_t length = text_data.size();

    if (length % comm_size != 0) {
      size_t pad = comm_size - (length % comm_size);
      text_data.resize(length + pad, ' ');
      length = text_data.size();
    }

    text_data.push_back(' ');

    chunk_size = static_cast<int>(length / comm_size);
  }

  MPI_Bcast(&chunk_size, 1, MPI_INT, 0, MPI_COMM_WORLD);

  std::vector<char> local_buffer(chunk_size + 1);
  std::vector<int> counts(comm_size, chunk_size + 1);
  std::vector<int> offsets(comm_size);

  if (rank == 0) {
    for (int i = 0; i < comm_size; ++i) {
      offsets[i] = i * chunk_size;
    }
  }

  MPI_Scatterv(text_data.data(), counts.data(), offsets.data(), MPI_CHAR, local_buffer.data(), chunk_size + 1, MPI_CHAR,
               0, MPI_COMM_WORLD);

  size_t local_res = CountSentencesInChunk(local_buffer, chunk_size);

  size_t total_res = 0;
  MPI_Reduce(&local_res, &total_res, 1, MPI_UNSIGNED_LONG, MPI_SUM, 0, MPI_COMM_WORLD);

  if (rank == 0) {
    GetOutput() = total_res;
  }

  return true;
}
```