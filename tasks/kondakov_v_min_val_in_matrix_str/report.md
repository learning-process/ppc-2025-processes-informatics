# Поиск минимального значения в каждой строке матрицы  
**Студент:** Кондаков Владислав Сергеевич, группа 3823Б1ФИ1  
**Технологии:** SEQ, MPI  
**Вариант:** 17  

---

## 1. Введение
Поставлена задача поиска минимального элемента в каждой строке матрицы. Последовательное решение достаточно простое, но при больших размерах матриц время выполнения быстро возрастает.  

Цель работы - реализовать и сравнить два варианта решения:  
- последовательный (SEQ),
- параллельный (MPI).  

Ожидаемый результат - ускорение вычислений за счёт распределения строк матрицы между несколькими процессами.

---

## 2. Постановка задачи
Требуется реализовать алгоритм поиска минимального значения в каждой строке прямоугольной матрицы целых чисел.

### Входные данные
Матрица `NxM`, представленная как `vector<vector<int>>`.

### Выходные данные
`vector<int>` длины `N`, где каждый элемент - минимальное значение соответствующей строки.

### Ограничения
- Все строки должны быть одинаковой длины.  

---

## 3. Последовательный алгоритм (SEQ)
Базовый алгоритм выполняет линейный проход по каждой строке:

1. Для каждой строки завести переменную `min_val`.
2. Обойти элементы строки и найти минимальный.
3. Записать результат в выходной массив.
4. Повторить для всех строк.

Алгоритм содержит два вложенных цикла и имеет сложность `O(N*M)`.

---

## 4. Схема параллельной обработки (MPI)

### Распределение данных
- Процесс **rank 0** рассылает всем остальным количество строк и столбцов.
- Строки распределяются равномерно по процессам:
  - каждый процесс получает участок `[st_row, en_row)`.

### Локальная обработка
Каждый процесс независимо вычисляет минимумы в своих строках:
```
for i in local_rows:
local_min[i] = min(row[i])
```

### Сбор результатов
Используется `MPI_Gatherv`, так как не все процессы получают одинаковое количество строк.  

После сборки процесс 0 рассылает окончательный вектор всем процессам через `MPI_Bcast`.

### Синхронизация
- `MPI_Bcast` - передача размеров матрицы, передача данных.
- `MPI_Gatherv` - сбор частичных результатов.

---

## 5. Детали реализации

### Структура кода
- `seq/include/ops_seq.hpp, seq/src/ops_seq.cpp` - последовательная реализация.
- `mpi/include/ops_mpi.hpp , mpi/src/ops_mpi.cpp` - MPI-версия.
- `common/include/common.hpp` - определения типов.
- `tests/functional/main.cpp, tests/performance/main.cpp` - тесты.

### Память
- Хранение матрицы `10000x10000` требует ~400 МБ.

---

## 6. Окружение

### Аппаратная конфигурация
- CPU: **AMD Ryzen 5 5650U(6/12)**
- RAM: **16 GB**
- ОС: **Ubuntu 22.04**  

### Инструменты
- Компилятор: **Clang**
- Сборка: **Release**
- MPI: OpenMPI

### Параметры среды
- `PPC_NUM_PROC` - 1, 2, 4 в зависимости от теста.

### Данные
Для тестов генерировалась матрица `10000 x 10000`, где  
последний элемент каждой строки отрицательный и равен `-(i+1)`.

---

## 7. Результаты и обсуждение

### 7.1 Проверка корректности
Корректность подтверждена сравнением с заранее известным результатом:  
минимум в i-й строке всегда равен `-(i+1)`.

---

### 7.2 Производительность

| Mode | Count | Time (s) | Speedup | Efficiency |
|------|--------|----------|---------|------------|
| seq | 1 | 0.187 | 1.00 | - |
| mpi | 2 | 0.105 | **1.78** | **0.89** |
| mpi | 4 | 0.074 | **2.53** | **0.63** |

### Обсуждение результатов
- На 2 процессах ускорение почти линейное - 1.78x, эффективность 89%.
- На 4 процессах наблюдается уменьшение эффективности (63%), потому что растут накладные расходы для синхронизации. 

---

## 8. Заключение
Были реализованы и протестированы последовательный и MPI-варианты поиска минимального значения в каждой строке матрицы.  

Выводы:
- Последовательная версия проста и надёжна, но медленнее на больших данных.
- MPI-реализация обеспечивает значительное ускорение - до 2.53× на 4 процессах.
- Эффективность снижается при увеличении количества процессов из-за расходов при синхронизации.
- Решение хорошо масштабируется при условии, что распределение строк равномерно и процессы имеют достаточный объём работы.

---

## 9. Список литературы
1. MPI Standard Documentation - https://www.mpi-forum.org/docs/   
2. Лекции и практики по параллельному программированию  
