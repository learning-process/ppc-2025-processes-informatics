# <Проверка лексикографической упорядоченности двух строк>

- Student: <Смышляев Александр Павлович>, group <3823Б1ФИ2>
- Technology: <SEQ | MPI>
- Variant: <26>

## 1. Introduction
**Мотивация:** Исследовать эффективность распараллеливания задачи сравнения строк через MPI, которая, в отличие от простых арифметических операций, имеет переменную вычислительную сложность.

**Проблема:** Производительность алгоритма сильно зависит от входных данных. В "лучшем случае" (различие в начале строк) затраты на коммуникацию могут превысить выгоду, в то время как в "худшем" (различие в конце) распараллеливание должно быть эффективным.

**Ожидаемый результат:** MPI-версия покажет значительное ускорение по сравнению с последовательной в "худшем случае", но эффективность будет снижаться с ростом числа процессов из-за накладных расходов.
## 2. Problem Statement
На вход поступают две строки произвольного размера. Задача — определить их лексикографический порядок.

## 3. Baseline Algorithm (Sequential)
Базовый (последовательный) алгоритм посимвольно сравнивает строки до первого различия. Если общая часть идентична (одна строка является префиксом другой), результат определяется сравнением длин строк.

## 4. Parallelization Scheme
Параллельный алгоритм основан на декомпозиции задачи. Вместо рассылки данных, предполагается, что каждый процесс уже имеет полные копии исходных строк.

1.  **Распределение работы:** Каждый процесс на основе своего ранга и общего числа процессов вычисляет уникальный, непересекающийся диапазон индексов для сравнения. Длина общего участка строк делится на `N` процессов, а остаток от деления распределяется по первым процессам.
2.  **Локальное сравнение:** Каждый процесс выполняет сравнение символов только в своем диапазоне. Если различие найдено, он сохраняет локальный результат (`-1` или `1`), иначе — `0`.
3.  **Сбор результатов:** С помощью операции `MPI_Allgather` каждый процесс отправляет свой локальный результат всем остальным. В итоге каждый процесс получает полный массив результатов от всех участников.
4.  **Финализация:** Каждый процесс анализирует полученный массив. Итоговый результат — это первый ненулевой элемент в этом массиве (так как массив упорядочен по рангам, это гарантирует нахождение самого первого различия в строках). Если все результаты нулевые, итоговый ответ определяется сравнением длин строк.

## 5. Experimental Setup
- **Hardware/OS:** `Intel Core i7-1255U` (10 ядер, 12 потоков), `16GB RAM`, `Windows 11`
- **Toolchain:** `MSVC v19.38.33130 (Visual Studio 2022)`, `MS-MPI`, `Release`
- **Environment:** `PPC_NUM_PROC`
- **Data:** Две строки на 20'000'000 элементов, различающиеся в последнем символе ("худший случай" для вычислений).

## 6. Results and Discussion

### 6.1 Correctness
Корректность реализаций проверена функциональными тестами (GTest). Тесты покрывают все основные сценарии: равные строки, пустые строки, строки-префиксы и строки с различиями в разных позициях.

### 6.2 Performance
Present time, speedup and efficiency. Example table:

| Mode        | Count | Time, s | Speedup | Efficiency |
|-------------|-------|---------|---------|------------|
| seq         | 1     |   0.018 |   1.00  | N/A        |
| mpi         | 2     |   0.01  |   1.8   | 90.0%      |
| mpi         | 4     | 0.00865 |   2.09  | 52.3%      |
| mpi         | 8     | 0.0111  |   1.62  | 20.3%      |
MPI-реализация показывает хорошее ускорение на 2 и 4 процессах с пиком производительности при N=4.

Высокая эффективность на 2 процессах (90%) говорит о том, что задача хорошо подходит для распараллеливания.

При увеличении числа процессов до 8 наблюдается падение производительности: время выполнения увеличилось по сравнению с 4 процессами. Накладные расходы на коммуникацию (MPI_Allgather) и синхронизацию начинают преобладать над выгодой от дальнейшего дробления вычислений.
## 7. Conclusions
Реализация распределенного сравнения строк с использованием MPI показала свою высокую эффективность для сценариев с большой вычислительной нагрузкой. Выбранный подход с репликацией данных и ручным разделением диапазонов позволил избежать затрат на пересылку больших объемов данных (`Scatterv`), заменив их одной коллективной операцией `Allgather` для сбора небольших локальных результатов. С ростом числа процессов ускорение остается значительным, хотя эффективность падает из-за накладных расходов на синхронизацию. В целом, MPI-подход является оправданным и эффективным решением для сравнения очень больших, преимущественно схожих строк.

## 8. References
1.  Лекции по параллельному программированию ННГУ
2.  Стандарт MPI
